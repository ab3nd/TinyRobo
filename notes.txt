
Fiducial tracking from NERVE cameras
	Camera uses RTSP
	Default TUIO tracker implementation can't use RTSP cameras
	v4l2loopback is broken on Ubuntu 14.04
		Yes, both v4l2loopback-dkms and v4l2loopback-source + module-helper
		Not going to bother compiling from source
			It would break with every kernel upgrade
			Unconvinced it's going to work, given that the packages are broken
		So no converting RTSP to a /dev/videoX entry
	TUIO isn't actually a fiducial library, it's a protocol
	And the reacTable amoeba tags appear to be detcted by a binary blob
		So those guys can go pound sand, I'll use something I can use. 
	April tags?


Bugs in v1 hardware:
Don't use 0204 parts. They're annoyingly tiny. 1206 for everything. 
The caps are OK 0805
The footprint for the diode is too big, it's only slightly bigger than 1206. 
The footprint for the switch needs the leg contacts moved in by half their length towards the switch
Via for the heat sink for the motor drivers needs to not be under the ESP8266
Connectorize battery

Needs pull-up to connect CH_PD high, pull-downs on GPIO15 (all times) and GPIO0 (only for programming)
 - GPIO15 is what I was going to use for one of the fault sensing lines

DRV8833 might be a good canidate for next driver, but only has PWM interface.
3A drive if outputs are paralleled, available in a TSSOP16 package. 

IFX9201SGAUMA1 would also be good, but requires higher voltage (e.g. two-cell battery and voltage regulation)
Has SPI interface, 6A(!) drive current, full bridge per chip. 
 
https://github.com/esp8266/Arduino/issues/22 Has how to get automatic reset, easier than integrating the limpkin.fr reset circuit.  
Needs a serial adapter that has DTR line, ordered that. 

Assembly pointers:
Get you some fine-point tweezers for great good

Ideological bugs:
Off is not where you think it is on the switch (on is towards the battery)
- Label on the PCB
Surface mount ESP8266 has no idiot lights, add one so I can tell when it is on
Add another light to an unused GPIO for debugging
Any reason I shouldn't have all pull-ups be one value (have some 10k and some 1k)?


Mobile Sensor Network Deployment using Potential Fields
Andrew Howard, Maja Mataric, Gaurav Sukhatme
	Deploying a sensor network in unknown environment
	Mobile nodes
	Maximize coverage
	Nodes are repelled by obstacles and each other
		Viscous friction force so that the expansion eventually stops
	No need for localization, aside from relative to other nodes
	Only does one thing (spread out)

A General Algorithim for Robot Formations Using Local Sensing and Minimal Computation
Jakob Fredslund, Maja J Mataric	
N robots, form geometric shape
	Each robot picks a friend, makes sure that friend is at angle Theta
	Three principles of formation control
	Unit-center-referenced
		Relative to centroid of all robots
		Requires global knowledge
	Leader-referenced
		Position of a selected leader
	Neighbor-referenced
		Relative to position of nearest neighbor
		Uses local knowledge
	Paper cites a bunch of possible strategies for formations 
	One robot is leader, has no friends, decides heading of formation
	Certain formations cannot be formed
		Can have at most two loose ends
		Assumptions of sensor precent certain curves
	Angle robot needs to keep its friend at depends on rank in formation
		Allows different angles for e.g. squares
	Leader can drag whole formation around
	Includes algorithims for avoiding obstacles
	Includes handling of individual robot "termination"

Laser-Based People Tracking
Ajo Fod, Andrew Howard, Maja J Mataric
	Tracking people using plana laser scanners
	Objects are tracked as blobs
	Blobs are registered between frames
		Prediction and update steps
	Groups of blobs that stay together are objects
	Object tracker smooths object paths and compensates for occlusions
	From old frame to new frame
		Bounding box old objects
		Expand box
		Check for matches within the expanded box in the new frame
			Minimum-distance point pairs are "matches"
		Weghted by quality of match, which is number of point matches
		New blobs get a state vector of zero
		old blobs get parent's state vector
		State vector can continue to update predicted state of currently missing blobs
			So when they reappear near their predicted location, they get their old state vector

Detecting Anamalous Human Interactions using Laser Rangefinders
	Uses the system described in "Laser-Based People Tracking"
	Tracks of activities re segmented to maximise Jensen-Shannon divergence
	Comparing concurrent positions of tracks detects interactions
	Model of interactions in space is developed
		Anomalous interactions are those of low probability under the model
	

Challenges in Evolving Controllers for Physical Robots
Maja Mataric, Dave Cliff
	Evolves morphology and controller
	Genetic Programming
		Operates on lisp S-expressions as the genome
	Generally, evolutionary control takes a long time
	Generally, controllers are evolved to do exactly one task
	As of '96, no evolutionary controller was doing anything that couldn't be done by hand
	Realtime on real hardware 
		Battery life
		Wear on the robot
	Simulation
		Noise and error models
			Noise has to match real noise
				Otherwise, behavior won't transfer to real world
			GA can exploit abstractions in simulation
		Generality v. Utility
			Simulator that simulates a given robot well won't generalize
	Evaluation
		Detecting convergence is hard to automate
		Human ranking is tedious and slow
	Fitness functions
		Complex to design for complex cases
		Has the same exploitable abstraction problems as simulaton
		May not be able to measure fitness parameters (see Evaluation, above)
	Overall, it seems like this is a bad way to go about what I want

Minimizing Complexity in Controlling a Mobile Robot Population
Maja J Mataric
	Distrbuting a task over homogeneous robots
	Minimal Modeling and no planning
	Only covers tasks that can be done by a single robot
		but get better with multiple robots
		e.g. foraging
	Ignorant coexistance
		Robots treat each other as obstacles
		More robots leads to more problems, slower task completion
	Informed coexistance
		Robots behave differently when avoiding robots than obstacles
		Wait for the other robot to get out of the way, then evade
		Minimizes interference, better than ignorant case
	Intelligent coexistance
		Robots have an idea of local population density, population gradient
		Can minimize potential for interference, not just react to it
		Homing, flocking, etc. 

Design of the Army Ant Cooperative Lifting Robot
John S. Bay
	Not really related, more about mechanical and electronic design

Ant-inspired Navigation in Unknown Environments
	Combination of landmarks and transitions between them
	Failure to detect landmarks triggers search

Relaxation on a Mesh: a Formalism for Generalized Location
	Spring relaxation of networks including some globally localized bodies
	I don't plan to do global localization

Huey, Dewey, Louie, and GUI - Commanding Robot Formations
Jacob Fredslund, Maja j Mataric
	GUI for commanding robots into formations
	Only formation, no box pushing, patrolling, soda-can-collecting, etc. 
	Uses the formation algorithm from "A General Algorithim for Robot Formations Using Local Sensing and Minimal Computation"
	Gui specifies node locations, angles can be calculated from that
	Limitation remains that no robot can look behind itself for its friend


Robots in Formation Using Local Information
Jakob Fredslund, Maja J Mataric
	Same as "A General Algorithim for Robot Formations Using Local Sensing and Minimal Computation" but with more implementation details


Bounds of Neglect Benevolence in Input Timing for Human Interaction with Robot Swarms
Sasanka Nagavalli, Shih-Yi Chien et al
	User may need to make changes to the swarm's goal from a previous goal
	Two capabilities needed
		Comprehension of swarm state
			Relations and regularities in behavior
		Prediction of effect of input on state
			Human must develop a mental model of swarm responses
			Timing lags make this harder
	Adding the human input ASAP may not be optimal
		"Neglect Benevolence" - some neglect may be good
	How does human understand swarm dynamics to choose best time to intervene?
		Humans can learn to approximate optimal timing
	Paper refers to "Neglect Benevolence shape-changing HSI reference task"
	Doesn't really effect compilation or anything, but good for interface design


Human-Swarm Interaction: Sources of Uncertainty
Sean Hayes, Julie Adams
	Defines swarms as >= 50 entities	
	Multiple sources of Uncertainty
		Physical state uncertianty
			Position uncertainty - Where each of the robots is, relative position
			Motion uncertainty - keeping track of speed and direction of members
			Aggregation and subgroup
				Cohesion uncertainty - how well is subgroup bound?
		Virtual state uncertainty
			Leadership uncertainty - which units are leaders?
			Influence uncertainty - how much influence do leaders have?
		Compound state uncertainty - combined virtual and physical
			Goal outcome uncertainty - will individuals contribute to goal?
			Role uncertainty - units may change roles due to physical or virtual state
			Dominance - attempts to influence others that may fail

Explict vs. Tacit Leadership in influencing the Behavior of Swarms
Saman Amirpour Amraii
	How does a teleoperated leader influence the swarm?
		My swarm isn't going to do this
		May provide bottleneck/single point of failure
	Consensus (tacit)
		No leader/follower distinction
	Flooding (explict)
		Leader influence takes precedence
	May be useful for control design of the compiler
	Flooding generally converges faster



This is a scratch file that I put stuff in when I remove it from the main paper. 

Don't expect it to be useful, or even to contain complete sentences. 

Motion "primitives" from Stupid Robot Tricks
Motion $\rightarrow$ moveArc, moveStop, moveForward, moveByRemoteControl, bumpMove

Orientation $\rightarrow$ orientForOrbit, orbitRobot, orientToRobot, matchHeadingToRobot, followRobot

Navigation $\rightarrow$ followTheLeader, orbitGroup, navigateGradient

Clustering $\rightarrow$ clusterOnSource, clusterWithBreadCrumbs, clusterIntoGroups

Dispersion $\rightarrow$ avoidRobot, avoidManyRobots, disperseFromSource, disperseFromLeaves, disperseUniformly

Utility $\rightarrow$ detectEdges

detectEdges is "detect if you are on the edge of the swarm" 

Utility classes are to be regarded with skepticism, they are like "miscelaneous" categories. 

$\Rightarrow$ iRobot swarm had directional IR signaling (quadrants) using signal strength to figure out range and bearing, so that's something I'll want to include or emulate in my system. 

$\Rightarrow$ I should probably include some form of charging that doesn't involve a lot of hands-on interaction with my robots. 

Computer is aware of meaning of gesture, locations of robots. 
Second assumption (global localization) may not hold. 
How can computer determine what programs or what parameters result in the completion of the task?

What are the tasks? Assume search and rescue domain, what are the tasks in USR? Search an area with good coverage. Report content of an area. Group at a location. Locate a specific resource. 

This could be situated at an intersection between planning and compiling, as the compilation might have to factor in elements of the known environment at the time of compilation. Since the actors are spatially situated, plans should incorporate spatial awareness. 

$\Rightarrow$ Why is almost everyone ignoring power supplies except as an afterthought? Not a computer science problem?


Notes on papers in verification of swarm robotics

ALLIANCE: An Arcitecture for Fault Tolerant Multirobot Cooperation
	Distributed team is needed for distributed tasks
	Decomposing a problem adds complexity
	Fault tolerance is point failures (individual robots) or communication
		Can occur any time, must adapt
	2 kinds of cooperation
		Intentional/Explict cooperation
			ALLIANCE
		Swarm/Ant-like cooperation
			Other papers
			"Such approaches usually rely on mathematical convergence
			results (such as the random walk theorem [14]) that indicate
			the desired outcome over a sufficiently long period of time. A
			key research issue in this scenario is determining the proper
			design of the local control laws that will allow the collection
			of robots to solve a given problem." <- good pointer on what to look into
			Assumes homogeneous robot hardware & software
				Which I'm aiming to not have
	Distributed AI (DAI) is apparently a field
		Negotiation, which fails under no communication
		Tends to be agents with perfect communication, not fallible robots
		
	"Our assumptions are as follows.
	1) The robots on the team can detect the effect of their own
	actions, with some probability greater than 0.
	2) Robot can detect the actions of other team members
	has redundant capabilities, with some
	for which
	probability greater than 0; these actions may be de-
	tected through any available means, including explicit
	broadcast communication.
	3) Robots on the team do not lie and are not intentionally
	adversarial.
	4) The communications medium is not guaranteed to be
	available.
	5) The robots do not possess perfect sensors and effectors.
	6) Any of the robot subsystems can fail, with some prob-
	ability greater than 0.
	7) If a robot fails, it cannot necessarily communicate its
	failure to its teammates.
	8) A centralized store of complete world knowledge is not
	available."
		Good list, I should probably have a similar one for my paper, early in the problem description
	Paper points out that recognizing that something is happening is really hard
		Overhead cam can fake this sense, but that's a bad thing to rely on
	ALLIANCE overview
		Robots have behaviors
		Behaviors have motivations
		Motivations can activate or deactivate behaviors based on percieved need
		Some low level stuff (avoid obstacles) may not ever turn off (always needed)
		Only does one thing at a time (except the low-level stuff)
		Impatience
			Increases desire to perform a behavior, when seeing that it needs doing and other robots are failing
		Acquiesence 
			Decreases desire to perform a behavior, to avoid all robots trying to do the same thing
			Triggered by getting a message from another bot saying "chill, I got this"
		Could communicate "I'm currently doing X" with local comms, and remember previously seen robots that were doing a thing
			Sounds like a job for quorum sensing
			"I've seen robot M, it was doing X" replications (and a timeout "Last time I saw M...")
		Robots can detect that their behaviors fail
			And then become reluctant to use them again
	Subsumption provides a pretty good way of composing behaviors
		The behaviors can then be reasoned about using e.g. random walk theories or the stochastic stuff from GCPR	
		
Self-stabilizing Systems in Spite of Distributed Control (Dijkstra! He has a way with titles.)			
	Assumes a Legitimate State, and machines on a sparse connected graph
	Global awareness of legitimacy is hard
		Perhaps "locally legit" is good, as long as moves tend to spread legitimacy rather than illegitimacy
	Assumption of connectivity may not hold, but how does it extend to severing/merging graphs?
	
Decentralized Model Predictive Control of Cooperating UAVs (Arthur Richards and Jonathan How)
	Assumes solid communication
	has better performance than a centralized version of the algorithim
	Can operate as an anytime algorithim, so only computes what is needed
	
Decentralized Task Allocation for Dynamic Environments (Luke B. Johnson, MS Thesis)
	Broadcast messages
	Message count should be minimized
	Sequential greedy algorithim
		All agents assemble a bid, and shares it with all others
		Whichever agent feels it can do a task best (max score based on its own knowledge) wins the bid
		Constraints based on interdependant tasks, whether the agents can actually be trusted to do the job
			Is this anything like the blockchain? Could the blockchain be used for this?
		Reaching a synchronized state with incomplete communication may be very slow or impossible. 
	Consensus-Based Bundle Algorithm (CBBA)	
		Each agent creates a bundle of tasks
		Tasks are added if the agent can outbid the current high bid
		Some additions may conflict (multiple agents may have better scores than current high bid)
		Conflicts resoved by communication to see if anyone outbids
			If so, agent must release task and ALL SUBSEQUENT tasks (tasks are on a path, and so have dependencies)
		So agents build a bundle, lose all, some, or none of it, then rebid from the end of whatever is left
	Asynchronous Consensus Based Bundle Algorithm
		Allows agents to enter and leave network
	This whole paper isn't really about task completion, just assignment	
	
------ 7/10/17 -----

Had some concerns about thesis once it was framed as a planning problem rather than a compilation problem due to the fact that planning has a long history, and a lot of work already done in it. 

As a planning problem, user input is desired world state (or can be transformed to desired world state). 

Can possibly converge to desired world state without knowing starting state, as in stochastic box-pushing example on wiki. 

Planner with unknown worldstate is using "coercion" to make the world match a known state before or in the process of operating. 

UI may convey how precisely user's input is supposed to be followed. 
  - Direct line to end point just means "go here", indirect, bendy line means follow this exact path
  - Do we need to get close, vs. jsut approximately hit the target? How approximately?

Could need a hierarchy of subplans based on what's available to the compiler, in terms of robot abilities
  - Heterogenous "processors" for a parallel compilation task. 

Program generation for swarms? Looking into Carlo Pinciroli's stuff

Do any systems allow specification of the desired end state of the universe, not the actions to take? Can the actions be transformed into the target end state, i.e. how do you know you're done?

Grammatical Swarm: The generation of programs by social programming
  Particle Swarm Optimization
  Each particle is a choice of program constuction rule
  Rules are in BNF
  Based on Grammatical Evolution
  Sort of a genetic algorithm, but the evaluation function/fitness adds or removes velocity to the particle swarm
  So all the particles converge towards the best solution found so far, but explore around it
  Genotype specifies a BNF grammar that permits derivation of a program
  Still has the problem that the encoding of the fitness function becomes the iterative target rather than the actual code of the solution. 

Property-driven design for swarm robotics
Manuele Brambilla, Carlo Pinciroli, Mauro Birattari and Marco Dorigo
  Top-down design, as opposed to code-and-fix
    Code and fix is expertise-dependent
  Formal spec of desired properties (but of the system, not of system + world (what I'm calling "the universe"))
  Applied using Discrete time Markov chains and probablistic computation tree logic
    Oh god more stuff to learn
  Protoswarm
    Assumes constant network connectivity and total spatial coverage
  Hamiltonian Vector Field methods
  	Specification of the system is as energy potentials and flows
  	Only works for spatially-organizing behaviors
  Automatic design methods
  	Evolutionary and reinforcement methods
  	Domain knowledge required, result may not be verifiable or generalizable
  Property Verification
  	The turing tarpit of formalisms, where you can prove you can do things, but not actually do them
  	Scaling issues

  Property-driven Design
  	1. Specify properties
  	2. Build a model
  		Programmer iterates on the model, checking that properties are verified
  		Final model 
  	3. Model is used as a guide to implement the swarm software
  	4. Run it on some real robots. May need some tuning. 

  So this is a design method, not an end-to-end automation, still has developer iterating on something
  I want to not have a designer, and leave the iterating to computers

  PCTL expands a Markov chain into a (potentially infinite) tree rooted at the initial state
    CTL can make assertions like "a given state will be reached" or "a given state will hold for a fixed time"
    PCTL adds probabilities to those assertions
    Potentially infinite trees? Put that in your limited system memory and smoke it. 

  PRISM model checker implements PCTL and DTMC (among others)

  Case study on aggregation
    Allows time bounds on behavior, so none of my "converges in ... finite time, I hope"
    Behaviors still hand-designed by the programmer, so while it can be checked fast, it still needs to be written by a person
      My stuff would be automatically designing the behaviors or behavior sets and triggers

  Property-driven design reduces the probability of designing the "wrong" system, but doesn't let you not design the system


Boolean Network Robotics as an Intermediate Step in the Synthesis of Finite State Machines for Robot Control
Lorenzo Garattoni 1 , Andrea Roli 2 , Matteo Amaducci 2 , Carlo Pinciroli 1 and Mauro Birattari 1
  Automated design of compact high-level representations of control software for robots
  Larger exploration footprint for automated design methods, compared to manual
  Automated design of FSMs for controlling the robots
  Boolean Network robots?
    Boolean network is a model of genetic regulatory networks
      I wonder if this relates to guards in GCPR?
        It sure looks like it
        Oriented graph with N nodes, associated with a boolean value and boolean function of inputs to node
        Various update schemes
        To control a robot, some nodes are input and output nodes
        Input node boolean values are imposed by sensor precepts, not other nodes
        Output nodes control robot actions (motor vel, etc. or actions)
        Yeah, this smells like an isomorphism. 
    Can be analysed as dynamic systems
    Automatic design shapes network dynamics in limited areas of state space
    State clusters are associated with behaviors of the robot
    Map from clusters to FSM states to get a formal and explainable framework

  Calls out the existing problems with evolutionary controllers
    Have to constrain FSM size or you get really hairy, uncompact representations
  ANNs have problems with explainability

  Example programs use a constrained network size. 
  Rather than having all the nodes of the network be behavioral primitives, and sequences of boolean actions control those, the boolean network acts as an action selector. 
  Constant connectivity, intially random, three incoming inputs to each node. No self-connections.
  Flips bits at random in the boolean functions of the nodes, and only keeps the ones that work at least as well as the current best. 
  I bet boolean networks are stupid-fast and compact to represent in programmable hardware. 

  This case isn't specifying the desired behavior from a user input
  It also requires a lot of simulated runs to develop the working networks
    It's stochastic gradient descent operating on a binary genome, or evolution again. 
    No crossover, though. Probably for the best, that would transplant part of the FSM into another part. 

  Constrained to dealing with booleans
    Not really that much of a constraint, you can represent floats with booleans, at a (probably high) cost in complexity. 
    Evolving sub-modules might help reduce this, since a subnetwork can be reduced to a boolean network node itself. 


Finite State Automata Synthesis in Boolean Network Robotics
L. Garattoni, C. Pinciroli, A. Roli, M. Amaducci, and M. Birattari
  Still an evolutionary method, still needs a fitness function defined for it
  Also all the examples are for single-robot cases, no assumptions about interaction
    Binary robots could have senses for other robots, and at some levels of abstraction, quorum sensing
  Does permit dynamic behaviors, and so dynamic environment and systems
  "FSA asan indirect product of the design process of BN-robot systems and, hence, we
do not have the problems of representing automata in terms of genomes and
constraints."
    No, you represent it in terms of a binary string that evolves under control of a fitness function, though...

Recent Advances in AI Planning
Daniel S. Weld
  1999, talking about the last 5 years in planning 
  2-phase GRAPHPLAN
    Apparently very fast
    Detail level is a bit out of scope for my work at present, seems to cover the textbook sections I read
  Compiling planning problems into propostional formulas using SAT algorithms
  Talks about planning based on a known inital position of the world
  Calls out problems with universal quantifiers 

A Survey of the Seventh International Planning Competition
Amanda Coles, Andrew Coles, Angel García Olaya, Sergio Jiménez, Carlos Linares López, Scott Sanner, Sungwook Yoon
  Constrained planning domain description language (PDDL)
  Fixed domains, so people are running with a specific description of a specific domain
  various constraints in various tracks (optimality, uncertainty, etc.)
  Paper doesn't cover how things worked aside from what won and what techniques they were using


What I'm doing isn't exactly classical planning, because it's the generation of behaviors and the conditions under which they are to be executed, rather than a sequence of actions. No temporality in my "plan". Also, I don't assume that once all the behaviors have been executed, the desired world state holds. Instead, execution of at least some of the behaviors by at least some of the agents is intended to converge to the desired world state, but some behaviors may not be executed by some agents, and some agents may execute no behaviors (because they're broken). 

While we're talking weirdness, any binary sequence could be a representation of a binary network's binary functions, and so e.g. the complete works of Shakespear in ASCII, combined with a given connectivity, might do something cool.

SWARMORPH-script: a language for arbitrary morphology generation in self-assembling robots
Anders Lyhne Christensen, Rehan O’Grady, Marco Dorigo
  Governs self-assembling robots
  Morphology scripting, inter-robot lcoal communication

AutoMoDe-Chocolate: a Method for the Automatic Design of Robot Swarms that Outperforms Humans
G. Francesca
   Previous methods: Vanilla and EvoStick
   Vanilla beats EvoStick, humans beat all
   Chocolate = Vanilla + better optimization algorithm
   Design of collective behavior, but designer eventually has to specify the behavior of individual robots
   "Presently, no general approach exists to derive the individual behavior of the robots from a desired collective behavior"
      Well, that's encouraging to me...
   1. Specification
   2. Development using simulation
   3. Deployment onto a swarm
   AutoMoDe (2014) defines a program by composing probablistic FSMs
   Vanilla specializes AutoMoDe for the E-puck
      Shouldn't define the problem for specific homogeneous collections of robots
   Comparison with Vanilla and Evostick was on aggregation and foraging
      I'm assuming that things like aggregation were defined as primitives I can compose
      Foraging is a "find the box/target area" kind of thing, one step in performing a task
      So I think I'm looking at a level up from this
   5 methods on 5 tasks
      Fixed tasks, rather than open tasks as defined by the user
   Mentions work on task allocation via reaction-diffusion
      Works well with local state, so robots who are well-situated to solve a problem volunteer for it
      The idea of volunteering based on local information is probably a good way to look at it, in opposition to assignment by a central authority. 
   4 design methods
      Vanilla
         Assembles pre-exising modules into a PFSM
         Modules might have some parameters that affect their functioning
         Behaviors 
            Activity the robot can perform
         Transitions
            Control switching behaviors based on a condition or event
            Boolean, based on input values
         "The six behaviors are:
exploration, stop, phototaxis, anti-phototaxis, attraction, and repulsion. With the
exception of stop, these behaviors include an obstacle avoidance mechanism. The
six transitions are: black-floor, gray-floor, white-floor, neighbor-count, inverted-
neighbor-count, fixed-probability."
         Up to four states with up to four outgoing edges
         Optimize the expected value of a task-specific performance measure
         F-Race optimization algorithim, whoever does the task fastest is fittest
            Chocolate uses iterated F-Race
                Each iteration resamples search space with a distribution that favors the best performers on previous iterations
                This is starting to sound a lot like an evolutionary method
      EvoStick
         Evolutional method, generates feed-fwd ANN with no hidden nodes
         Inputs are robot sensors
         Outputs operate on the wheel speeds
            So the only possible actions are changing the position of the robot
      U-human
      	 Unconstrained human
      	 Person writing some code, no constraint on what they write
      	 Testing in ARGoS, but not the robots, like the automatic methods
      	 C++ class that operates on the inputs of the robot and provides logic for controlling the robot
      C-human
         Human who has to use the Vanilla control architecture and modules
         Human does what the Vanilla optimization algorithm would have to do
            This sounds like setting the human up for a beating, simply because they can't search the space as fast
         Again, only four states and at most four transitions out of each one
   5 conditions
      Shelter with constrained access
      Largest covering network
      Coverage with forbidden areas
      Surface and perimeter coverage
      Aggregation with ambient cues
         These are more complex tasks than my primitives, and possibly more complex than my tasks for the UI
   Vanilla and EvoStick can create solutions in 2h20m, so humans were given 4h, since they have to watch sims, and the software doesn't. 
   EvoStick beats the heck out of everything, all the time... in simulation
      It can't cross the reality gap, so it's probably overfitting
      In reality, it gets beat nearly all the time by something
   C-human beats U-human, which is surprising, but may be up to reduced variance due to reduced chance for bugs
   Chocolate beats humans, more in simulation than in reality, but usually in both
      Chocolate also has good reality-gap-crossing results

AutoMoDe-Chocolate: automatic design of control software for robot swarms
G. Francesca, M. Brambilla, A. Brutschy, L. Garattoni, R. Miletitch, G. Podevijn, A. Reina, T. Soleymani, M. Salvaro, C. Pinciroli, F. Mascia, V. Trianni , and M. Birattari
   Seems largely like a restating of the previous paper? Maybe that was a preprint. 

An Experiment in Automatic Design of Robot Swarms: AutoMoDe-Vanilla, EvoStick, and Human Experts
G. Francesca, M. Brambilla, A. Brutschy, L. Garattoni, R. Miletitch, G. Podevijn, A. Reina, T. Soleymani, M. Salvaro, C. Pinciroli, V. Trianni, M. Birattari
   14-page version of the two papers above

Boolean network robotics: a proof of concept
Andrea Roli and Mattia Manfroni, Carlo Pinciroli and Mauro Birattari
   Covers a lot of the same ground that the previous binary network paper I listed covers. 
   More mathematical explanation of the error/fitness function
   The evaluation heuristic from iterated F-Race sounds like it would be great for this
      Assuming that more-similar bitstrings have more-similar behavior, then selecting from a distribution that favors the elite examples would tend to generate more elite examples. 
   The single-bit-flip approach that was used is pretty close to this anyway, as it uses minimal perturbations
   Detail on training, used a shaping approach, where first phototaxis was trained, and then a handclap triggered antiphototaxis
      Longer runtime with the clap

ARK: Augmented Reality for Kilobots
Andreagiovanni Reina, Alex J. Cope, Eleftherios Nikolaidis, James A.R. Marshall, and Chelsea Sabo
   Similar design to my system
   Automates some aspects of e.g. identifying the robots
   Highly tied to the Kilobot platform
   I should certainly cite it, though

Towards a swarm of agile micro quadrotors
Alex Kushleyev, Daniel Mellinger, Caitlin Powers, Vijay Kumar
   Seems unrelated

Searching for swarm robot planning gets a lot of hits based on PSO, but I want the swarm on a table, not in the planner. 

I'm getting the impression that a multi-agent planner might assume much less stochasticity on the part of the agents than I am actually going to have in my system. 

Interactions among Autonomous Planning Agents
Frank Von Martial
   Autonomous agents create their own plans independently
   Plans are Executed in a common environment
   Paper proposes a taxonomy, harmful/favorable interactions
   Implies a dynamic environment
   Has been modeled as a single multiagent plan with conflicts, which can be resolved
   Communication can be present or absent
   Assumptions
      the agents are "intellegent", which is a hell of an assumption
      Agents have different skills
      Agents can include each other's actions as part of their plans
         Parenthetically notes as "(multiagent planning)", which means what I'm planning isn't
      Agents can communicate actions to each other
      Agents are honest and benevolent
         Don't lie about actions, don't want to harm each other
   I don't think this is the model I'm looking at, since I want the total behavior to be sorted by the compiler/planner (complanner? Planpiler?) rather than by an iterated negotiation among agents

Multi-Agent Planning under Dynamic Adaptive Autonomy
K. S. Barber and D. C. Han
   Autonomy levels characterize agent's role in organization of agents
   Agents can change autonomy levels dynamically
   Concurrent actions by multiple agents
   Agents can enter into autonomy agreements with each other to attain goals they otherwise can't reach
      e.g. a ship in a naval formation can't change position with getting clearance (the agreement) to do so. 
   The determine if they need these agreements via a 2-stage planning process
      1. Come up with goals based on available subgoals and intended goals
      2. Filter the available operators by autonomy level, and plan using the remaining ones. If needed, try to acquire higher autonomy levels
   
I think a lot of the problem I'm having with planning here is that there are some actions that are going to be ongoing things, which overlap each other, rather than discrete operations in a plan. Some planners do talk about contingencies, but I'm thinking of stuff like random walking forever, as a plan element. It (eventually) has a probablistic postcondition of having visited everywhere in a bounded area, but it doesn't synchronize on that point with anything else, because it could take almost any amount of time. 

Is It an Agent, or Just a Program?: A Taxonomy for Autonomous Agents 
Stan Franklin and Art Graesser 
   Agents need to be able to execute autonomously and have domain-oriented reasoning
   Agents need to get data from their environment (which may be virtual)
   Agents have goals
   Not really useful to me, but could be interesting to read some other time. 

Robot Path Planning using Particle Swarm Optimization of Ferguson Splines 
Martin Saska, Martin Macas, Libor Preucil, and Lenka Lhotska
   Splines for indivisual robot movement
   Cool result, but got into my search due to mention of particle swarm, not robot swarm

Cooperative Mobile Robotics: Antecedents and Directions
Y. UNY CAO, ALEX S. FUKUNAGA, ANDREW B. KAHNG
   1995, said field of multiple cooperating robots was still in its formative stages
   Task may be too complex for one robot
   Fault tolerance
   Insight into social theories and life sciences 
   Cooperation is the use of some mechanism of the system to increase total utility on a task
   Dudek et al. (1993) taxonomy on SWARM and Mataric's Behavior based work
   Common problems
      Traffic control of swarms
         Geometric problem in configuration spacetime
         Behavior-based collision avoidance is fine, if you're not restricted to roads
      Box-pushing cooperative mainipulation
         As a study fo task allocation, fault-tolerance, reinforcement learning  
         " Cooperative manipulation of large
objects is particularly interesting in that cooperation
can be achieved without the robots even knowing of
each others’ existence (Sen et al., 1994;  Tung and
Kleinrock, 1993). "
      Foraging
         Stigmurgy, chain formation and passing
   So how should cooperation arise?
      "Note that
certain basic robot interactions are not task-performing
interactions per se, but are rather basic primitives upon
which task-performing interactions can be built, e.g.,
following ((Connell,  1987;  Donald et al.,  1994) and
many  others)  or  flocking  (Reynolds,  1987;  Mataric,
1994a)."
      Group Architecture
         Abilities of robots
         homo/heterogeneity
         Central or not
         Task coverage (parker 1994)
            Ability of a given team member to do a task
            Maximal in homogeneous groups
         Communication structures
            Via environment, e.g. stigmurgy
            Via sensing, robots can tell each other from environmental obstacles
               Flocking and pattern formation
            Via communication
               Explicit sending and receiving of messages
               Signboards, diffusion of messages
         Modeling of other agents
            Box and bar pushing without communication
      Resource conflict resolution
      Origins of cooperation
         Eusocial is emergent, gentically programmed group behaivor 
         Cooperation is an intentional desire to cooperate to maximize individual utility
         Not intrested in explicitly designed cooperation (good, I'm not either)
         Learning control parameters to maximize perceived utility
            Cites Yanco & Stein 1992!
      Geometric problems
         Path planning, formations, patterns in space   
         Formation and marching are a useful tool for caging manipulation
         Amount of information available affects solubility of problem
         Formation is optimally solved in computational geometry as "geometric matching under isometry" 

SWARM ROBOT MATERIALS HANDLING PARADIGM FOR A MANUFACTURING WORKCELL
Keith L. Doty  and Ronald E. Van Aken 1993
   Paper is working on materiels handling to work areas for some process
   Adaptable in the face of changes to the processs
   Devices that need materials emit brodcast requests
   Robots detect requests, can load and unload machines, and carry material
   Machines take parts and finsih them
   No learning
   Machines ask for materials, but aren't told if it's on the way
   Robots wander randomly when they're not tracking a request for material RFM
   Not competetive with actual scheduling, but functional

Path Planning and Motion Coordination in Multiple Mobile Robot Teams
Lynne E. Parker
   Becomes a problem in my system when the user specifies waypoints
   Don't want to wedge all the robots when passing through a narrow area
   But also don't want to plan the paths and timings of all robots and encode in programs for each robot
   Need a reactive approach
   General optimal planning is PSPACE-hard
   A* exponentioal in dimensions of configuration space, and so in number of robots
   Decoupled planners plan individually, and then resolve collosions/conflicts
   Motion coordination doesn't need advance planning for swarming or flocking, but does need reactivity
   Coupled, centralized
      Whole swarm considered as a composite system, classical planning 
      Potential fields can be used (could also be used decentralized and decoupled)
      Tend to computational intractability without using some form of dimensionality reduction
   Decoupled
      Prioritized or not
      Path coordination
         Plans paths and then plans velocities
         So where robot paths intersect, they miss each other in time/space
   Motion coordination
      Reactive, dealing with problems while moving on the path
      Traffic controls, like yeild to oncoming traffic
   Table 1 is cool, doesn't copy/paste well, lists swarm behaviors

New Potential Functions for Multi robot path planning : SWARM or SPREAD
Sung-hwan Kim, Gyungtae Lee, Inpyo Hong, Young-Joo Kim, Daeyoung Kim
   Artificial potential fields with priority selection between robots
   New potentials based on priority
   Avoids local minima in APF
   Distance to goal is used as a multiplication factor so that goal is always lowest point
   Potential field is calculated per-robot, rather than all over 

Multi-Robot Path-Planning Based on Implicit Cooperation in a Robotic Swarm 
Guillaume Beslon, Frederique Biennier, Beat Hirsbrunner 
   Reactive material handling agents in a conveying task
   Stigmurgic strategies
   Each agent has a beacon
   Each agent beacon re-emits any beacon that it detects
   So shadows of machines and agents are filled in by the beacons on those agents
   Front sector of mobile agents doesn't emit, so they don't do head-on collisions
      Also, they random walk when shadowed by another agent, avoiding collisions

Handbook of Robotics, Ch 40 Multiple Mobile Robot Systems
Lynne E. Parker
   Makes distinction between collective swarm and intentionally coooperative systems
   I'm doing a more collective swarm than intentionally cooperative 
   Has similarity to elements of the Parker paper above, in terms of taxonomizing


From real robot swarm to evolutionary multi-robot organism
S. Kornienko, O. Kornienko, A. Nagarathinam, P. Levi
   Jasmine robots, and some talk about self assembly, which Jasmine can't do
   Jasmine docking guided by IR sensors
   Planar self-assembly via IR signalling
   Robots controlled by petri-net, has a high-level description of the robots including the "genes" for the full organism as well as the individual robot

No Robot Left Behind: Coordination to Overcome Local Minima in Swarm Navigation
Leandro Soriano Marcolino and Luiz Chaimowicz
   Some robots are rescuers, help others out of local minima
   "In  order  to  compute  the  gradient
forces,  robots  must  know  their  global  position.  This  is  a
strong assumption, but it is generally accepted when dealing
with  swarm  navigation."
   I'm not assuming that
   Robots do gradient descent/ascent to the zero isocontour of a 3D surface whose value is less than zero inside its boundary and great outside its boundary
   Rescuers can go push stuck robots by approaching them (altering the local potentail field)
   Trapped robots repel all non-rescuers, so local minima don't fill up with robots
   Rescuers self-elect, trapped robots approach rescuers, rescuers retrace path to lead

A Multiagent Planning Architecture
David E. Wilkins and Karen L. Myers 1998
   MPA defines a uniform interface for agents
   Shared plan representation
   Metalevel agents that work on the interactions between other agents
   Emphasis on application to large scale planning
   Planning cell
      Collection agents
      Two distingiushed agents
         Cell manager
            Composes cell from agent pool
            Distributes task
         Plan server
            Warehouse of plan parts and information
   Act formalism for storing shared plan representation
   Message passing among agents
   This is a multiagent planner in that it uses multiple agents to create a plan, not because it makes plans for multiple agents

IMPACTing SHOP: Putting an AI Planner into a Multi-Agent Environment 
Jurgen Dix, Hector Munoz-Avila, Dana S. Nau, Lingling Zhang 
   Multiple agents
   Multiple infromation sources
   Mixed symbolic/numeric reasoning
      Pretty normal for planners by 2k2, isn't it?
   Paper doesn't address multiple planning agents
   Shop does hierarchical task network planning

ZEUS: A Toolkit for Building Distributed Multi-Agent Systems
Hyacinth S. Nwana, Divine T. Ndumu, Lyndon C. Lee & Jaron C. Collis
   Seems really unrelated, largely about building pure-software agents for undefined problems
   It also seems a lot like trying to implement web services. Like, call programs on other computers to do tasks
   I'm not sure there's any reason to be talking about this as agents

What was the point of agents anyway?
   Something to do with Minsky's Society of Mind? 
   Agent-based systems appear to have some idea of seperation of concerns for agents, with each one having a particular responsibility. 
   Not seeing any reason this couldn't be done with e.g. a library...
   Natural-language interaction, with a conversational agent, but again, this is a UI concern
   Agents can drive themselves, based on sensing their environment and context
   Agents can act without people controlling them

Integrating Agent-Based Mixed-Initiative Control With An Existing Multi-Agent Planning System
Mark Burstein, George Ferguson, and James Allen
   Mixed-initiative control 
   Wraps a non-agent planner in an interface so other agents can communicate with it
      Cool and all, but RPC doesn't deserve this level of discussion
   Multi-agent planning in general appears to refer to planning by multiple agents, not for them

I should check that I'm not too close to Mataric's behavior-based synthesis of collective behaviors (1992-1994)

Decentralized Controllers for Shape Generation with Robotic Swarms
Mong-Ying Ani Hsieh, Vijay Kumar, Luiz Chaimowicz
   Robots converge to a specific class of simple closed curves
   Local sensing only 
   "Ogren et al. relaxed this assumption in the
development of coordination strategies for a group of
unidentified, holonomic robots. 15 Similar approaches for
multi-robot manipulation were presented by Song and
Kumar 16 and Pereira and Kumar 17 respectively. Chaimowicz
et al. extended these approaches to arbitrary shapes and
established convergence to patterns that approximate the
desired shape. 18"
   These approaches might be useful as primitive behaviors the planner can invoke


Generation of desired emergent behavior in swarm of micro-robots
Sergey Kornienko and Olga Kornienko and Paul Levi


Should add citations for Miniman and MiCRoN
   MiCRoN is floor-powered, optically tracked from above, has a manipulator finger
Things to look into: 
Multi-objectivization (Trianni and Lopes-Ibanez, 2014) 
Novelty Search (Lehman and Stanley 2011, Gomes et al 2013)
Heirarchical decomposition (Duarte et al, 2014) 
   Apparently untested on robots, and the decomposition is designed for the task by the programmer

From Local to Global Behavior in Intelligent Self-Assembly
Chris Jones and Maja J. Mataric
   Transition Rule Set compiler
   Takes a desired structure for a self-assembling robot, outputs a set of rules
   Operates on a grid, with local sensing
   Uses a state transition set
   Only covers self assembly
   Consistent rule sets
      Consistency requires that the spatiotemporal constraints to construct the figure are properly set up and that contraditory transistion rules not become active at the same time
      Inconsistency can cause e.g. building the perimiter of a filled figure without filling it, making it impossible to finish. 
   Limited to connected figures. No islands, no islands in holes in the figure. 
   Does do some of the same things I want to do
      User specification converted into local rules for robots
      mobile robots
   Also doesn't do some things I want to do
      Strictly a morphological language

Designing Collective Behavior in a Termite-Inspired Robot Construction Team
Justin Werfel1, Kirstin Petersen, Radhika Nagpal
   Given a physical structure, output a set of rules
   Local sensing
   Communication through the environment
   Strictly a morphological language, again

Differences from what I'm proposing
   I'm proposing a realtime user interface for this operation
   I'm proposing open-ended tasks, not only construction
      Could probably generalize to construction, but the UI would have to support it
   User interface elements of project are unrelated to previous compiler work

Goals as Parallel Program Specifications
Leslie Pack Kaelbling 1988
   Programmer specifies agent's behaivor using symbolic goal-reduction rules that are compiled into a program
   Realtime, dynamic domains permitting parallel actions
   Mentions Georgeff & Lansky Reactive Planning (1978)
      Does runtime interpretation of highly conditional user-specified plans
   Gapps model of computation
      Agent transduces stream of input into stream of output
      Small upper bound on time for transduction ("reaction time")
      Rex language
         takes program spec as input
         generates description of a synchronous digital circuit with delay components to satisfy spec
         circuit operates on a clock
         Used to program "the SRI robot", maybe Shakey?
      Computations as a perception and action component
         Perception component maintains state
         Action component is stateless, fired by Perception component
         This seems a lot like GCPR with ROS callbacks operating on it...
   Goals
      execution
         do(g) - instant action g, just do it
      Maintenence   
         maint(h) - if h is true, act to keep it true as long as possible
      Achievement
         ach(i) - make i true ASAP
      Set of goals is boolean operation of primitive goals
      Not-acheiving X is the same as maintaining not-X and not-maintaining X is the same as acheiving not-X (they are dual)
   Saying an action leads to a goal
      Action is a correct step toward satisfying a goal
      Doesn't appear admit formalization in a domain-nonspecific way
      Seems to require some way of representing the leads-to structures of the domain...
   Goal g can be reduced to g' if any action that leads to g' will lead to g
   "Note that the conditions in a program need not be exhaustive-satisfaction does not require that there be an action that leads to the goal in every situation, since this is impossible in general."
   When more than one condition and associated action is true (leads towards goal), execution of the program can pick one at random
   This is a LOT like GCPR
   Gapps programs
      set of goal reduction rules and a top-level goal-expression
      Paper defines operations on the expressions of a goal
   Reduction rules match goal expressions if their patterns can be "unified in the current binding environment"
   The binding environment is bindings of the compile time variables in the patterns of the expression under evaluation
      If the patterns match, Gapps sets up a binding environment to evaluate the rule
      Example is that acheiving the goal at(p) with the variables dist-err and angle-err reduces to if not facing(p)angle-err acheive facing(p) angle-err acheive moved-toward(p) distance-error
         In otherwords, if you're not at p, face p based on the error in your angle and move towards it based on the error in your distance from it
         At... runtime, I think, p would be substitued (bound) with a place to go
   Compiler expects that acheiving two conjunctive goals reduces to if you have one goal, maintain it and acheive the other. 
      This seems prone to combinatorial explosion in the face of multiple goals
   Supports priority lists for goals, and prioritzing methods of acheiving the goals (if one is better somehow)
      Can also prioritize acheiving a set of goals, but less-preferred goals are subsets of the set of decreasing size
         So "get me a pizza, or if you can't, get me pizza ingredients, or at least get me some of the pizza ingredients"
   Actions can be merged
      good for merging e.g. vector velocities
      Have to tell the system that velocities can always be merged, and then define how to merge them e.g. averaging

Ok, so Gapps has programs that are evaluated kind of like the way I was planning to use GCPR, but doesn't have a UI, and assumes it's being developed by a programmer, not used by a normal user. 

"From Local to Global Behavior in Intelligent Self-Assembly" has compilation of a desired end state into a set of rules for a FSM, but operates in a gridlike world and is for construction of a set of figures, rather than general action. 

"Designing Collective Behavior in a Termite-Inspired Robot Construction Team" has compilation of a desired end state into rules for local sensing and action, but for a domain consisting of construction. Not intended for real-time-like commands either. 

Looks like people either have compilation into a rule set from a high-level representation, but for closed domains, or have software development required of the user?

7/24

Human Interaction With Robot Swarms: A Survey
Andreas Kolling ; Phillip Walker ; Nilanjan Chakraborty ; Katia Sycara ; Michael Lewis
http://ieeexplore.ieee.org/document/7299280/

Survey of Human-Swarm Interaction (HSI)

Explicitly indicates that swarms are distributed, individual robots might not be effective

Reasons to have an operator
	"1) recognize and mitigate shortcomings of the autonomy; 2) have available “out-of-band” information not accessible to the autonomy and that can be utilized to increase performance; and 3) convey changes in intent as mission goals change."

Paper outlines these as reseach questions
    "How do the properties of the communication channel between operator and swarm affect HSIs, such as the ability to observe and control the swarm?"
    	I approach this with the swarm vs. cloud representation, the "no visible robots" case would also be in this area
    "How can an operator observe a swarm and its dynamics?"
    	Top-down view...
    "What are the different control methods used, and how do they affect the ability of an operator to control a swarm?"

    "What is the relevance of the notion of levels of automation in HSI and how has it been exploited and studied?"

    "How do swarm dynamics affect the ability of the operator to control the swarm?"

There are a lot of swarm taxonomies
	This paper discusses swarms based on methodologies, tasks, and algorithms
	List bioinspired, control theoretic, amorphous, and physics
		I touch on all of those except control theoretic
			Ionnas's work is control theoretic, though
		Control theory has formal methods for defining whether human control input is theoretically possible for a task
			I think programming via desired end states might sidestep this, unless you can't draw the result desired...

Mentions use of belwethers in swarm control

Task type list is of interest as "primitive" behaviors
	Aggregation and Rendezvous
	Deployment and Area Coverage
		Including art gallery problem
	Flocking and Formation control
		Control theory shows up a lot here
		Boids
	Foraging and transport
		Including minimal paths
		Caging manipulation

Cognitive complexity
	Fan-out and neglect tolerance in independent tasks
	"A different form of control, such as designating a region to be searched by drawing it on a map, can command an arbitrary number of robots with a single operator action, as long as the interactions between the robots (such as preventing collisions) can be handled autonomously. In this case, the number of actions the operator must take are independent of the number of robots, and thus, control is O(1) , allowing one (or a fixed number of) human operator(s) to control any number of robots. "
		That's what I'm shooting for
	Useful point is that if the user has to coordinate inter-robot interactions, scaling can be exponential
		So REALLY don't do that

Communication 
	State has to get back to the user somehow
		I've just kind of assumed I have a magic eye in the sky
		Although the zero robot case is of interest because it assumes your magic eye is nearly blind
	Work has been done on bandwidth as far as receiving robot updates
		don't have to have perfect data on the whole swarm
		this supports e.g. the use of the cloud view
	Proximal interaction is cool, but I'm not doing it

State Estimiation and Visualization
	-> I should include a section on this <-
		few, many, cloud, no visuals
	"For example, a visualization of forces might aid comprehension for an operator familiar with attractive and repulsive forces. Very little research, however, has investigated these ideas."
	Centroid + std Dev is sufficient for target search and navigation
		S. Nunnally, P. Walker, A. Kolling, N. Chakraborty, M. Lewis, K. Sycara, M. Goodrich, "Human influence of robotic swarms with bandwidth and localization issues"
		So my cloud model is supported

The control types they identify are 
    "switching between algorithms that implement desired swarm behaviors;"
    "changing parameters of a swarm control algorithm;"
    "indirect control of the swarm via environmental influences;"
    "control through selected swarm members, typically called leaders."
    Heh. Select None. I'm having the compiler select parameters and algorithms
    	This saves the operator from having to know how the various algorithms will cause the swarm to move/behave
    Z. Kira, M. Potter, "Exerting human control over decentralized robot swarms", Proc. 4th Int. Conf. Auton. Robot. Agents, pp. 566-571, 2009.
    	Looks interesting, in that there are virtual particles exerting pull on robots
    		Would have to check in simulation to get the right positions, and then deploy those to robots
    		Which sounds like a nightmare to make reactive in a dynamic environment
    Personality of robots + hot/cold regions in environment
    	H. Hexmoor, B. McLaughlan, M. Baker, "Swarm control in unmanned aerial vehicles", Proc. Int. Conf. Artif. Intell., pp. 911-917, 2005.
    	Seems to assume localization
    D. S. Brown, M. A. Goodrich, "Human-swarm interactions based on managing attractors", Proc. ACM/IEEE Int. Conf. Human-Robot Interaction, pp. 90-97, 2014.
    	Flocking-task only
    Environmental influences
    	Nice if you can influence the environment
    	B. Walter, A. Sannier, D. Reiners, J. Oliver, "UAV swarm control: Calculating digital pheromone fields with the GPU", J. Defense Model. Simulation: Appl. Methodol. Technol.,
    		50k drones, in simulation
    Leaders/belwethers 
    	persistent, essentially the user teleoperators a leader or leaders
    	Can also have no specific leader, but joystick an attractor or overall swarm desired direction


Research Advance in Swarm Robotics
Ying Tan, Zhong-yang Zheng
	Focus on bioinspired
	V. high-level overview, cites some stuff that might be useful if I have to e.g. justify that a particular technical challenge is surmountable

"A multi-robot coverage approach based on stigmergic communication." Multiagent system technologies (2012): 126-138.
Ranjbar-Sahraei, Bijan, Gerhard Weiss, and Ali Nakisaei. 
	Stigmurgic communication for area coverage and intruder detection
	Mentions that people have done stigmurgy with RFID and with ethanaol
	Hasn't been implmented for real yet, but simulation looks good
	Coverage based on driving in a circle and detecting when you cross over another robot's trail. 
	I could actually do this based on an overhead projector and color sensors on the robots, or the top camera looking at the color of the white areas of the april tags to determine "pheremone concentration" over the area where the robot is currently located

An Architecture for Swarm Robots
K.A.Hawick, H.A.James, J.E.Story and R.G.Shepherd
	PIC, TINI (probably not avaialable anymore), bluetooth module
	Also essentially a souped-up toy
		Used Cybot bases
	Price breakdown as of writing, in UK pounds:
		Cybot		42
		TINI 		70
		PIC 		 7
		WaveLAN    110
		misc.       18
		Total      247
	This was in 2k2, so 15 years old

Formica 
	http://warrantyvoidifremoved.com/formica
	15-24 UK pounds
	Cites a lot of other robot swarms
	DIY motor drivers, P & N MOSFETs
		Really clever merger of dual motor drivers using 6 MOSFETs instead of four, the H-bridges have a common center leg
		4 drive lines because of using P & N MOSFETs so the outside legs have common drive pins
	IR sensors
		Distance sensing to obstacles based on intensity of reflection, this is also really clever
	no wireless, at least no radio, can do IR comms
	MSP430 controller
	Direct drive by pager motors
	The entire electrical design of these things is brilliant


An Overview of Physicomimetics
William M. Spears, Diana F. Spears, Rodney Heil, Wesley Kerr, and Suranga Hettiarachchi
	robotic behaviors based on solids, liquids, and gases
	also known as artificial physics
		Doesn't have to be natural physics, can have different fields and so on
	Robot has to sense enough to detct "forces" and move enough to respond to them
	Solids and crystals for formations
		Synthetic aperature radar, beamforming
	Solid/liquid transition is controlled by a parameter balancing attractive and repulsive forces
	Gases for coverage and dispersion
		Dominated by repulsive forces
	By giving robots color plus different forces based on color, square lattices can be formed
		mimics sodium/chlorine interaction in forming salt crystals
	All done with local forces
	Rotation of moving crystal through obstacle field is an emergent quality
	Liquids can also flow through obstacles while maintaining connectivity
		Connectivity draws a lot of research, so this is a really cool result
	Adding brownian motion to gas gives it better area coverage for a sweeping traversal of an area
	Applied genetic algorithims to tune parameters
		Got good results even with losing up to 75% of the robots
		Or with losing 75% of the sensor accuracy	


Off topic, is firefly synchronization applicable to underwater gliders?
	Surface, and you can reach anyone already on the surface
	So surface, wait a random amount of time, and dive, emitting a "We dive!" signal when you do
	If you hear a "We dive!" signal, dive immediately
	Stay down for a fixed period
	I think this will eventually collect all the gliders into one synchronous swarm

Can I get battery level monitoring in my system? Maybe an ADC-capable GPIO?

Range-Sensor Based Navigation in Three Dimensions (1999)
Ishay Kamon, Elon Rimon, Ehud Rivlin
	3DBug
	Straight line to the target unless there's an obstacle
	Minimal reactive data gathering about obstacle during avoidance
	in 3 dimensions, so not a plane bug
	Bug algos in general augment local planning with a global convergence criterion
		Bug moves straight towards target (global convergence)
		When bug hits an obstacle, it switches to following the obstacle edge
			"leaving condition" causes bug to leave the edge (e.g. moving along the edge puts you further from the target)
				My example here is bad because it traps the bug in concavities
			If the bug loops (uh, detecting this might be an open question...), it decides it can't reach the target
		To decide unrechability on a 3D surface, the bug needs to check the whole surface
	3Dbug uses position and range sensors
		Localization may not be a thing...
	Cool, but makes assumptions that don't apply in my case

A Pursuit-Evasion BUG Algorithm (2001) (were bugs hot at the turn of the century?)
Stjepan Rajko, Steven M. LaValle
	PE-BUG
	Not just navigation
	No map
	Pursuer needs to find evaders
		Can see walls, and see moving evaders
	Does not require pursuer to localize
	Pursuer finds boundaries of areas it can't see by looking for discontinuities in depth graph
		This is handy for one of my personal projects!

Path-Planning Strategies for a Point Mobile Automaton Moving Amidst Unknown Obstacles of Arbitrary Shape (1987)
I. Vladimir, J. Lumelsky, and Alexander A. Stepanov
	The original bug paper
	Limited to things homeomorphic to a plane
	Provable reachability is interesting
	
Performance Comparison of Bug Navigation Algorithms
James Ng & Thomas Bräunl
	Talks about target expressed in distance and bearing
	So if the robot knows its heading, then maybe global location isn't needed
		Original bug paper used global location to determine if the perimeter of the object had been circumnavigated
	Turns out that a bug algorithm, as originally designed, isn't in itself sufficient to follow a wall
		It assumes "wall follow" is just a thing you can do
	Some practical extension of bugs to real robots
		e.g. approximating points, rather than requiring that it hit the exact coordinate
		imperfect sensing
	Sensor noise can cause bugs to not terminate, or do a bad job (incorrect termination, termination too far from target)

I-Bug: An Intensity-Based Bug Algorithm (2009)
Kamilah Taylor and Steven M. LaValle
	No precise position, no coordinate, no time, no odometry
	Signal intensity function from source
		This is handy for swarms that can do gradient signalling
	Level of signal doesn't have to be circles, but has to be topologically equivalent to circles
		Does this hold for discrete robots generating the signal field?

IBA: Intelligent Bug Algorithm – A Novel Strategy to Navigate Mobile Robots Autonomously
Muhammad Zohaib, Syed Mustafa Pasha, Nadeem Javaid, and Jamshed Iqbal
	Uses a range sensor to see if there's something between it and the target, leaves if there isn't. 
	This seems a LOT like visbug

K-Bug, A NEW BUG APPROACH FOR MOBILE ROBOT’S PATH PLANNING
Ricardo A. Langer, Leandro S. Coelho, and Gustavo H. C. Oliveira
	Goes to closest point of visible obstacles between it and the target

Ok, so there are a host of bug algorithims
	some have some userful properties for swarms
	Many make poor assumptions
		Unlimited range visual sensors
		Perfect sensing
		noiseless sensing
		point robots
		etc. 


