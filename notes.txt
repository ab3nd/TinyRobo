
Fiducial tracking from NERVE cameras
	Camera uses RTSP
	Default TUIO tracker implementation can't use RTSP cameras
	v4l2loopback is broken on Ubuntu 14.04
		Yes, both v4l2loopback-dkms and v4l2loopback-source + module-helper
		Not going to bother compiling from source
			It would break with every kernel upgrade
			Unconvinced it's going to work, given that the packages are broken
		So no converting RTSP to a /dev/videoX entry
	TUIO isn't actually a fiducial library, it's a protocol
	And the reacTable amoeba tags appear to be detcted by a binary blob
		So those guys can go pound sand, I'll use something I can use. 
	April tags?


Bugs in v1 hardware:
Don't use 0204 parts. They're annoyingly tiny. 1206 for everything. 
The caps are OK 0805
The footprint for the diode is too big, it's only slightly bigger than 1206. 
The footprint for the switch needs the leg contacts moved in by half their length towards the switch
Via for the heat sink for the motor drivers needs to not be under the ESP8266
Connectorize battery

Needs pull-up to connect CH_PD high, pull-downs on GPIO15 (all times) and GPIO0 (only for programming)
 - GPIO15 is what I was going to use for one of the fault sensing lines

DRV8833 might be a good canidate for next driver, but only has PWM interface.
3A drive if outputs are paralleled, available in a TSSOP16 package. 

IFX9201SGAUMA1 would also be good, but requires higher voltage (e.g. two-cell battery and voltage regulation)
Has SPI interface, 6A(!) drive current, full bridge per chip. 
 
https://github.com/esp8266/Arduino/issues/22 Has how to get automatic reset, easier than integrating the limpkin.fr reset circuit.  
Needs a serial adapter that has DTR line, ordered that. 

Assembly pointers:
Get you some fine-point tweezers for great good

Ideological bugs:
Off is not where you think it is on the switch (on is towards the battery)
- Label on the PCB
Surface mount ESP8266 has no idiot lights, add one so I can tell when it is on
Add another light to an unused GPIO for debugging
Any reason I shouldn't have all pull-ups be one value (have some 10k and some 1k)?


Mobile Sensor Network Deployment using Potential Fields
Andrew Howard, Maja Mataric, Gaurav Sukhatme
	Deploying a sensor network in unknown environment
	Mobile nodes
	Maximize coverage
	Nodes are repelled by obstacles and each other
		Viscous friction force so that the expansion eventually stops
	No need for localization, aside from relative to other nodes
	Only does one thing (spread out)

A General Algorithim for Robot Formations Using Local Sensing and Minimal Computation
Jakob Fredslund, Maja J Mataric	
N robots, form geometric shape
	Each robot picks a friend, makes sure that friend is at angle Theta
	Three principles of formation control
	Unit-center-referenced
		Relative to centroid of all robots
		Requires global knowledge
	Leader-referenced
		Position of a selected leader
	Neighbor-referenced
		Relative to position of nearest neighbor
		Uses local knowledge
	Paper cites a bunch of possible strategies for formations 
	One robot is leader, has no friends, decides heading of formation
	Certain formations cannot be formed
		Can have at most two loose ends
		Assumptions of sensor precent certain curves
	Angle robot needs to keep its friend at depends on rank in formation
		Allows different angles for e.g. squares
	Leader can drag whole formation around
	Includes algorithims for avoiding obstacles
	Includes handling of individual robot "termination"

Laser-Based People Tracking
Ajo Fod, Andrew Howard, Maja J Mataric
	Tracking people using plana laser scanners
	Objects are tracked as blobs
	Blobs are registered between frames
		Prediction and update steps
	Groups of blobs that stay together are objects
	Object tracker smooths object paths and compensates for occlusions
	From old frame to new frame
		Bounding box old objects
		Expand box
		Check for matches within the expanded box in the new frame
			Minimum-distance point pairs are "matches"
		Weghted by quality of match, which is number of point matches
		New blobs get a state vector of zero
		old blobs get parent's state vector
		State vector can continue to update predicted state of currently missing blobs
			So when they reappear near their predicted location, they get their old state vector

Detecting Anamalous Human Interactions using Laser Rangefinders
	Uses the system described in "Laser-Based People Tracking"
	Tracks of activities re segmented to maximise Jensen-Shannon divergence
	Comparing concurrent positions of tracks detects interactions
	Model of interactions in space is developed
		Anomalous interactions are those of low probability under the model
	

Challenges in Evolving Controllers for Physical Robots
Maja Mataric, Dave Cliff
	Evolves morphology and controller
	Genetic Programming
		Operates on lisp S-expressions as the genome
	Generally, evolutionary control takes a long time
	Generally, controllers are evolved to do exactly one task
	As of '96, no evolutionary controller was doing anything that couldn't be done by hand
	Realtime on real hardware 
		Battery life
		Wear on the robot
	Simulation
		Noise and error models
			Noise has to match real noise
				Otherwise, behavior won't transfer to real world
			GA can exploit abstractions in simulation
		Generality v. Utility
			Simulator that simulates a given robot well won't generalize
	Evaluation
		Detecting convergence is hard to automate
		Human ranking is tedious and slow
	Fitness functions
		Complex to design for complex cases
		Has the same exploitable abstraction problems as simulaton
		May not be able to measure fitness parameters (see Evaluation, above)
	Overall, it seems like this is a bad way to go about what I want

Minimizing Complexity in Controlling a Mobile Robot Population
Maja J Mataric
	Distrbuting a task over homogeneous robots
	Minimal Modeling and no planning
	Only covers tasks that can be done by a single robot
		but get better with multiple robots
		e.g. foraging
	Ignorant coexistance
		Robots treat each other as obstacles
		More robots leads to more problems, slower task completion
	Informed coexistance
		Robots behave differently when avoiding robots than obstacles
		Wait for the other robot to get out of the way, then evade
		Minimizes interference, better than ignorant case
	Intelligent coexistance
		Robots have an idea of local population density, population gradient
		Can minimize potential for interference, not just react to it
		Homing, flocking, etc. 

Design of the Army Ant Cooperative Lifting Robot
John S. Bay
	Not really related, more about mechanical and electronic design

Ant-inspired Navigation in Unknown Environments
	Combination of landmarks and transitions between them
	Failure to detect landmarks triggers search

Relaxation on a Mesh: a Formalism for Generalized Location
	Spring relaxation of networks including some globally localized bodies
	I don't plan to do global localization

Huey, Dewey, Louie, and GUI - Commanding Robot Formations
Jacob Fredslund, Maja j Mataric
	GUI for commanding robots into formations
	Only formation, no box pushing, patrolling, soda-can-collecting, etc. 
	Uses the formation algorithm from "A General Algorithim for Robot Formations Using Local Sensing and Minimal Computation"
	Gui specifies node locations, angles can be calculated from that
	Limitation remains that no robot can look behind itself for its friend


Robots in Formation Using Local Information
Jakob Fredslund, Maja J Mataric
	Same as "A General Algorithim for Robot Formations Using Local Sensing and Minimal Computation" but with more implementation details


Bounds of Neglect Benevolence in Input Timing for Human Interaction with Robot Swarms
Sasanka Nagavalli, Shih-Yi Chien et al
	User may need to make changes to the swarm's goal from a previous goal
	Two capabilities needed
		Comprehension of swarm state
			Relations and regularities in behavior
		Prediction of effect of input on state
			Human must develop a mental model of swarm responses
			Timing lags make this harder
	Adding the human input ASAP may not be optimal
		"Neglect Benevolence" - some neglect may be good
	How does human understand swarm dynamics to choose best time to intervene?
		Humans can learn to approximate optimal timing
	Paper refers to "Neglect Benevolence shape-changing HSI reference task"
	Doesn't really effect compilation or anything, but good for interface design


Human-Swarm Interaction: Sources of Uncertainty
Sean Hayes, Julie Adams
	Defines swarms as >= 50 entities	
	Multiple sources of Uncertainty
		Physical state uncertianty
			Position uncertainty - Where each of the robots is, relative position
			Motion uncertainty - keeping track of speed and direction of members
			Aggregation and subgroup
				Cohesion uncertainty - how well is subgroup bound?
		Virtual state uncertainty
			Leadership uncertainty - which units are leaders?
			Influence uncertainty - how much influence do leaders have?
		Compound state uncertainty - combined virtual and physical
			Goal outcome uncertainty - will individuals contribute to goal?
			Role uncertainty - units may change roles due to physical or virtual state
			Dominance - attempts to influence others that may fail

Explict vs. Tacit Leadership in influencing the Behavior of Swarms
Saman Amirpour Amraii
	How does a teleoperated leader influence the swarm?
		My swarm isn't going to do this
		May provide bottleneck/single point of failure
	Consensus (tacit)
		No leader/follower distinction
	Flooding (explict)
		Leader influence takes precedence
	May be useful for control design of the compiler
	Flooding generally converges faster



This is a scratch file that I put stuff in when I remove it from the main paper. 

Don't expect it to be useful, or even to contain complete sentences. 

Motion "primitives" from Stupid Robot Tricks
Motion $\rightarrow$ moveArc, moveStop, moveForward, moveByRemoteControl, bumpMove

Orientation $\rightarrow$ orientForOrbit, orbitRobot, orientToRobot, matchHeadingToRobot, followRobot

Navigation $\rightarrow$ followTheLeader, orbitGroup, navigateGradient

Clustering $\rightarrow$ clusterOnSource, clusterWithBreadCrumbs, clusterIntoGroups

Dispersion $\rightarrow$ avoidRobot, avoidManyRobots, disperseFromSource, disperseFromLeaves, disperseUniformly

Utility $\rightarrow$ detectEdges

detectEdges is "detect if you are on the edge of the swarm" 

Utility classes are to be regarded with skepticism, they are like "miscelaneous" categories. 

$\Rightarrow$ iRobot swarm had directional IR signaling (quadrants) using signal strength to figure out range and bearing, so that's something I'll want to include or emulate in my system. 

$\Rightarrow$ I should probably include some form of charging that doesn't involve a lot of hands-on interaction with my robots. 

Computer is aware of meaning of gesture, locations of robots. 
Second assumption (global localization) may not hold. 
How can computer determine what programs or what parameters result in the completion of the task?

What are the tasks? Assume search and rescue domain, what are the tasks in USR? Search an area with good coverage. Report content of an area. Group at a location. Locate a specific resource. 

This could be situated at an intersection between planning and compiling, as the compilation might have to factor in elements of the known environment at the time of compilation. Since the actors are spatially situated, plans should incorporate spatial awareness. 

$\Rightarrow$ Why is almost everyone ignoring power supplies except as an afterthought? Not a computer science problem?


Notes on papers in verification of swarm robotics

ALLIANCE: An Arcitecture for Fault Tolerant Multirobot Cooperation
	Distributed team is needed for distributed tasks
	Decomposing a problem adds complexity
	Fault tolerance is point failures (individual robots) or communication
		Can occur any time, must adapt
	2 kinds of cooperation
		Intentional/Explict cooperation
			ALLIANCE
		Swarm/Ant-like cooperation
			Other papers
			"Such approaches usually rely on mathematical convergence
			results (such as the random walk theorem [14]) that indicate
			the desired outcome over a sufficiently long period of time. A
			key research issue in this scenario is determining the proper
			design of the local control laws that will allow the collection
			of robots to solve a given problem." <- good pointer on what to look into
			Assumes homogeneous robot hardware & software
				Which I'm aiming to not have
	Distributed AI (DAI) is apparently a field
		Negotiation, which fails under no communication
		Tends to be agents with perfect communication, not fallible robots
		
	"Our assumptions are as follows.
	1) The robots on the team can detect the effect of their own
	actions, with some probability greater than 0.
	2) Robot can detect the actions of other team members
	has redundant capabilities, with some
	for which
	probability greater than 0; these actions may be de-
	tected through any available means, including explicit
	broadcast communication.
	3) Robots on the team do not lie and are not intentionally
	adversarial.
	4) The communications medium is not guaranteed to be
	available.
	5) The robots do not possess perfect sensors and effectors.
	6) Any of the robot subsystems can fail, with some prob-
	ability greater than 0.
	7) If a robot fails, it cannot necessarily communicate its
	failure to its teammates.
	8) A centralized store of complete world knowledge is not
	available."
		Good list, I should probably have a similar one for my paper, early in the problem description
	Paper points out that recognizing that something is happening is really hard
		Overhead cam can fake this sense, but that's a bad thing to rely on
	ALLIANCE overview
		Robots have behaviors
		Behaviors have motivations
		Motivations can activate or deactivate behaviors based on percieved need
		Some low level stuff (avoid obstacles) may not ever turn off (always needed)
		Only does one thing at a time (except the low-level stuff)
		Impatience
			Increases desire to perform a behavior, when seeing that it needs doing and other robots are failing
		Acquiesence 
			Decreases desire to perform a behavior, to avoid all robots trying to do the same thing
			Triggered by getting a message from another bot saying "chill, I got this"
		Could communicate "I'm currently doing X" with local comms, and remember previously seen robots that were doing a thing
			Sounds like a job for quorum sensing
			"I've seen robot M, it was doing X" replications (and a timeout "Last time I saw M...")
		Robots can detect that their behaviors fail
			And then become reluctant to use them again
	Subsumption provides a pretty good way of composing behaviors
		The behaviors can then be reasoned about using e.g. random walk theories or the stochastic stuff from GCPR	
		
Self-stabilizing Systems in Spite of Distributed Control (Dijkstra! He has a way with titles.)			
	Assumes a Legitimate State, and machines on a sparse connected graph
	Global awareness of legitimacy is hard
		Perhaps "locally legit" is good, as long as moves tend to spread legitimacy rather than illegitimacy
	Assumption of connectivity may not hold, but how does it extend to severing/merging graphs?
	
Decentralized Model Predictive Control of Cooperating UAVs (Arthur Richards and Jonathan How)
	Assumes solid communication
	has better performance than a centralized version of the algorithim
	Can operate as an anytime algorithim, so only computes what is needed
	
Decentralized Task Allocation for Dynamic Environments (Luke B. Johnson, MS Thesis)
	Broadcast messages
	Message count should be minimized
	Sequential greedy algorithim
		All agents assemble a bid, and shares it with all others
		Whichever agent feels it can do a task best (max score based on its own knowledge) wins the bid
		Constraints based on interdependant tasks, whether the agents can actually be trusted to do the job
			Is this anything like the blockchain? Could the blockchain be used for this?
		Reaching a synchronized state with incomplete communication may be very slow or impossible. 
	Consensus-Based Bundle Algorithm (CBBA)	
		Each agent creates a bundle of tasks
		Tasks are added if the agent can outbid the current high bid
		Some additions may conflict (multiple agents may have better scores than current high bid)
		Conflicts resoved by communication to see if anyone outbids
			If so, agent must release task and ALL SUBSEQUENT tasks (tasks are on a path, and so have dependencies)
		So agents build a bundle, lose all, some, or none of it, then rebid from the end of whatever is left
	Asynchronous Consensus Based Bundle Algorithm
		Allows agents to enter and leave network
	This whole paper isn't really about task completion, just assignment	
	
------ 7/10/17 -----

Had some concerns about thesis once it was framed as a planning problem rather than a compilation problem due to the fact that planning has a long history, and a lot of work already done in it. 

As a planning problem, user input is desired world state (or can be transformed to desired world state). 

Can possibly converge to desired world state without knowing starting state, as in stochastic box-pushing example on wiki. 

Planner with unknown worldstate is using "coercion" to make the world match a known state before or in the process of operating. 

UI may convey how precisely user's input is supposed to be followed. 
  - Direct line to end point just means "go here", indirect, bendy line means follow this exact path
  - Do we need to get close, vs. jsut approximately hit the target? How approximately?

Could need a hierarchy of subplans based on what's available to the compiler, in terms of robot abilities
  - Heterogenous "processors" for a parallel compilation task. 

Program generation for swarms? Looking into Carlo Pinciroli's stuff

Do any systems allow specification of the desired end state of the universe, not the actions to take? Can the actions be transformed into the target end state, i.e. how do you know you're done?

Grammatical Swarm: The generation of programs by social programming
  Particle Swarm Optimization
  Each particle is a choice of program constuction rule
  Rules are in BNF
  Based on Grammatical Evolution
  Sort of a genetic algorithm, but the evaluation function/fitness adds or removes velocity to the particle swarm
  So all the particles converge towards the best solution found so far, but explore around it
  Genotype specifies a BNF grammar that permits derivation of a program
  Still has the problem that the encoding of the fitness function becomes the iterative target rather than the actual code of the solution. 

Property-driven design for swarm robotics
Manuele Brambilla, Carlo Pinciroli, Mauro Birattari and Marco Dorigo
  Top-down design, as opposed to code-and-fix
    Code and fix is expertise-dependent
  Formal spec of desired properties (but of the system, not of system + world (what I'm calling "the universe"))
  Applied using Discrete time Markov chains and probablistic computation tree logic
    Oh god more stuff to learn
  Protoswarm
    Assumes constant network connectivity and total spatial coverage
  Hamiltonian Vector Field methods
  	Specification of the system is as energy potentials and flows
  	Only works for spatially-organizing behaviors
  Automatic design methods
  	Evolutionary and reinforcement methods
  	Domain knowledge required, result may not be verifiable or generalizable
  Property Verification
  	The turing tarpit of formalisms, where you can prove you can do things, but not actually do them
  	Scaling issues

  Property-driven Design
  	1. Specify properties
  	2. Build a model
  		Programmer iterates on the model, checking that properties are verified
  		Final model 
  	3. Model is used as a guide to implement the swarm software
  	4. Run it on some real robots. May need some tuning. 

  So this is a design method, not an end-to-end automation, still has developer iterating on something
  I want to not have a designer, and leave the iterating to computers

  PCTL expands a Markov chain into a (potentially infinite) tree rooted at the initial state
    CTL can make assertions like "a given state will be reached" or "a given state will hold for a fixed time"
    PCTL adds probabilities to those assertions
    Potentially infinite trees? Put that in your limited system memory and smoke it. 

  PRISM model checker implements PCTL and DTMC (among others)

  Case study on aggregation
    Allows time bounds on behavior, so none of my "converges in ... finite time, I hope"
    Behaviors still hand-designed by the programmer, so while it can be checked fast, it still needs to be written by a person
      My stuff would be automatically designing the behaviors or behavior sets and triggers

  Property-driven design reduces the probability of designing the "wrong" system, but doesn't let you not design the system


Boolean Network Robotics as an Intermediate Step in the Synthesis of Finite State Machines for Robot Control
Lorenzo Garattoni 1 , Andrea Roli 2 , Matteo Amaducci 2 , Carlo Pinciroli 1 and Mauro Birattari 1
  Automated design of compact high-level representations of control software for robots
  Larger exploration footprint for automated design methods, compared to manual
  Automated design of FSMs for controlling the robots
  Boolean Network robots?
    Boolean network is a model of genetic regulatory networks
      I wonder if this relates to guards in GCPR?
        It sure looks like it
        Oriented graph with N nodes, associated with a boolean value and boolean function of inputs to node
        Various update schemes
        To control a robot, some nodes are input and output nodes
        Input node boolean values are imposed by sensor precepts, not other nodes
        Output nodes control robot actions (motor vel, etc. or actions)
        Yeah, this smells like an isomorphism. 
    Can be analysed as dynamic systems
    Automatic design shapes network dynamics in limited areas of state space
    State clusters are associated with behaviors of the robot
    Map from clusters to FSM states to get a formal and explainable framework

  Calls out the existing problems with evolutionary controllers
    Have to constrain FSM size or you get really hairy, uncompact representations
  ANNs have problems with explainability

  Example programs use a constrained network size. 
  Rather than having all the nodes of the network be behavioral primitives, and sequences of boolean actions control those, the boolean network acts as an action selector. 
  Constant connectivity, intially random, three incoming inputs to each node. No self-connections.
  Flips bits at random in the boolean functions of the nodes, and only keeps the ones that work at least as well as the current best. 
  I bet boolean networks are stupid-fast and compact to represent in programmable hardware. 

  This case isn't specifying the desired behavior from a user input
  It also requires a lot of simulated runs to develop the working networks
    It's stochastic gradient descent operating on a binary genome, or evolution again. 
    No crossover, though. Probably for the best, that would transplant part of the FSM into another part. 

  Constrained to dealing with booleans
    Not really that much of a constraint, you can represent floats with booleans, at a (probably high) cost in complexity. 
    Evolving sub-modules might help reduce this, since a subnetwork can be reduced to a boolean network node itself. 


Finite State Automata Synthesis in Boolean Network Robotics
L. Garattoni, C. Pinciroli, A. Roli, M. Amaducci, and M. Birattari
  Still an evolutionary method, still needs a fitness function defined for it
  Also all the examples are for single-robot cases, no assumptions about interaction
    Binary robots could have senses for other robots, and at some levels of abstraction, quorum sensing
  Does permit dynamic behaviors, and so dynamic environment and systems
  "FSA asan indirect product of the design process of BN-robot systems and, hence, we
do not have the problems of representing automata in terms of genomes and
constraints."
    No, you represent it in terms of a binary string that evolves under control of a fitness function, though...

Recent Advances in AI Planning
Daniel S. Weld
  1999, talking about the last 5 years in planning 
  2-phase GRAPHPLAN
    Apparently very fast
    Detail level is a bit out of scope for my work at present, seems to cover the textbook sections I read
  Compiling planning problems into propostional formulas using SAT algorithms
  Talks about planning based on a known inital position of the world
  Calls out problems with universal quantifiers 

A Survey of the Seventh International Planning Competition
Amanda Coles, Andrew Coles, Angel García Olaya, Sergio Jiménez, Carlos Linares López, Scott Sanner, Sungwook Yoon
  Constrained planning domain description language (PDDL)
  Fixed domains, so people are running with a specific description of a specific domain
  various constraints in various tracks (optimality, uncertainty, etc.)
  Paper doesn't cover how things worked aside from what won and what techniques they were using


What I'm doing isn't exactly classical planning, because it's the generation of behaviors and the conditions under which they are to be executed, rather than a sequence of actions. No temporality in my "plan". Also, I don't assume that once all the behaviors have been executed, the desired world state holds. Instead, execution of at least some of the behaviors by at least some of the agents is intended to converge to the desired world state, but some behaviors may not be executed by some agents, and some agents may execute no behaviors (because they're broken). 

While we're talking weirdness, any binary sequence could be a representation of a binary network's binary functions, and so e.g. the complete works of Shakespear in ASCII, combined with a given connectivity, might do something cool.

SWARMORPH-script: a language for arbitrary morphology generation in self-assembling robots
Anders Lyhne Christensen, Rehan O’Grady, Marco Dorigo
  Governs self-assembling robots
  Morphology scripting, inter-robot lcoal communication

AutoMoDe-Chocolate: a Method for the Automatic Design of Robot Swarms that Outperforms Humans
G. Francesca
   Previous methods: Vanilla and EvoStick
   Vanilla beats EvoStick, humans beat all
   Chocolate = Vanilla + better optimization algorithm
   Design of collective behavior, but designer eventually has to specify the behavior of individual robots
   "Presently, no general approach exists to derive the individual behavior of the robots from a desired collective behavior"
      Well, that's encouraging to me...
   1. Specification
   2. Development using simulation
   3. Deployment onto a swarm
   AutoMoDe (2014) defines a program by composing probablistic FSMs
   Vanilla specializes AutoMoDe for the E-puck
      Shouldn't define the problem for specific homogeneous collections of robots
   Comparison with Vanilla and Evostick was on aggregation and foraging
      I'm assuming that things like aggregation were defined as primitives I can compose
      Foraging is a "find the box/target area" kind of thing, one step in performing a task
      So I think I'm looking at a level up from this
   5 methods on 5 tasks
      Fixed tasks, rather than open tasks as defined by the user
   Mentions work on task allocation via reaction-diffusion
      Works well with local state, so robots who are well-situated to solve a problem volunteer for it
      The idea of volunteering based on local information is probably a good way to look at it, in opposition to assignment by a central authority. 
   4 design methods
      Vanilla
         Assembles pre-exising modules into a PFSM
         Modules might have some parameters that affect their functioning
         Behaviors 
            Activity the robot can perform
         Transitions
            Control switching behaviors based on a condition or event
            Boolean, based on input values
         "The six behaviors are:
exploration, stop, phototaxis, anti-phototaxis, attraction, and repulsion. With the
exception of stop, these behaviors include an obstacle avoidance mechanism. The
six transitions are: black-floor, gray-floor, white-floor, neighbor-count, inverted-
neighbor-count, fixed-probability."
         Up to four states with up to four outgoing edges
         Optimize the expected value of a task-specific performance measure
         F-Race optimization algorithim, whoever does the task fastest is fittest
            Chocolate uses iterated F-Race
                Each iteration resamples search space with a distribution that favors the best performers on previous iterations
                This is starting to sound a lot like an evolutionary method
      EvoStick
         Evolutional method, generates feed-fwd ANN with no hidden nodes
         Inputs are robot sensors
         Outputs operate on the wheel speeds
            So the only possible actions are changing the position of the robot
      U-human
      	 Unconstrained human
      	 Person writing some code, no constraint on what they write
      	 Testing in ARGoS, but not the robots, like the automatic methods
      	 C++ class that operates on the inputs of the robot and provides logic for controlling the robot
      C-human
         Human who has to use the Vanilla control architecture and modules
         Human does what the Vanilla optimization algorithm would have to do
            This sounds like setting the human up for a beating, simply because they can't search the space as fast
         Again, only four states and at most four transitions out of each one
   5 conditions
      Shelter with constrained access
      Largest covering network
      Coverage with forbidden areas
      Surface and perimeter coverage
      Aggregation with ambient cues
         These are more complex tasks than my primitives, and possibly more complex than my tasks for the UI
   Vanilla and EvoStick can create solutions in 2h20m, so humans were given 4h, since they have to watch sims, and the software doesn't. 
   EvoStick beats the heck out of everything, all the time... in simulation
      It can't cross the reality gap, so it's probably overfitting
      In reality, it gets beat nearly all the time by something
   C-human beats U-human, which is surprising, but may be up to reduced variance due to reduced chance for bugs
   Chocolate beats humans, more in simulation than in reality, but usually in both
      Chocolate also has good reality-gap-crossing results

AutoMoDe-Chocolate: automatic design of control software for robot swarms
G. Francesca, M. Brambilla, A. Brutschy, L. Garattoni, R. Miletitch, G. Podevijn, A. Reina, T. Soleymani, M. Salvaro, C. Pinciroli, F. Mascia, V. Trianni , and M. Birattari
   Seems largely like a restating of the previous paper? Maybe that was a preprint. 

An Experiment in Automatic Design of Robot Swarms: AutoMoDe-Vanilla, EvoStick, and Human Experts
G. Francesca, M. Brambilla, A. Brutschy, L. Garattoni, R. Miletitch, G. Podevijn, A. Reina, T. Soleymani, M. Salvaro, C. Pinciroli, V. Trianni, M. Birattari
   14-page version of the two papers above

Boolean network robotics: a proof of concept
Andrea Roli and Mattia Manfroni, Carlo Pinciroli and Mauro Birattari
   Covers a lot of the same ground that the previous binary network paper I listed covers. 
   More mathematical explanation of the error/fitness function
   The evaluation heuristic from iterated F-Race sounds like it would be great for this
      Assuming that more-similar bitstrings have more-similar behavior, then selecting from a distribution that favors the elite examples would tend to generate more elite examples. 
   The single-bit-flip approach that was used is pretty close to this anyway, as it uses minimal perturbations
   Detail on training, used a shaping approach, where first phototaxis was trained, and then a handclap triggered antiphototaxis
      Longer runtime with the clap

ARK: Augmented Reality for Kilobots
Andreagiovanni Reina, Alex J. Cope, Eleftherios Nikolaidis, James A.R. Marshall, and Chelsea Sabo
   Similar design to my system
   Automates some aspects of e.g. identifying the robots
   Highly tied to the Kilobot platform
   I should certainly cite it, though

Towards a swarm of agile micro quadrotors
Alex Kushleyev, Daniel Mellinger, Caitlin Powers, Vijay Kumar
   Seems unrelated

Searching for swarm robot planning gets a lot of hits based on PSO, but I want the swarm on a table, not in the planner. 

I'm getting the impression that a multi-agent planner might assume much less stochasticity on the part of the agents than I am actually going to have in my system. 

Interactions among Autonomous Planning Agents
Frank Von Martial
   Autonomous agents create their own plans independently
   Plans are Executed in a common environment
   Paper proposes a taxonomy, harmful/favorable interactions
   Implies a dynamic environment
   Has been modeled as a single multiagent plan with conflicts, which can be resolved
   Communication can be present or absent
   Assumptions
      the agents are "intellegent", which is a hell of an assumption
      Agents have different skills
      Agents can include each other's actions as part of their plans
         Parenthetically notes as "(multiagent planning)", which means what I'm planning isn't
      Agents can communicate actions to each other
      Agents are honest and benevolent
         Don't lie about actions, don't want to harm each other
   I don't think this is the model I'm looking at, since I want the total behavior to be sorted by the compiler/planner (complanner? Planpiler?) rather than by an iterated negotiation among agents

Multi-Agent Planning under Dynamic Adaptive Autonomy
K. S. Barber and D. C. Han
   Autonomy levels characterize agent's role in organization of agents
   Agents can change autonomy levels dynamically
   Concurrent actions by multiple agents
   Agents can enter into autonomy agreements with each other to attain goals they otherwise can't reach
      e.g. a ship in a naval formation can't change position with getting clearance (the agreement) to do so. 
   The determine if they need these agreements via a 2-stage planning process
      1. Come up with goals based on available subgoals and intended goals
      2. Filter the available operators by autonomy level, and plan using the remaining ones. If needed, try to acquire higher autonomy levels
   
I think a lot of the problem I'm having with planning here is that there are some actions that are going to be ongoing things, which overlap each other, rather than discrete operations in a plan. Some planners do talk about contingencies, but I'm thinking of stuff like random walking forever, as a plan element. It (eventually) has a probablistic postcondition of having visited everywhere in a bounded area, but it doesn't synchronize on that point with anything else, because it could take almost any amount of time. 

Is It an Agent, or Just a Program?: A Taxonomy for Autonomous Agents 
Stan Franklin and Art Graesser 
   Agents need to be able to execute autonomously and have domain-oriented reasoning
   Agents need to get data from their environment (which may be virtual)
   Agents have goals
   Not really useful to me, but could be interesting to read some other time. 

Robot Path Planning using Particle Swarm Optimization of Ferguson Splines 
Martin Saska, Martin Macas, Libor Preucil, and Lenka Lhotska
   Splines for indivisual robot movement
   Cool result, but got into my search due to mention of particle swarm, not robot swarm

Cooperative Mobile Robotics: Antecedents and Directions
Y. UNY CAO, ALEX S. FUKUNAGA, ANDREW B. KAHNG
   1995, said field of multiple cooperating robots was still in its formative stages
   Task may be too complex for one robot
   Fault tolerance
   Insight into social theories and life sciences 
   Cooperation is the use of some mechanism of the system to increase total utility on a task
   Dudek et al. (1993) taxonomy on SWARM and Mataric's Behavior based work
   Common problems
      Traffic control of swarms
         Geometric problem in configuration spacetime
         Behavior-based collision avoidance is fine, if you're not restricted to roads
      Box-pushing cooperative mainipulation
         As a study fo task allocation, fault-tolerance, reinforcement learning  
         " Cooperative manipulation of large
objects is particularly interesting in that cooperation
can be achieved without the robots even knowing of
each others’ existence (Sen et al., 1994;  Tung and
Kleinrock, 1993). "
      Foraging
         Stigmurgy, chain formation and passing
   So how should cooperation arise?
      "Note that
certain basic robot interactions are not task-performing
interactions per se, but are rather basic primitives upon
which task-performing interactions can be built, e.g.,
following ((Connell,  1987;  Donald et al.,  1994) and
many  others)  or  flocking  (Reynolds,  1987;  Mataric,
1994a)."
      Group Architecture
         Abilities of robots
         homo/heterogeneity
         Central or not
         Task coverage (parker 1994)
            Ability of a given team member to do a task
            Maximal in homogeneous groups
         Communication structures
            Via environment, e.g. stigmurgy
            Via sensing, robots can tell each other from environmental obstacles
               Flocking and pattern formation
            Via communication
               Explicit sending and receiving of messages
               Signboards, diffusion of messages
         Modeling of other agents
            Box and bar pushing without communication
      Resource conflict resolution
      Origins of cooperation
         Eusocial is emergent, gentically programmed group behaivor 
         Cooperation is an intentional desire to cooperate to maximize individual utility
         Not intrested in explicitly designed cooperation (good, I'm not either)
         Learning control parameters to maximize perceived utility
            Cites Yanco & Stein 1992!
      Geometric problems
         Path planning, formations, patterns in space   
         Formation and marching are a useful tool for caging manipulation
         Amount of information available affects solubility of problem
         Formation is optimally solved in computational geometry as "geometric matching under isometry" 

SWARM ROBOT MATERIALS HANDLING PARADIGM FOR A MANUFACTURING WORKCELL
Keith L. Doty  and Ronald E. Van Aken 1993
   Paper is working on materiels handling to work areas for some process
   Adaptable in the face of changes to the processs
   Devices that need materials emit brodcast requests
   Robots detect requests, can load and unload machines, and carry material
   Machines take parts and finsih them
   No learning
   Machines ask for materials, but aren't told if it's on the way
   Robots wander randomly when they're not tracking a request for material RFM
   Not competetive with actual scheduling, but functional

Path Planning and Motion Coordination in Multiple Mobile Robot Teams
Lynne E. Parker
   Becomes a problem in my system when the user specifies waypoints
   Don't want to wedge all the robots when passing through a narrow area
   But also don't want to plan the paths and timings of all robots and encode in programs for each robot
   Need a reactive approach
   General optimal planning is PSPACE-hard
   A* exponentioal in dimensions of configuration space, and so in number of robots
   Decoupled planners plan individually, and then resolve collosions/conflicts
   Motion coordination doesn't need advance planning for swarming or flocking, but does need reactivity
   Coupled, centralized
      Whole swarm considered as a composite system, classical planning 
      Potential fields can be used (could also be used decentralized and decoupled)
      Tend to computational intractability without using some form of dimensionality reduction
   Decoupled
      Prioritized or not
      Path coordination
         Plans paths and then plans velocities
         So where robot paths intersect, they miss each other in time/space
   Motion coordination
      Reactive, dealing with problems while moving on the path
      Traffic controls, like yeild to oncoming traffic
   Table 1 is cool, doesn't copy/paste well, lists swarm behaviors

New Potential Functions for Multi robot path planning : SWARM or SPREAD
Sung-hwan Kim, Gyungtae Lee, Inpyo Hong, Young-Joo Kim, Daeyoung Kim
   Artificial potential fields with priority selection between robots
   New potentials based on priority
   Avoids local minima in APF
   Distance to goal is used as a multiplication factor so that goal is always lowest point
   Potential field is calculated per-robot, rather than all over 

Multi-Robot Path-Planning Based on Implicit Cooperation in a Robotic Swarm 
Guillaume Beslon, Frederique Biennier, Beat Hirsbrunner 
   Reactive material handling agents in a conveying task
   Stigmurgic strategies
   Each agent has a beacon
   Each agent beacon re-emits any beacon that it detects
   So shadows of machines and agents are filled in by the beacons on those agents
   Front sector of mobile agents doesn't emit, so they don't do head-on collisions
      Also, they random walk when shadowed by another agent, avoiding collisions

Handbook of Robotics, Ch 40 Multiple Mobile Robot Systems
Lynne E. Parker
   Makes distinction between collective swarm and intentionally coooperative systems
   I'm doing a more collective swarm than intentionally cooperative 
   Has similarity to elements of the Parker paper above, in terms of taxonomizing


From real robot swarm to evolutionary multi-robot organism
S. Kornienko, O. Kornienko, A. Nagarathinam, P. Levi
   Jasmine robots, and some talk about self assembly, which Jasmine can't do
   Jasmine docking guided by IR sensors
   Planar self-assembly via IR signalling
   Robots controlled by petri-net, has a high-level description of the robots including the "genes" for the full organism as well as the individual robot

No Robot Left Behind: Coordination to Overcome Local Minima in Swarm Navigation
Leandro Soriano Marcolino and Luiz Chaimowicz
   Some robots are rescuers, help others out of local minima
   "In  order  to  compute  the  gradient
forces,  robots  must  know  their  global  position.  This  is  a
strong assumption, but it is generally accepted when dealing
with  swarm  navigation."
   I'm not assuming that
   Robots do gradient descent/ascent to the zero isocontour of a 3D surface whose value is less than zero inside its boundary and great outside its boundary
   Rescuers can go push stuck robots by approaching them (altering the local potentail field)
   Trapped robots repel all non-rescuers, so local minima don't fill up with robots
   Rescuers self-elect, trapped robots approach rescuers, rescuers retrace path to lead

A Multiagent Planning Architecture
David E. Wilkins and Karen L. Myers 1998
   MPA defines a uniform interface for agents
   Shared plan representation
   Metalevel agents that work on the interactions between other agents
   Emphasis on application to large scale planning
   Planning cell
      Collection agents
      Two distingiushed agents
         Cell manager
            Composes cell from agent pool
            Distributes task
         Plan server
            Warehouse of plan parts and information
   Act formalism for storing shared plan representation
   Message passing among agents
   This is a multiagent planner in that it uses multiple agents to create a plan, not because it makes plans for multiple agents

IMPACTing SHOP: Putting an AI Planner into a Multi-Agent Environment 
Jurgen Dix, Hector Munoz-Avila, Dana S. Nau, Lingling Zhang 
   Multiple agents
   Multiple infromation sources
   Mixed symbolic/numeric reasoning
      Pretty normal for planners by 2k2, isn't it?
   Paper doesn't address multiple planning agents
   Shop does hierarchical task network planning

ZEUS: A Toolkit for Building Distributed Multi-Agent Systems
Hyacinth S. Nwana, Divine T. Ndumu, Lyndon C. Lee & Jaron C. Collis
   Seems really unrelated, largely about building pure-software agents for undefined problems
   It also seems a lot like trying to implement web services. Like, call programs on other computers to do tasks
   I'm not sure there's any reason to be talking about this as agents

What was the point of agents anyway?
   Something to do with Minsky's Society of Mind? 
   Agent-based systems appear to have some idea of seperation of concerns for agents, with each one having a particular responsibility. 
   Not seeing any reason this couldn't be done with e.g. a library...
   Natural-language interaction, with a conversational agent, but again, this is a UI concern
   Agents can drive themselves, based on sensing their environment and context
   Agents can act without people controlling them

Integrating Agent-Based Mixed-Initiative Control With An Existing Multi-Agent Planning System
Mark Burstein, George Ferguson, and James Allen
   Mixed-initiative control 
   Wraps a non-agent planner in an interface so other agents can communicate with it
      Cool and all, but RPC doesn't deserve this level of discussion
   Multi-agent planning in general appears to refer to planning by multiple agents, not for them

I should check that I'm not too close to Mataric's behavior-based synthesis of collective behaviors (1992-1994)

Decentralized Controllers for Shape Generation with Robotic Swarms
Mong-Ying Ani Hsieh, Vijay Kumar, Luiz Chaimowicz
   Robots converge to a specific class of simple closed curves
   Local sensing only 
   "Ogren et al. relaxed this assumption in the
development of coordination strategies for a group of
unidentified, holonomic robots. 15 Similar approaches for
multi-robot manipulation were presented by Song and
Kumar 16 and Pereira and Kumar 17 respectively. Chaimowicz
et al. extended these approaches to arbitrary shapes and
established convergence to patterns that approximate the
desired shape. 18"
   These approaches might be useful as primitive behaviors the planner can invoke


Generation of desired emergent behavior in swarm of micro-robots
Sergey Kornienko and Olga Kornienko and Paul Levi


Should add citations for Miniman and MiCRoN
   MiCRoN is floor-powered, optically tracked from above, has a manipulator finger
Things to look into: 
Multi-objectivization (Trianni and Lopes-Ibanez, 2014) 
Novelty Search (Lehman and Stanley 2011, Gomes et al 2013)
Heirarchical decomposition (Duarte et al, 2014) 
   Apparently untested on robots, and the decomposition is designed for the task by the programmer

From Local to Global Behavior in Intelligent Self-Assembly
Chris Jones and Maja J. Mataric
   Transition Rule Set compiler
   Takes a desired structure for a self-assembling robot, outputs a set of rules
   Operates on a grid, with local sensing
   Uses a state transition set
   Only covers self assembly
   Consistent rule sets
      Consistency requires that the spatiotemporal constraints to construct the figure are properly set up and that contraditory transistion rules not become active at the same time
      Inconsistency can cause e.g. building the perimiter of a filled figure without filling it, making it impossible to finish. 
   Limited to connected figures. No islands, no islands in holes in the figure. 
   Does do some of the same things I want to do
      User specification converted into local rules for robots
      mobile robots
   Also doesn't do some things I want to do
      Strictly a morphological language

Designing Collective Behavior in a Termite-Inspired Robot Construction Team
Justin Werfel1, Kirstin Petersen, Radhika Nagpal
   Given a physical structure, output a set of rules
   Local sensing
   Communication through the environment
   Strictly a morphological language, again

Differences from what I'm proposing
   I'm proposing a realtime user interface for this operation
   I'm proposing open-ended tasks, not only construction
      Could probably generalize to construction, but the UI would have to support it
   User interface elements of project are unrelated to previous compiler work

Goals as Parallel Program Specifications
Leslie Pack Kaelbling 1988
   Programmer specifies agent's behaivor using symbolic goal-reduction rules that are compiled into a program
   Realtime, dynamic domains permitting parallel actions
   Mentions Georgeff & Lansky Reactive Planning (1978)
      Does runtime interpretation of highly conditional user-specified plans
   Gapps model of computation
      Agent transduces stream of input into stream of output
      Small upper bound on time for transduction ("reaction time")
      Rex language
         takes program spec as input
         generates description of a synchronous digital circuit with delay components to satisfy spec
         circuit operates on a clock
         Used to program "the SRI robot", maybe Shakey?
      Computations as a perception and action component
         Perception component maintains state
         Action component is stateless, fired by Perception component
         This seems a lot like GCPR with ROS callbacks operating on it...
   Goals
      execution
         do(g) - instant action g, just do it
      Maintenence   
         maint(h) - if h is true, act to keep it true as long as possible
      Achievement
         ach(i) - make i true ASAP
      Set of goals is boolean operation of primitive goals
      Not-acheiving X is the same as maintaining not-X and not-maintaining X is the same as acheiving not-X (they are dual)
   Saying an action leads to a goal
      Action is a correct step toward satisfying a goal
      Doesn't appear admit formalization in a domain-nonspecific way
      Seems to require some way of representing the leads-to structures of the domain...
   Goal g can be reduced to g' if any action that leads to g' will lead to g
   "Note that the conditions in a program need not be exhaustive-satisfaction does not require that there be an action that leads to the goal in every situation, since this is impossible in general."
   When more than one condition and associated action is true (leads towards goal), execution of the program can pick one at random
   This is a LOT like GCPR
   Gapps programs
      set of goal reduction rules and a top-level goal-expression
      Paper defines operations on the expressions of a goal
   Reduction rules match goal expressions if their patterns can be "unified in the current binding environment"
   The binding environment is bindings of the compile time variables in the patterns of the expression under evaluation
      If the patterns match, Gapps sets up a binding environment to evaluate the rule
      Example is that acheiving the goal at(p) with the variables dist-err and angle-err reduces to if not facing(p)angle-err acheive facing(p) angle-err acheive moved-toward(p) distance-error
         In otherwords, if you're not at p, face p based on the error in your angle and move towards it based on the error in your distance from it
         At... runtime, I think, p would be substitued (bound) with a place to go
   Compiler expects that acheiving two conjunctive goals reduces to if you have one goal, maintain it and acheive the other. 
      This seems prone to combinatorial explosion in the face of multiple goals
   Supports priority lists for goals, and prioritzing methods of acheiving the goals (if one is better somehow)
      Can also prioritize acheiving a set of goals, but less-preferred goals are subsets of the set of decreasing size
         So "get me a pizza, or if you can't, get me pizza ingredients, or at least get me some of the pizza ingredients"
   Actions can be merged
      good for merging e.g. vector velocities
      Have to tell the system that velocities can always be merged, and then define how to merge them e.g. averaging

Ok, so Gapps has programs that are evaluated kind of like the way I was planning to use GCPR, but doesn't have a UI, and assumes it's being developed by a programmer, not used by a normal user. 

"From Local to Global Behavior in Intelligent Self-Assembly" has compilation of a desired end state into a set of rules for a FSM, but operates in a gridlike world and is for construction of a set of figures, rather than general action. 

"Designing Collective Behavior in a Termite-Inspired Robot Construction Team" has compilation of a desired end state into rules for local sensing and action, but for a domain consisting of construction. Not intended for real-time-like commands either. 

Looks like people either have compilation into a rule set from a high-level representation, but for closed domains, or have software development required of the user?

7/24

Human Interaction With Robot Swarms: A Survey
Andreas Kolling ; Phillip Walker ; Nilanjan Chakraborty ; Katia Sycara ; Michael Lewis
http://ieeexplore.ieee.org/document/7299280/

Survey of Human-Swarm Interaction (HSI)

Explicitly indicates that swarms are distributed, individual robots might not be effective

Reasons to have an operator
	"1) recognize and mitigate shortcomings of the autonomy; 2) have available “out-of-band” information not accessible to the autonomy and that can be utilized to increase performance; and 3) convey changes in intent as mission goals change."

Paper outlines these as reseach questions
    "How do the properties of the communication channel between operator and swarm affect HSIs, such as the ability to observe and control the swarm?"
    	I approach this with the swarm vs. cloud representation, the "no visible robots" case would also be in this area
    "How can an operator observe a swarm and its dynamics?"
    	Top-down view...
    "What are the different control methods used, and how do they affect the ability of an operator to control a swarm?"

    "What is the relevance of the notion of levels of automation in HSI and how has it been exploited and studied?"

    "How do swarm dynamics affect the ability of the operator to control the swarm?"

There are a lot of swarm taxonomies
	This paper discusses swarms based on methodologies, tasks, and algorithms
	List bioinspired, control theoretic, amorphous, and physics
		I touch on all of those except control theoretic
			Ionnas's work is control theoretic, though
		Control theory has formal methods for defining whether human control input is theoretically possible for a task
			I think programming via desired end states might sidestep this, unless you can't draw the result desired...

Mentions use of belwethers in swarm control

Task type list is of interest as "primitive" behaviors
	Aggregation and Rendezvous
	Deployment and Area Coverage
		Including art gallery problem
	Flocking and Formation control
		Control theory shows up a lot here
		Boids
	Foraging and transport
		Including minimal paths
		Caging manipulation

Cognitive complexity
	Fan-out and neglect tolerance in independent tasks
	"A different form of control, such as designating a region to be searched by drawing it on a map, can command an arbitrary number of robots with a single operator action, as long as the interactions between the robots (such as preventing collisions) can be handled autonomously. In this case, the number of actions the operator must take are independent of the number of robots, and thus, control is O(1) , allowing one (or a fixed number of) human operator(s) to control any number of robots. "
		That's what I'm shooting for
	Useful point is that if the user has to coordinate inter-robot interactions, scaling can be exponential
		So REALLY don't do that

Communication 
	State has to get back to the user somehow
		I've just kind of assumed I have a magic eye in the sky
		Although the zero robot case is of interest because it assumes your magic eye is nearly blind
	Work has been done on bandwidth as far as receiving robot updates
		don't have to have perfect data on the whole swarm
		this supports e.g. the use of the cloud view
	Proximal interaction is cool, but I'm not doing it

State Estimiation and Visualization
	-> I should include a section on this <-
		few, many, cloud, no visuals
	"For example, a visualization of forces might aid comprehension for an operator familiar with attractive and repulsive forces. Very little research, however, has investigated these ideas."
	Centroid + std Dev is sufficient for target search and navigation
		S. Nunnally, P. Walker, A. Kolling, N. Chakraborty, M. Lewis, K. Sycara, M. Goodrich, "Human influence of robotic swarms with bandwidth and localization issues"
		So my cloud model is supported

The control types they identify are 
    "switching between algorithms that implement desired swarm behaviors;"
    "changing parameters of a swarm control algorithm;"
    "indirect control of the swarm via environmental influences;"
    "control through selected swarm members, typically called leaders."
    Heh. Select None. I'm having the compiler select parameters and algorithms
    	This saves the operator from having to know how the various algorithms will cause the swarm to move/behave
    Z. Kira, M. Potter, "Exerting human control over decentralized robot swarms", Proc. 4th Int. Conf. Auton. Robot. Agents, pp. 566-571, 2009.
    	Looks interesting, in that there are virtual particles exerting pull on robots
    		Would have to check in simulation to get the right positions, and then deploy those to robots
    		Which sounds like a nightmare to make reactive in a dynamic environment
    Personality of robots + hot/cold regions in environment
    	H. Hexmoor, B. McLaughlan, M. Baker, "Swarm control in unmanned aerial vehicles", Proc. Int. Conf. Artif. Intell., pp. 911-917, 2005.
    	Seems to assume localization
    D. S. Brown, M. A. Goodrich, "Human-swarm interactions based on managing attractors", Proc. ACM/IEEE Int. Conf. Human-Robot Interaction, pp. 90-97, 2014.
    	Flocking-task only
    Environmental influences
    	Nice if you can influence the environment
    	B. Walter, A. Sannier, D. Reiners, J. Oliver, "UAV swarm control: Calculating digital pheromone fields with the GPU", J. Defense Model. Simulation: Appl. Methodol. Technol.,
    		50k drones, in simulation
    Leaders/belwethers 
    	persistent, essentially the user teleoperators a leader or leaders
    	Can also have no specific leader, but joystick an attractor or overall swarm desired direction


Research Advance in Swarm Robotics
Ying Tan, Zhong-yang Zheng
	Focus on bioinspired
	V. high-level overview, cites some stuff that might be useful if I have to e.g. justify that a particular technical challenge is surmountable

"A multi-robot coverage approach based on stigmergic communication." Multiagent system technologies (2012): 126-138.
Ranjbar-Sahraei, Bijan, Gerhard Weiss, and Ali Nakisaei. 
	Stigmurgic communication for area coverage and intruder detection
	Mentions that people have done stigmurgy with RFID and with ethanaol
	Hasn't been implmented for real yet, but simulation looks good
	Coverage based on driving in a circle and detecting when you cross over another robot's trail. 
	I could actually do this based on an overhead projector and color sensors on the robots, or the top camera looking at the color of the white areas of the april tags to determine "pheremone concentration" over the area where the robot is currently located

An Architecture for Swarm Robots
K.A.Hawick, H.A.James, J.E.Story and R.G.Shepherd
	PIC, TINI (probably not avaialable anymore), bluetooth module
	Also essentially a souped-up toy
		Used Cybot bases
	Price breakdown as of writing, in UK pounds:
		Cybot		42
		TINI 		70
		PIC 		 7
		WaveLAN    110
		misc.       18
		Total      247
	This was in 2k2, so 15 years old

Formica 
	http://warrantyvoidifremoved.com/formica
	15-24 UK pounds
	Cites a lot of other robot swarms
	DIY motor drivers, P & N MOSFETs
		Really clever merger of dual motor drivers using 6 MOSFETs instead of four, the H-bridges have a common center leg
		4 drive lines because of using P & N MOSFETs so the outside legs have common drive pins
	IR sensors
		Distance sensing to obstacles based on intensity of reflection, this is also really clever
	no wireless, at least no radio, can do IR comms
	MSP430 controller
	Direct drive by pager motors
	The entire electrical design of these things is brilliant


An Overview of Physicomimetics
William M. Spears, Diana F. Spears, Rodney Heil, Wesley Kerr, and Suranga Hettiarachchi
	robotic behaviors based on solids, liquids, and gases
	also known as artificial physics
		Doesn't have to be natural physics, can have different fields and so on
	Robot has to sense enough to detct "forces" and move enough to respond to them
	Solids and crystals for formations
		Synthetic aperature radar, beamforming
	Solid/liquid transition is controlled by a parameter balancing attractive and repulsive forces
	Gases for coverage and dispersion
		Dominated by repulsive forces
	By giving robots color plus different forces based on color, square lattices can be formed
		mimics sodium/chlorine interaction in forming salt crystals
	All done with local forces
	Rotation of moving crystal through obstacle field is an emergent quality
	Liquids can also flow through obstacles while maintaining connectivity
		Connectivity draws a lot of research, so this is a really cool result
	Adding brownian motion to gas gives it better area coverage for a sweeping traversal of an area
	Applied genetic algorithims to tune parameters
		Got good results even with losing up to 75% of the robots
		Or with losing 75% of the sensor accuracy	


Off topic, is firefly synchronization applicable to underwater gliders?
	Surface, and you can reach anyone already on the surface
	So surface, wait a random amount of time, and dive, emitting a "We dive!" signal when you do
	If you hear a "We dive!" signal, dive immediately
	Stay down for a fixed period
	I think this will eventually collect all the gliders into one synchronous swarm

Can I get battery level monitoring in my system? Maybe an ADC-capable GPIO?

Range-Sensor Based Navigation in Three Dimensions (1999)
Ishay Kamon, Elon Rimon, Ehud Rivlin
	3DBug
	Straight line to the target unless there's an obstacle
	Minimal reactive data gathering about obstacle during avoidance
	in 3 dimensions, so not a plane bug
	Bug algos in general augment local planning with a global convergence criterion
		Bug moves straight towards target (global convergence)
		When bug hits an obstacle, it switches to following the obstacle edge
			"leaving condition" causes bug to leave the edge (e.g. moving along the edge puts you further from the target)
				My example here is bad because it traps the bug in concavities
			If the bug loops (uh, detecting this might be an open question...), it decides it can't reach the target
		To decide unrechability on a 3D surface, the bug needs to check the whole surface
	3Dbug uses position and range sensors
		Localization may not be a thing...
	Cool, but makes assumptions that don't apply in my case

A Pursuit-Evasion BUG Algorithm (2001) (were bugs hot at the turn of the century?)
Stjepan Rajko, Steven M. LaValle
	PE-BUG
	Not just navigation
	No map
	Pursuer needs to find evaders
		Can see walls, and see moving evaders
	Does not require pursuer to localize
	Pursuer finds boundaries of areas it can't see by looking for discontinuities in depth graph
		This is handy for one of my personal projects!

Path-Planning Strategies for a Point Mobile Automaton Moving Amidst Unknown Obstacles of Arbitrary Shape (1987)
I. Vladimir, J. Lumelsky, and Alexander A. Stepanov
	The original bug paper
	Limited to things homeomorphic to a plane
	Provable reachability is interesting
	
Performance Comparison of Bug Navigation Algorithms
James Ng & Thomas Bräunl
	Talks about target expressed in distance and bearing
	So if the robot knows its heading, then maybe global location isn't needed
		Original bug paper used global location to determine if the perimeter of the object had been circumnavigated
	Turns out that a bug algorithm, as originally designed, isn't in itself sufficient to follow a wall
		It assumes "wall follow" is just a thing you can do
	Some practical extension of bugs to real robots
		e.g. approximating points, rather than requiring that it hit the exact coordinate
		imperfect sensing
	Sensor noise can cause bugs to not terminate, or do a bad job (incorrect termination, termination too far from target)

I-Bug: An Intensity-Based Bug Algorithm (2009)
Kamilah Taylor and Steven M. LaValle
	No precise position, no coordinate, no time, no odometry
	Signal intensity function from source
		This is handy for swarms that can do gradient signalling
	Level of signal doesn't have to be circles, but has to be topologically equivalent to circles
		Does this hold for discrete robots generating the signal field?

IBA: Intelligent Bug Algorithm – A Novel Strategy to Navigate Mobile Robots Autonomously
Muhammad Zohaib, Syed Mustafa Pasha, Nadeem Javaid, and Jamshed Iqbal
	Uses a range sensor to see if there's something between it and the target, leaves if there isn't. 
	This seems a LOT like visbug

K-Bug, A NEW BUG APPROACH FOR MOBILE ROBOT’S PATH PLANNING
Ricardo A. Langer, Leandro S. Coelho, and Gustavo H. C. Oliveira
	Goes to closest point of visible obstacles between it and the target

Ok, so there are a host of bug algorithims
	some have some userful properties for swarms
	Many make poor assumptions
		Unlimited range visual sensors
		Perfect sensing
		noiseless sensing
		point robots
		etc. 


https://mobile.aau.at/publications/jdeed-2017-Spiderino_low-cost_robot_for_swarm_research_and_educational_purposes.pdf

Well damnit 

gst-launch-1.0 v4l2src device=/dev/video0 ! "image/jpeg,width=1024,height=768" ! jpegdec ! videoconvert ! tee name=f ! queue ! v4l2sink device=/dev/video1 f. ! queue ! v4l2sink device=/dev/video2

Updated gstreamer invocation for my camera, seems to have good framerate but bad lag. I don't want any lower of a resolution, so maybe dropping the framerate will help matters?

Distributed efficient localization in swarm robotic systems using swarm intelligence algorithms
Alan Oliveira de Sá, Nadia Nedjah, Luizade Macedo Mourelle
	Uses position of reference nodes
	Range-based method
		Actual ranges can be measured
	Range-free method
		Hops, signal propagation techniques
	Paper cites a lot of other papers that do positioning
	For my work, since the actual formation of the coordinate system is out of scope, I can assume there is some form of coordinate system available, produced via one or more of these methods, and the robots can use that. 
		Should have some possible error in it. 

Swarm robotics search & rescue: A novel artificial intelligence-inspired optimization approach
M.Bakhshipour, M.Jabbari Ghadi, F.Namdari
	

Feature matching based positioning algorithm for swarm robotics☆
Ahmet Çağdaş Seçkin, Ceyhun Karpuz, Ahmet Özek
	Uses cameras under the robots, they try to align common areas of their images
	Aimed more at drones than ground robots

Efficient Strategy for Collective Navigation Control in Swarm Robotics☆
Luneque Silva Junior, Nadia Nedjah
	Wave algorithms
	Network of conneted robots
	Wave Swarm strategy to sequentialize subtasks
	Wave algo has requirements
		1. Computation is finite sequence of events
		2. Computation includes decision event
		3. In each computation ever decide-event is caused by an event in each node
	some node (initiator) starts the local algorithm and broadcasts
	others start when they get the message
	Messages don't return to nodes that they were from
	Initiator has to know when all nodes have received the message
		Propagation of information with feedback PIF
	"In the context of robotic swarms, it is necessary that all robots do the same subtask in a given instant."
		Well, no, actually it isn't. 
	Navigation together as recruitment, alignment, and movement
		Recruit to form group
		Align to all point the same way (tank-style steering)
		Move keeping distance to others
		

Multiscale Modelling and Analysis of Collective Decision Making in Swarm Robotics
Matthias Vigelius, Bernd Meyer, Geoffrey Pascoe
	Density estimation
		Robots wander randomly, bumping into each other
		Observe color (red or green) of bumped robots
		After N bumps, change to most-often observed color
		Stable, converges to most common color
	Largely done in simulation, numerical solutions to behavior of system
	Kilobot tests
		Much noisier results, but ok agreement with sim


Potential Limitations of Multi-touch Gesture Vocabulary: Differentiation, Adoption, Fatigue
Wendy Yee
	Direct gestures, like grabing/moving content (NUI basis)
	Need more abstract/indirect gestures
		Action on groups, motions through hierarchy
	Main criteria
		1. High context, should be clear that gestures can be used, and gesture should realae to task
		2. minimal effort, not a lot of dexterity
		3. Appropriate metaphors, logical relationship with the functionality
		4. Not fatiguing, ok for repetitive use
		5. Easy for the applicaiton to recognize well
	Gestures have to be distinct enough for the user to remember and execute with minimal cuing
	Full hand/arm involvement in gesture leads to fatigue

There are a lot of papers on various sensing technologies, and sub-divisons of them (e.g. camera tracking with or without fiducials, capacitive sensing, acoustic/knock approaches)

A Multi-Touch Natural User Interface Framework
Jialiang Yao, Terrence Fernando, Hongxia Wang
	Design of multitouch gestures based on field study
		Consolidated into lowlevel actions
	Aware of users inheriting preferences from the applicaitons they use (iOS & Android)
	Paper prototyped
	Designed for a VERY specific tool
		Gestures for that tool, although somewhat applicable to similar tools
		Not an attempt at a universal gesture interface (which probably wouldn't make sense)

Squidy: A Zoomable Design Environment for Natural User Interfaces
Werner A. Konig, Roman Radle, Harald Reiterer
	"post-WIMP user interfaces"
	Characterizes design and hardware support space as very fragmented
	MAX/MSP and vvvv as visual represesntations of data flow
		Hierarchical representations so that subunits can be represented as one block
	Squidy ties together a bunch of device toolkits and NUI frameworks
	Kind of like GStreamer
		sources, filters, sinks
	Graphic like vvvv or Max/MSP
		Zoomable for more info 
			Zoom in on node, get info about how it works
			Parameter setting also done in zoom
	Prototyping environmnet for NUI

Multitouch Interaction for Tangible User Interfaces
Hartmut Seichter, Raphael Grasset, Julian Looser, Mark Billinghurst
	AR + computer vision-based touch interaction
	Tangible usier interface TUI
		Physical stuff you can touch

Informing the Design of Direct-Touch Tabletops
Chia Shen, Kathy Ryall, Clifton Forlines, Alan Esenther, Frederic Vernier, Katherine Everitt, Mike Wu, Daniel Wigdor, Meredith Ringel Morris, Mark Hancock, Edward Tse
	From MERL, the DiamondTouch people
	Table as external memory, stuff on it as reminders of an ongoing task/process
	Table as collaboration point, multiple workers
	Experiments in document orientation
	Occlusion and reach
	Modal regions for gesture re-use
		use depends on mode, mode is spatial region (e.g. "edit area")
	"registration" for gesture re-use
		register gesture, then action gesture
			Kind of like Mark's gesture grammar

Experiences with and Observations of Direct-Touch Tabletops
Kathy Ryall, Meredith Ringel Morris, Katherine Everitt, Clifton Forlines, Chia Shen
	Unstructured free-form interactions
	Some people hesitate to touch the table while others are touching it
		Not a thing with my single-user interface
	Novice users prefer single-touch interaction
		"intuiutive" - probably from mouse interaction
	Midas touch problems
	Big fingers have problems with small buttons
	Hygene concerns with lots of users touching table
		...I've thought about this with my experiment too
	Users want "elbow room"
	Fingers are not good enough for touch input
		Did they explore virtual keyboards? Swype/google predictive keyboard is good
	Not all docs have orientation problems (photos less than text)

The Design and Evaluation of Multitouch Marking Menus
G. Julian Lepinski, Tovi Grossman, George Fitzmaurice
	Menus are not great on Multitouch due to low pointing accuracy
	Marking menus have high angular accuracy
	AKA radial menus
		Appear around cursor
	Backs up my assertion that gestures have scale problems in complex applicaitons
	5-finger down as in DREAM, then lift some set to chord, then stroke

User-Defined Gestures for Surface Computing
Jacob O. Wobbrock, Meredith Ringel Morris, Andrew D. Wilson
	Showed effect of gesture, asked users to perform its cause
	"Our findings indicate that users rarely care about the number of fingers they employ, that one hand is preferred to two, that desktop idioms strongly influence users’ mental models, and that some commands elicit little gestural agreement, suggesting the need for on-screen widgets"
	Backs up my assertion that designers come up with gestures and teach them to users
	Also suggests that there is a linguistic dimension to gestures
		citations of research on gesture, rather than UI design
	Users are sometimes poor at picking differentiable gestures
		I've seen users notice that they're doing this, e.g. realizing that forming a line formation and driving to a location can't both be "select robots -> draw line"
		"patrol" vs. "form a box"
			or not care that these are subtly different
	Taxonomy v. different from Mark's
	Very general gesture set, not tied to a specific task
	Interesting points about users wanting to be consistent
	Good paper, work into related work

ShadowGuides: Visualizations for In-Situ Learning of Multi-Touch and Whole-Hand Gestures
Dustin Freeman, Hrvoje Benko, Meredith Ringel Morris, Daniel Wigdor
	On-demand assistance
	Shows possible completions of gesture within interface display
		Context-aware
	Registration, continuation, movement, end life cycle for gestures
	Better-liked than video

Gesture Studio: Authoring Multi-Touch Interactions through Demonstration and Declaration
Hao Lü, Yang Li
	Tool for creating interactions, extension of Gesture Coder
	Proton uses regular expressions of gestures
		Which I think implies that a DFA can accept gestures (may have automata wrong...)
	Has to use very few examples, as otherwise it won't save dev time
	Suggests PFSM to avoid making an over-complex FSM
		Better for ambiguious gestures
	Composes state machines to recognize gestures
		May be a useful tactic for my recognizer?


Everything is a Window: Utilizing the Window Manager for Multi-Touch Interaction
Raphael Wimmer, Fabian Hennecke
	Big curved desk
	Blend of multitouch and legacy apps

Magic Desk: Bringing Multi-Touch Surfaces into Desktop Work
Xiaojun Bi, Tovi Grossman, Justin Matejka, George Fitzmaurice
	This is fitting the work to the tool rather than the other way around
	Checking where users could make gestures and how easily
	Dragging finger, docking boxes to each other
	Measured execution time and fatigue

Multitouch Finger Registration and Its Applications
Oscar Kin-Chung Au, Chiew-Lan Tai
	Seems a lot like DREAM
	Applied to pulling up a menu with menu items at finger locations

Towards a Formalization of Multi-touch Gestures 
Dietrich Kammer, Jan Wojdziak, Mandy Keck, Rainer Groh, Severin Taranko
	Lots of UI toolkits
		Each has standard set of gestures
		Adding new ones is doable but hard
	Formalizaton of gesture building blocks 
	Windows touch and TUIO lack abstraction
	Semiotics for multi-touch gestures
	Sequences of atomic gestures in a text format
	EBNF of syntax for the gesture formalism is provided
	Could use this as the intermediate language output by the gesture recognition software
		Can probably build state machine directly from EBNF
	Mapping between gestures and actual GeForMT stuff is hard
		Wiggly line "move" shape of line actually matters for my application
			Does say "Fine-grained information for each atomic gesture has to be available within the framework."
		Has no temporal character
			So no time-outs, no press&hold for N sec

Using the PyMT toolkit for HCI Research
Thomas Hansen, Christopher Denter, Mathieu Virbel
	Tech report on the framework
	Doesn't mention gestures or NUI 

Ghosts in the Interface: Meta-user Interface Visualizations as Guides for Multi-touch Interaction
Davy Vanacken, Alexandre Demeure, Kris Luyten, Karin Coninx
	Users tend to operate using one finger (I should look at this in my system)
	Invisibility/directness of interface is a leaky metaphor
		Picture of a picture isn't a picture
		So users are caught between "natural" interactions and a non-natural interface
		Invisible UI has no affordances

Taxonomy and Overview of Multi-touch Frameworks: Architecture, Scope and Features
Dietrich Kammer, Mandy Keck, Georg Freitag, Markus Wacker


Validation study papers that might be useful

Extracting Usability Information from User Interface Events
DAVID M. HILBERT AND DAVID F. REDMILES
	User interface clicks and typing need automated processing to be useful as information
	Covers techniques for workign with interaction data stream
	Application to usability
		Formative - research that guides the creation of a UI
		Summative - research that compares a UI to e.g. previous versions, judgement about finished UI
	Evaluation approaches
		Predictive - based on psych modeling approaches (GOMS (John & Kieras), Cognitive Walkthrough (Lewis et al 1992)), or expertise (Heuristic (Neilsen & Mack 1994))
		Observational - observing users interacting with the system
			What I'm planning so far
		Participative - Collecting data directly from the users, interviews and such
	Indicators
		Online behavior/performance
		Offline behavior
		Cognition/understanding
		Attitude/opinion
		Stress/anxiety (e.g. EKG/GSR)
	Events can be compose of other, usually higher-frequency events
		e.g. filling a form is composed of filling textboxes (which is composed of keystrokes) and mousing between them
	Events may have context
		click is on something, might be on a menu brought up by a previous click
	Bulk of paper is reporting on tools

Teaching Natural User Interaction Using OpenNI and the Microsoft Kinect Sensor
Norman Villaroman, Dale Rowe, Bret Swan
	Has a nice history of NUI devices
	Mostly about teaching UI design for NUI, not evaluation


The GOMS Family of User Interface Analysis Techniques: Comparison and Contrast
BONNIE E. JOHN and DAVID E. KIERAS
	By the original GOMS authors
	Goals, Operators, Methods, and Selections
	Goals
		What the user wants to do
		Can have (nested) subgoals
		multiple active at once
	Operators
		Actions the user does in service of a goal
		peception, cognition, UI interaction, etc. 
		Changes either the user's internal state or the stae of the environment
		Usually has parameters like execution time
	Methods
		Sequences of operators and subgoals to accomplish a goal
	Selections
		How the user chooses which operators and methods to use
	Method vs Operator is level of detail chosen by the person doing the study
	Rest of paper compares some GOMS-descended models
	Seems to be about evaluating UI that already has commands, rather than finding the commands
	May be worth revisiting, but seems more for optimization than creation


Gestures without Libraries, Toolkits or Training: A $1 Recognizer for User Interface Prototypes
Jacob O. Wobbrock, Andrew D. Wilson, Yang Li
	Gesture recognition can be tricky
	Mentions Dynamic Time Warping, HMM, ANN, feature-based classifiers
	single-stroke gestures
	4 steps
		1 resample the point path (velocity invariance)
			convert to N equidistant points
			N=64 found to be pretty good, 32 <= N <= 256 seemed fine
			squares well with speed to point density relation on the 3M screen
			calculate the overall path lenght, divide by N-1, linear interpolate
		2 rotate based on the "indicatitive angle" (rotation invariance)
			angle between first point and centroid
			rotate to point to 0 (off to the left), or really any fixed angle
		3 scale and translate (location and scale invariance)
			scale to a fixed size square and put the centroid at the origin
		4 find angle for best score
			compare to each template based on distance between corresponding points
			rotate to best match 
				continuious, so can do searches
				can brute force, paper lists a better approach
	Can probably be extended to multitouch
		Points ordered by contact point and by time
		possibly doesn't even need that, as long as the gesture is bounded
		seperating two gestures at the same time from one multi-point gesture is problematic
			Try all contact points together, then pairs?
			Or the other way around. Which is better?
	Can't tell e.g. rectangle from square, up from down arrow
	Can't actually recognize my "drag" command, as it has no fixed shape
	Can't tell the various box selects apart
	Can detect pinch, tap, lasso (as circle)
	Circle is lasso based on context
		box select and cut-line divide are ambiguious, esp. under this recognizer

Wiimote and Kinect: Gestural User Interfaces add a Natural third dimension to HCI.
Rita Francese, Ignazio Passero, Genoveffa Tortora
	Evaluation metrics are subjective usability, presence, immersion
	"Natural user interfaces disappear behind the content, and
direct manipulation style (e.g., touch, voice commands and
gestures) is the primary interaction method adopted [2, 10].
Despite that, too often the window/icons/mouse metaphors
contaminate the gestural interfaces vanishing their efficacy
[28], the user is involved in a frustrating experience: the
motion capture based interface fails in being effective since
it’s used only for mimicking the classic mouse interaction."
		Yeah, that would be nice. What actually happens is that the users drag that stuff in anyway. 
		Describes a couple of intefaces using Kinect and Wiimote to fly around Bing maps

Touch-Based User Interface for Elderly Users
Juha Häikiö et al
	Touch phone to appropriate tag for NFC communication to order food
	"elderly persons who were eligible for home care provided by the town."
		Living in a first-world country must be nice
	Not entirely NUI, but easy to use, even on limited UI cell phone

USABILITY ENGINEERING METHODS FOR SOFTWARE Developers
Andreas Holzinger
	Inspection
		Cognitive Walkthrough
			Task oriented
			analyist steps through a task taking notes
		Heuristic (Neilsen)
		Action Analysis
	Test
		Think-aloud
		Field Observation
		Questionnaires
	Qualities
		Learnability - rapid start to working with the system
		Efficiency - high productivity in use
		Memorability - minimal need to relearn after non-use
		low error rate - few and easy-to-fix errors
		satisfaction - pleasant to use (subjective, unless you count stress via GSR)
	My design is intended to get:
		learnability and memorability by discovery of gestures
		efficiency by hopefully having users make good choices for gestures
	Validataion should check
		low error rate - users complete tasks
		satisfaction - what did users think of system results

The Future of Natural User Interfaces
Jhilmil Jain, Arnie Lund, Dennis Wixon
	Just a description of a SIG

Using Metaphors to Create a Natural User Interface for Microsoft Surface
Kay Hofmeester, Dennis Wixon
	Metaphors as guides to understanding and prediction
	UI as a world with rules and behaviors
	"During the sessions, we asked participants to sketch out their ideas on napkins."
		This is too twee for words
	Early surface, emphasis on multi-person computing
	Interesting overview of design process, not relevant to my work

Heuristic Evaluation of UI
Jakob Nielsen and Rolf Molich
	Evaluators are presented with a design and asked to comment on it
	Individial evaluators are pretty bad (they miss a lot)
	Aggregating them covers the gaps
	Distinct from 
		Formal
			some analysis technique (GOMS?)
		Automatic
			Computerized proceedure for testing
		Empirically
			Experiments with test users
	Molich/Nielsen 9 principles
		Simple and Natural dialog
		Speak the user's language
		Minimize memory load
		Be consistent
		Provide feedback
		Provide clearly marked exits
		Provide shortcuts
		Have good error messages 
		Prevent errors
	Not going to cut it for my PhD, though, since I have to do an emperical test

Usability Inspection Methods
Jakob Nielsen
	Heursitic
		Experts judge the interface using established rules
	Cognitive walkthrough
		detailed proceedure to simulate user problem solving
	Formal inspection
		Combines Heuristic & Cognitive Walkthrough in a detailed proceedure
	Pluralistic Walkthrough
		User, devs, human-factors people all do Cog. Walk. together
	Feature inspection
		sequence of features to accomplish a task, looking for long/cumbersome sequences
	Consistency inspection
		Devs from other projects check that interface does things the same way as theirs
	Standards inspection
		Expert on a standard checks for compliance with it
			Nielsen has a paper on the usability of usability standards that addresses this
				People following a standard are like people following a heuristic
				They miss a lot of things, but if you have enough of them, it will still help

The conceptualization and empirical validation of web site user satisfaction
Steve Muylle a,* , Rudy Moenaert b , Marc Despontin c
	Very web-site oriented
	Interesting dimensional breakdown of "satisfaction", but not relevant for my system
		Large elements of satsifaction were based in hyper-media specific attributes


TASK-CENTERED USER INTERFACE DESIGN
A Practical Introduction
by Clayton Lewis and John Rieman
	Points out that test users should be representative of target population
	I don't, at this point, have a target population
	That said, "college-educated people" seems like something I'd expect of swarm robot users
	Has some math for doing comparisons
	Interesting overview

Since I don't have a target population, the main things I'm looking for are that the user interface
	1. Allows the users to complete the tasks, and
	2. Doesn't have them do a lot of unneeded flailing

Detecting flailing
	-making gestures that the system cannot interpret as commands
	-making gestures that are interpreted as commands, but miss the user's intention
		- for the experiment, have the user state their high-level intention before interacting
		- plan-out-loud before doing the actual interactions, describe their strategy

Beyond Fingers and Thumbs – A Graceful Touch UI
Elegant Multi-touch and Gesture UI with Context Dependent Prompting
Sue Hessey, Szu Han Chen, and Catherine White
	Leap-motion-based approach with in-air finger sensing

A review of swarm robotics tasks (2014)
Levent Bayındır
	Seems to pretty much be the hierarchy paper I was working on
	Good paper to cite for overview reasons


Evolution of swarm robotics systems with novelty search
Jorge Gomes, Paulo Urbano, Anders Lyhne Christensen
	Search rewards novelty (difference from previous solutions) rather than fitness
	Has to be combined with fitness in some way 
		Otherwise you get "solutions" that are novel but bad
	Interesting approach, I'm not doing evolution for time reasons

The TAM: abstracting complex tasks in swarm robotics research
Arne Brutschy · Lorenzo Garattoni · Manuele Brambilla ·
Gianpiero Francesca · Giovanni Pini · Marco Dorigo · Mauro Birattari
	e.g. foraging doesn't actually handle the object, just goes between locations
	A little booth for an e-puck
		Being in the booth for a given amount of time is "doing the task"
	TAM can react to e-puck with changing colors
	Has a citation for Arduino, which would be good to have for my hardware paper

Beyond kappa: A review of interrater agreement measures
Mousumi BANERJEE, Michelle CAPOZZOLI, Laura McSWEENEY, and Debajyoti SINHA
	C's K is to avoid agreement by chance
	Fleiss generalized to >2 raters
	K is biased by true prevalence of a label in the population
		Can get high K just by having a thing that's way more common
			Drag gestures are SUPER common
	Covers a lot of genrealizations of Kappa, predates Krippendorff

Massive Uniform Manipulation:
Controlling Large Populations of Simple Robots with a Common Input Signal
Aaron Becker, Golnaz Habibi, Justin Werfel, Michael Rubenstein, and James McLurkin
	All robots get the same inputs and move uniformly
	Apparently having one obstacle to pile up against allows many manipulation tasks
	Fig. 1 shows a lot of different obstacles
	Apparently a single square obstacle is sufficient for controlling the final position of every robot
	Later figures show that you can draw the Mona Lisa with it

Collective decision with 100 Kilobots: speed versus accuracy in binary discrimination problems
Gabriele Valentini · Eliseo Ferrante 2 · Heiko Hamann · Marco Dorigo 
	Collective decision making
	Not sure any of my swarm tasks require decision at collective level
		In fact, I don't add a lot of autonomy at all
	Iterative, local, asynchronous
	Agents advertise opinion for time based on assessed quality
		Better quality, longer time
	Agents change their opinion to majority of neighbors
		See a lot more of option A if it's the better option, because more time is spent signalling it
	Neightborhood size affects time/accuracy tradeoff
	Can be represened as differential equations or chemical reaction network

Leader Election Algorithims for Static Swarms
Valery Karpov, Irina Karpova
	Keeps using "simple" in different ways
	Iterative voting with local sensing of votes, v. like quorum and "Collective decision with 100 Kilobots"

Topological Mapping of Unknown Environments using an Unlocalized Robotic Swarm
Alireza Dirafzoon and Edgar Lobaton
	Uses proximity of other anges and times of encounter
	Gives topology (connectedness, holes)
	Does not give metrics 

Exploring a user‐defined gesture vocabulary for descriptive mid‐air interactions
Hessam Jahani · Manolya Kavakli
	Analysis techniques may be useful, also my brain isn't working, WTF

Design and Development of an Inexpensive Aquatic Swarm Robotics System
Vasco Costa, Miguel Duarte, Tiago Rodrigues, Sancho Moura Oliveira and Anders Lyhne Christensen
	Inexpensive swarm robot aquatic surface vessels
	300EU materials
	Pi 2, GPS, magnetic heading sensor, dual brusheless motors

Investigating the effect of increasing robot group sizes on the human psychophysiological state in the context of human–swarm interaction
Gaëtan Podevijn, Rehan O’Grady, Nithin Mathews, Audrey Gilles 2, Carole Fantini-Hauwel, Marco Dorigo
	GSR and heart rate, plus self-reported metrics
	N=24
	"Passive interaction"
		Human sits in chair, robots come out of a little compartment and surround them
	1, 3, or 24 robots
	45s of exposure
	Robots do random walk with obstacle avoid
	E-pucks, so about the size of a coffee cup
	Results: 24 robots gets stronger reaction
		Reaction is generally positive, people are happy/excited


Electroencephalography as implicit communication channel for proximal interaction between humans and robot swarms
Luca Mondada, Mohammad Ehsanul Karim, Francesco Mondada
	LED on robot blinks at fixed frequency
	Steady-state visually-evoked potential in human checked for frequency
	Match human frequency to robot, and you know what robot they are paying attention to
	Simplified selection
	Used Emotive EPOC (looked at OpenEEG too, v. difficult to deploy)
	Works, but not terribly great, 75% average correct recognition

Evolving Neural Networks through Augmenting Topologies
Kenneth O. Stanley, Risto Miikkulainen
	Evolving topology to save humans the time of picking a topology
		Afer all, a fully connected network can approximate any continuious function
		...so why not choose a fully connected network every time?
	Keeps historical information on origin of genes
		Used to ensure that crossover doesn't trash useful genes
			E.g. an organism needs at least one copy of gene A to be useful, so keep at least one gene that is A-descended
	Random starting population is bad
		Some chance that members have e.g. no path from input to output
		Lots of unneeded parameters
			Want to start minimal, for fast searching
	Similar topologies are assigned to niches, compete with each other
		Allows topological changes that may initially reduce fitness to become useful
	
An indirect adaptive robot controller
	Weiping Li, Jean-Jacques E. Slotine
	Manipulator control, in the late 80's
	Concerned with tracking and adaption, possibly to change in the manipulator due to other forces?
	I suspect a lot of this is rolled into modern controllers at a level below what most people care about. 
	Similar to motion in space (the controller drives the manipulator to a path)

Exponential Convergence of a Learning Controller for Robot Manipulators 
Roberto Horowitz, William Messner, and John B. Moore 
	Early 90s, learning controller
	Didn't really get the math in this one

A Robust Adaptive Robot Controller 
Harry Berghuis, Romeo Ortega, and Henk Nijmeijer 
	Also early 90's
	Also gnarly control theory math, I'm just writing down the terms I don't understand for looking up later

A Brachiating Robot Controller
Jun Nakanishi, Toshio Fukuda, Daniel E. Koditschek
	y2k, so more modern than the others by about 10 years. 
	Seems to have different methods of proving the controller works for different motion tasks
	Again, the math is out of my league

Optimal Design of CMAC Neural-Network Controller for Robot Manipulators
Young H. Kim and Frank L. Lewis
	1997
	Neural network dealing with nonlinear effects on top of a linear controller
	
Decentralized controllers for shape generation with robotic swarms
M. Ani Hsieh, Vijay Kumar, and Luiz Chaimowicz		
	2008
	Typical swarm robot description, no communication of internal state
	Uses an artificial potential function for inter-robot interaction and location
		It operates in a coordinate frame, in other words
	But the math is simple enough that I get it!
		The system is in equilibrium when no robots are moving
		q-dot = v = 0 (change in position and velocity are zero)
		Change in velocity is given by the potential field and driving towards the desired curve
		So when the potential field and driving force drop to zero, the system is in equilibrium
	Almost...
		They then break out a big function that looks suspiciously like the forms of some of the Lypunov function canidates from the previous papers. 
	Once they have the proofs of driving to a simple closed curve, they then generalize to RBFs
		Shapes can then be generated to create a vector feild with an ... arbitrary zero isocontour?
		Probably closed forms only, an isocontour can't have a gap in it
			(in practice, you could just add a "And don't be in this area" term)
	Paper also points out that doing pattern generation in a coordinate frame without localization is "difficult"


Controlling Swarms of Robots Using Interpolated Implicit Functions
Luiz Chaimowicz, Nathan D. Michael, Vijay Kumar
2005
	Radial basis functions for 2d curves, as in previous paper. 
	They also use holonomic robots, which is nice

Cooperative transport by ants and robots
C. Ronald Kube, Eric Bonabeau
2000
	Uses finite state machines for control
	Doesn't really talk about proof, but has some demonstrations


SYNTHESIS OF WHOLE-BODY BEHAVIORS THROUGH HIERARCHICAL CONTROL OF BEHAVIORAL PRIMITIVES
Luis Sentis and Oussama Khatib
2005
	Swaps behaviors during movement
	Control heirarchy to avoid problems with safety/running into stuff
	"Null space" at one point is a space of motion with no effects on preceeding levels of heirarchy	

Using Controller-Synthesis Techniques to Build
Property-Enforcing Layers
Karine Altisen, Aurelie Clodic, Florence Maraninchi, and Eric Rutten
	Intermediate layer that enforces constraints of an entire system 
	May delay or prevent requests to the system that violate constraints
	Controller synthesis with Mealy machines
	Theoretical results on automata, so I may be able to generalize from expressing my robot control programs as automata and then getting the formal results there.

On Formal Specification of Emergent Behaviours in Swarm Robotic Systems
Alan FT Winfield, Jin Sa, Mari-Carmen Fernandez-Gago, Clare Dixon, Michael Fisher
	Mentions a previous paper with a description of a 'dependable swarm' (Winfield et all 2005)
	Also cites some other papers on modeling of swarms

	Suggested method is:
	"1. Formally specify the individual robots , including their safety and liveness properties.
	2. Formally specify the swarm by combining the specifications of individual robots.
	3. Formally specify any anticipated or desired emergent behaviours.
	4. Carry out proofs to determine if the swarm specification satisfies any of the emergent behaviours"
		The problem with doing this on my swarm is that the desired emergent behavior is specified by the user.

	Safeness vs. Liveness makes sense for me to examine
		Safeness is the set of actions that don't break the system
			Only safeness -> nothing is certain to happen
		Liveness specifies what wil occur
			Only liveness -> nothing is guaranteed to not break

	Specification is in the form of logic, which I understand a LOT better than control theory.
	Enforces asyncrony, only one robot may be taking an action at a time
		this is a hell of a constraint for a swarm...
	Bah. Paper then goes on to say what they're looking into for automated proofs, but not that they actually have proved anything yet. 
		Mapping spec into monodic first order temporal logic
			Solver called TeMP to carry out the proofs
			They note that it takes a long time. I wonder if anyone has done GPU-based logic provers?
				(Yes)

The Freeze-Tag Problem: How to Wake Up a Swarm of Robots
Esther M. Arkin, Michael A. Bender, Sandor P. Fekete, Joseph S. B. Mitchell, Martin Skutella
	Interesting proof technique (exchange argument)

Algorithms for Rapidly Dispersing Robot Swarms in Unknown Environments
Tien-Ruey Hsiang, Esther M. Arkin, Michael A. Bender, Sandor P. Fekete, and Joseph S. B. Mitchell
	Artifical physics has no guarantees on dispersion time
	Greedy algorithms can enter loops and never complete dispersion
	Uses proofs on states of robots and "pixels" of the environment that the robot can occupy
	Discretizes movement and position

Stochastic  Strategies  for  a  Swarm  Robotic  Assembly  System
Loıc Matthey, Spring Berman and Vijay Kumar
	Modeled using chemical reaction network (CRN)
	Robots assembling parts scattered randomly around a space
	Stochastic control policies
	Conversion of chemical reaction network into an ODE abstraction
		Couldn't use eignevalues due to difficulty finding an anlytic expression
		Estimated time to completion by linearizing around equilibrium
			Optimized estimated time to completion

Pattern Generation with Multiple Robots
Mong-ying A. Hsieh and Vijay Kumar
	Similar to the other papers from Kumar's group's work
	Adds constraint to maintain communication network
	

Notes on Assessment of swarm robotic systems
============================================

Open-hardware e-puck Linux extension board for experimental swarm robotics research
Wenguo Liu, Alan FT Winfield
Basically just an ARM9 board for the epuck to let people run linux on it
	Raspberry Pi would do this now

Human Interaction with Robot Swarms: A Survey
Andreas Kolling, Phillip Walker, Nilanjan Chakraborty, Katia Sycara, Michael Lewis
	"But the presence of a human operator
	can be beneficial and even necessary since the operator could
	(a) recognize and mitigate shortcomings of the autonomy, (b)
	have available ”out of band” information not accessible to the
	autonomy and that can be utilized to increase performance,
	and (c) convey changes in intent as mission goals change."

http://robotics.cse.tamu.edu/dshell/cs689/papers/holland99stigmergy.pdf
Interesting paper on collection and clustering of frisbees by robots using stigmergy
Assessment seems to just be based on examining overhead cam images and seeing how frisbees are clustered
	Cutoff for assessment was that 90% of frisbees were in a cluster
	Assessments were very specific to the various algorithms being tested

https://www.researchgate.net/profile/Ramon_Estana/publication/221116450_The_I-SWARM_Project_Intelligent_Small_World_Autonomous_Robots_for_Micro-manipulation/links/5666c35608ae418a786f52e8/The-I-SWARM-Project-Intelligent-Small-World-Autonomous-Robots-for-Micro-manipulation.pdf
The I-SWARM Project:Intelligent Small World Autonomous Robots for Micro-manipulation
Jorg Seyfried, Marc Szymanski, Natalie Bender,Ramon Estana, Michael Thiel, and Heinz Worn
Good overview of Iswarm goals, but no assessment, just brainstorming

AutoMoDe: A novel approach to the automatic design of control software for robot swarms
Gianpiero Francesca, Manuele Brambilla, Arne Brutschy, Vito Trianni, Mauro Biratta
Optomizes a task-specific objective function for the transition rules and parameters of a PFSM composed of parametric modules
Aggregation and foraging tasks
Authors feel that evolving software is prone to exploiting simulation because the simulation is regular and predictable, while the dynamic and complex environment being simulated is not
	This is actually a really interesting point
	They further claim that the use of e.g. ANNs to have high representational power allows this sort of exploitation
		You can't exploit what you're not smart enough to model
		Reality gap as an example of overfitting to the simulation
	Parametric models in a PFSM probably has some mathematical relationship to GCPR
		Esp. if GCPR actions are the modular components
			I wasn't doing this in favor of trying to generate as much as possible, but e.g. "turn to heading" is kind of like that
	Also pretty similar to behavior-based robotics
Bias-variance tradeoff
	Being able to reproduce any input-output mapping results in being v. sensitive to the elements in the training set
	Adding variability/noise to training data helps reduce this
	But swarm state is exponential in number of robots
	Can also reduce the ability to represent all possible mappings
		By reducing representational power
Has to be adapted to a specific model of robot
	reference model of the robot
		created by an expert
	modules use the reference model robot
		can be reused
Control cycle sounds a lot like GCPR cycle as well
	But not binary predicates
Behaviors used in the paper
	Explore (wander/obstacle avoid)
	Stop
	Move towards light (with obstacle avoid)
	Move away from light (with obstacle avoid)
	Go towards the robots nearby (with obstacle avoid)
	Go away from the robots nearby (with obstacle avoid)
Conditions
	Floor color is black|grey|white
	Neighbor count (probablistic transition with a threshold)
	Inverted neighbor count
	Fixed probablity
Optimization using F-Race
	Iterative, done in simulation, gets rid of low performers
Limited number of states and transitions
	Intended to minimize complexity, paper uses 4 states and up to 4 transitions each
Assessment
	Aggregation objective function is the max number of robots in one black area of arena over total number of robots
	Foraging objective function is count of trips between source location (black) and home (white, marked with light)
	Performance on both tasks is compared to evostick (neural network algorithim for robot controllers)
	Compared simulation and real for both systems
		evostick has reality gap problems
			robots in simulation interfered with each other less
			robots in sim had a larger turning radius than in reality (problem with model of e-puck?)
		automode doesn't have them, and outperforms evostick
What this doesn't have that mine does is direct user input into how the task is done.

http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5571&rep=rep1&type=pdf
Assessment in simulation
	Specific to task, motion of a box using limited sensors and Adaptive Logic Network
	Distance traveled, success of moving the target object 100 units in any direction
		Not in a user-specified direction
Mentions need of ability to measure progress and avoid stagnation (balanced forces on box) and cyclic behavior

https://dash.harvard.edu/bitstream/handle/1/8954815/ICRA11_Final.pdf?sequence=1
Design of Control Policies for Spatially Inhomogeneous Robot Swarms with Application to Commercial Pollination
Spring Berman, Vijay Kumar, and Radhika Nagpal
Supervisor computes parameters for robots and task transitions, and broadcasts to swarm
	Sounds like AutoMoDe
	Brings up connection to chemical reaction systems as well
Fluid dynamic model of robot motion, rather than e.g. grid-based
	Mathematically, this seems a little over the top. 
	Transition in eq. 19 looks a lot like the stuff from GCPR papers
Assessment was based on concentrations of types of pollen in a simulated raspberry patch
Model used to set control paramters for robobees, which then moved pollen around

https://www.researchgate.net/profile/Maja_Mataric/publication/224658369_Minimizing_complexity_in_controlling_a_mobile_robot_population/links/0c96052747a2ce920b000000.pdf
Assessment of various conditions for robot awareness
Score was time to get all robots to goal in homing task
	Ignorant co-existence
		inter-robot interference caused problems when robots treated each other as obstacles
	Informed co-existence
		Robots stopped and let each other pass
	Intelligent co-existence
		Robots used information about relative density to arbitrate behavior

https://www.researchgate.net/profile/Andry_Tanoto/publication/4363364_Analysis_and_design_of_human-robot_swarm_interaction_in_firefighting/links/09e41512f50aeabee6000000.pdf
Guardian system for firefighters
Assessment plans "are being prepared", requires system to be working first

AutoMoDe-Chocolate: automatic design of control software for robot swarms 
Gianpiero Francesca, Manuele Brambilla
Arne Brutschy, Lorenzo Garattoni, Roman Miletitch, Gaëtan Podevijn, Andreagiovanni Reina, Touraj Soleymani, Mattia Salvaro, Carlo Pinciroli, Franco Mascia, Vito Trianni, Mauro Birattari
Chocolate is Vanilla, only with a better optimization strategy
Assessment shows that it outdoes a human designer
	Vanilla got beaten by a human using the same modules that vanilla could use
Seems to support the idea that the performance measure is specified in terms of the task required
	So there isn't going to be a universal performance measure
The various AutoMoDe flavors don't seem to have support for teamwork, so much as some degree of emergence based on treating the other robots positions as an input
	There are not, for example, communication methods other than being present or absent
Bunch more tasks
	Shelter with confined access
	Largest covering network
	Cover with forbidden areas
	Surface and Perimeter Coverage
	Aggregation with ambient cues
Performance measure specified by experts, varies with task
Also, Vanilla and evostick both take over 2 hours on a 400-core cluster
	200k executions of ARGoS

A Distributed Feedback Mechanism to Regulate Wall Construction by a Robotic Swarm
Robert L. Stewart and R. Andrew Russell 
	Assessed in terms of wall constuction, minimizing robot "frustration"

Swarm Intell Swarm robotics: a review from the swarm engineering perspective
Manuele Brambilla, Eliseo Ferrante, Mauro Birattari, Marco Dorigo
I think I have other notes on this higher up in this file, mostly looking at assessment now
2013, surely something has happened in 5 years
	If not, what would prevent it?
	"Unfortunately, in swarm robotics there are
	still no formal or precise ways to design individual level behaviors that produce
	the  desired  collective  behavior.  The  intuition  of  the  human  designer  is  still  the
	main ingredient in the development of swarm robotics systems."
PFSMs are more or less the way it's done
	AutoMoDe is a PFSM testing system
	Formal design of PFSM rather than iterative assessment might be faster, if more complex
Analysis
	Microscopic - individual robots and robot-to-robot or robot-to-environment interactions
		Varying abstraction levels, point robots, 2d with kinematics, 3d with physics, etc. 
		Done in simulation 
			This isn't analysis so much as it is an enabler of trial and error
	Macroscopic
		Rate and differential equations
			The robobees, mass flow and turbulence 
			Can be derived from a PFSM
				Paper has sketch of method
			Still seems inclined towards task specific models of assessment
			Doesn't model space and time
				So implies that robots can be anywhere at any time
			Langevin and Fokker-Plank equations
				Model robot as partially stochastic fluid flow
			Still doesn't cover communications, but at least adds spatial aspects
		Classical control theory
			Tends to rely on assumptions that don't hold
				Point robots with holonomic steering and perfect sensing in the presence of global information
		Probablistic model checking
			Konur 2012, Brambilla et al 2012
		Linear Temporal Logic
			Safety and aliveness, a la Hadas
		A lot of the macroscopic with other apporaches was then "validated in simulation"
			So demonstrated first mathematically, and then in simulation
"Verification and validation.
Verification and validation exploit analysis methods,
which have been discussed in detail in Section 2.2. Despite the great number of
analysis methods, performing verification and validation of a swarm robotics sys-
tem  and  comparing  one  system  with  another  are  still  very  difficult  tasks.  The
reason  behind  this  is  the  lack  of  well  defined  metrics  and  testbed  applications.
Very often, metrics are too tightly related to a specific solution and thus cannot
be reused for other systems or for comparisons. The lack of common metrics is
also related to the lack of well defined testbed applications. As said, foraging and
construction are the only commonly used testbed applications. However, foraging
is limited in its use to some collective behaviors, such as task allocation or area
coverage and cannot be used in others. Moreover, as discussed in the taxonomy
presented by Winfield (2009), there is no single definition of a standard foraging
scenario. In order to promote the comparison of swarm robotics systems, it would
be necessary to define a set of standard foraging scenarios and promote the distri-
bution of open-source behaviors and public available datasets. Construction, as a
testbed, suffers from similar limitations."
	So yeah, still no consistent set of tests and methods, nothing across all swarms or even across all tasks


http://www.dtic.mil/dtic/tr/fulltext/u2/a445596.pdf
Has a section on performance of a plan
Partial plans on limited information to obtain a subgoal

https://drum.lib.umd.edu/bitstream/handle/1903/6383/TR_2003-35.pdf;sequence=1
On the Structural Complexity of the Motion Description Language MDLe
	MDLe sounds a lot like a continuious rather than a discrete finite state aautomaton (an infinite state automaton?)

https://smartech.gatech.edu/bitstream/handle/1853/38598/04739185.pdf
MDLn
	For networked systems

Control Strategies for Mobile Robot With Obstacle Avoidance
M. Zohaib, M. Pasha, R. A. Riaz, N. Javaid, M. Ilahi, R. D. Khan
Overview, no new info
	Bug algos - provably correct, non-optimal paths
	Potential field - gets stuck in local minima
	VFH - better path, more computation
	Gap following - trapped by U-shaped obstacles
	New Hybrid Navigation - complete, requires a map (at which point you use A* instead)

An Improved Tangent Bug Method Integrated with Artificial Potential Field for Multi-robot Path Planning
Emam Fathy Mohamed, Khaled El-Metwally, A.R. Hanafy
Potential field is great for formations, allows robots to clump together dynamically
Some can get trapped in a local minimum
Need to detect that they're trapped to switch to modified tangent-bug
Uses minimum safe distance to switch between potential field and tangent-bug
	So if the distance is set larger than the field trap range, it doesn't get trapped

A New Bug-type Navigation Algorithm Considering Practical Implementation Issues for Mobile Robots 
Yi Zhu, Tao Zhang, Jingyan Song, Xiaqin Li 	
Testing bug algo on a real robot
Uses distance histogram/gap follow for local movement

A new bug-type navigation algorithm for mobile robots in unknown environments containing moving obstacles
Yi Zhu, Tao Zhang, Jingyan Song and Xiaqin Li
Distance Histogram bug algo (DH-Bug)
A lot of the same area as the other paper by them
	Points out some good reasons you can't have convergence in dynamic environments
		Goal accessability may change
		Changes can't be predicted
		Moving objects might be fast and mean enough to try to hit you

Gap Navigation Trees: Minimal
Representation for Visibility-based Tasks
Benjamın Tovar, Luis Guilamo, and Steven M. LaValle
Gap navigation tree data structure
Gap is sudden transition in distance from robot
	uses e.g. a 360 degree range sensor
	actually even simpler, a 360 degree gap sensor, no metric range
Move towards gaps
	Assumes a point robot
Gaps appear or disappear as a result of movement
	Tree maintained by adding or removing gaps
Can't tell obstacles apart
Will loop around circles forever (gap chasing tangent) unless it drops a pebble first
	"pebbles" mean localization, usually robots don't actually carry pebbles


--> IS AUTOMATICLY-MODIFIED TANGENT BUG THE "HOLY GRAIL"? <--
Tangent Bug can be erpresented as DFA
GCPR as PFA
Composition via substitution of states for various tasks
Admits relatively easy modeling of programs

Computer-Aided Compositional Design and Verification for Modular Robots
Tarik Tosun, Gangyuan Jing, Hadas Kress-Gazit, and Mark Yi
Series-parallel action graphs
Create complex behaviors by composition of simpler ones
Behaviors are supported by physical configurations of the robot
	Other behavior approaches are for cyclic behaviors
	gait tables, phased automata, hormone and role-based control
Uses domino timing, so actions can be blocked by failures
	Timeouts allow actions to progress, but may not succeed
		e.g. attempts to close gripper, doesn't do it in time, continues with gripper open
Composed in series (execute one after another) or parallel (execute at the same time)
Intended to trade richness for programmer time
	So not a fully-featured plan execution model
Checks physical stability, self-collision, conflict between commanded actions, simulated over-torque and other forces
Users still have to come up with configurations to compose
	Not that bad, since they can be created by composition, and checked automatically


Directed Graphs and Motion Description Languages for Robot Navigation and Control
D. Hristu-Varsakelis and S. Andersson
Abstract seems like Maja Mataric's landmark based navigation from the '80s
MDLe uses time and interrupt conditions to control actions
	"kinetic state machine"
Statememts in MDLe were of the form (atom (condition) (action))
Plans are a sequence of statements
Going from lab1 to lab2 could be expressed as going lab1 to office, then office to lab2
 	builds local landmarks (lab1, office, etc)
 	Combines via simple sequences of MDLe
 Landmarks recognized with rich sensor information
 Paths much sparser

Navigation Strategies for Multiple Autonomous Mobile Robots Moving in Formation 
P. K. C. Wang 
Implementable navigation strategies for fleets in formation
How are perturbations delt with?
Particle robots with a cone of vision
	Control-theoretic view of a number of swarm flocking algorithms 
	Doesn't include collision avoidance strategies
Needs communication and visibility at all times
Nice theoretical work, but not useful for my system

Robotic Urban Search and Rescue: A Surveyfrom the Control Perspective
Yugang Liu, Goldie Nejat
Has a good overview of multi-robot in USAR
Multi-robot more than swarm, though
	Very few collaborative approaches

A Simple Local Path Planning Algorithm for Autonomous Mobile Robots 
Buniyamin N., Wan Ngah W.A.J., Sariff N., Mohamad Z. 
Point- Bug Seems a bit like TangentBug, but maybe simpler sensing

Sensory-Based Motion Planning with Global Proofs
Ishay  Kamon and  Ehud  Rivlin
DistBug, uses distance sensors
Tested on a real robot
Some of this write-up sounds a lot like Emam Fathy Mohamed, Khaled El-Metwally, A.R. Hanafy bagging on local minima in potential fields
	Probably to be expected, similar topics and similar motivation

Compiler testing using a sentence generator
Celentano, A., Reghizzi, S. C., Vigna, P. D., Ghezzi, C., Granata, G., & Savoretti, F.
Produces compilable programs 
	from BNF 
	plus some actions to e.g. keep variable names consistent
Lists a bunch of correctnesses
	"Lexical correctness: the program tokens are well formed. 
	Syntactical (or context-free) correctness: the program structure is derived according to its formal context-free description. 
	Compile-time correctness: the program can be compiled without diagnostic messages (i.e. it is syntactically correct and satisfies context dependencies). 
	Run-time correctness: the program can be executed without run-time errors such as infinite loops or arithmetic faults (i.e. it is correct with respect to the syntax, the context dependencies and the semantics). 
	Logical correctness: the program can be executed and it produces the expected results."
Compiler checkers don't need to care about runtime and logical errors. 
	Those are the programmer's problem. The compiler doesn't put them in. 

Since I'm doing a BNF-like expression of the language for the parser, I can operate this, generate programs, and then run them. Might not end up doing anything useful, though. 
	I think maybe this work predates tools that generated compilers 
		It's from 1980 or so
	And so it's more for compilers that people hacked on and defined the language for later
Generator only automates input production, human has to check that object code is right
	If it could generate test object code too, it would be the (correct) compiler


Will You Still Compile Me Tomorrow? Static Cross-Version Compiler Validation
Chris Hawblitzel, Shuvendu K. Lahiri, Kshama Pawar, Hammad Hashmi, Sedar Gokbulut, Lakshan Fernando, Dave Detlefs, and Scott Wadsworth
Checks for semantically equivalent assembly from various versions of the compiler
	Same input, 2 compilers, should have the "same" output
Compiler validation vs Tranlation Validation
	CV - theorem prover on the compiler, so all compiler output is valid for all valid source programs
	TV - theorem prober on the output of a compilation, to check that translation is semantically equivalent to source. 
		Isn't actually decidable, so prone to false alarms
	As of 2013, compiler verification has scaled to moderately-sized research compilers
Cross-version validation can miss bugs that have always been there
	TV can catch these, one hopes
Validator translates everything into Boogie, which is statically checkable for validity
I'm not running on a defined machine architecture
	So I don't have to worry about assembly language sequences that are legit operations,
	but don't do what the original source code says. 

	

Supervisory control theory applied to swarm robotics
Yuri K . Lopes, Stefan M. Trenkwalder, André B. Leal, Tony J. Dodd, Roderich Groß
	Formal methods don't guarntee that the implementation matches the spec
		because the control code is generated manually
		Experiments on real robots (e-pucks and kilobots)
	Supervisory control theory
		formally synthesizes controllers called "supervisors"
			Not the same as supervisory control / level-of-autonomy a la Parasuraman
		Formally models the capabilities of the robots and specs for the system
		Ramadge and Wonham Framework (?)
		Assumes discrete system states
			Hybrid System Theory allows discrete and continuious states
			Discrete event systems (DES)
				Changes in states are triggered by events
				Uncontrollable events are feedback, eg. from sensors
				Controllable events are command signals e.g. to move the robot forwards
				Free behavior models
					Represent what the system si capable of doing
					Realized as generators
				Control specification
					Represents what the system should do
					Also realized as a generator 
				Both free behavior model and control spec are in a formal language
					words in the language consit of symbols over an alphabet
					symbols are events in the DES
				Desireable sequences of events are the words in the language
				SCT prevents controllable events that are not desired, based on the state
	Segregation
		Leaders broadcast a color
		Followers with one leader don't move
		Followers with no leader don't move
		Followers with more than one leader move randomly
	Aggregation
		Uses a known correct controller from the literature
		Formalized into SCT
	Object Clustering
		Uses one of the evolved controllers from the literature
		Model developed into SCT state diagrams
	Group Formation
		Model based on communication

	Composition semantics are a bit confusing to me
	Operators on the composed transition graph make sure that the resulting language has no deadlocks (!)
	Can have problems with exponential growth 
		Exponential in the number of free behavior mdoels and specs
			The very simple models from the example section ended up with hundreds or thousands of states and transitions
		Modular approach to fix
			One supervisor for each spec
			All supeprvisors run at once
		Local modular approach to reduce state count in supervisors
			Supeprvisor for each control spec
			Only free behavior models that the control spec metions are take into account
				So if the spec doesn't say anything about an event, don't use that fbm

I'm not seeing how this changes the development process, it just puts it in a formal representation instead of code
	And seems kind of user-hostile

Automatic Design of Robot Swarms: Achievements and Challenges (2016)
Gianpiero Francesca, Mauro Birattari
	Automatic design as a an optimization problem
	Current dev methods as individual points, not a design science/engineering dicipline
	Offline methods
		Good overview of genetic algos
		Has some mention of automode-chocolate/vanilla
	Online methods
		L-Alliance 
		Methods that try different things and share results
			Assessing results must be v. hard...
		Embodied evolution
			Robots broadcast mutated versions, do local assessment
			MEDEA MONEE and odNEAT (for evolution section)
	Calls for a reference design model
		If specified in SCT, could ease at least some of that problem
	Refs to Lopes call it a principled manual method, so I was right about it changing where the work is
		"Some effort has been made recently to overcome this problem and a number of principled manual methods have been proposed [e.g., see Hamann and Wörn (2008), Kazadi et al. (2009), Berman et al. (2011), Werfel et al. (2014), Brambilla et al. (2015), Reina et al. (2015), and Lopes et al. (2016)]."

Observing the Effects of Overdesign in the Automatic Design of Control Software for Robot Swarms
Mauro Birattari, Brian Delhaisse, Gianpiero Francesca, and Yvon Kerdoncuff
	Overdesign is the automated desgin analog of overtraining
	The reality gap is like the generalization problem in ML
		Similar to some of the statements about evolved controllers representing too much
			And so being brittle, because they were beginning to represent their own environment too much
		This is the bias-variance decomposition of the error
			Complexity increases variance but decreases bias, at some point (optimal complexity), they cross over
			Probably why the magic number of hidden units is like 3-5, no matter what you're doing
				And why the number is fucking magic instead of an engineering result
	Uses EvoStick, the one AutoMoDe beats...
		Typical evo/neuro approach
	And they get a divergence where the sim keeps getting better and the result in real life gets worse


Probabilistic Supervisory Control Theory (pSCT) Applied to Swarm Robotics
Yuri K . Lopes, Stefan M. Trenkwalder, André B. Leal, Tony J. Dodd, Roderich Groß
	Probablistic extension of SCT
		"Probabilistic generators differ from probabilistic automata.
	Probabilistic automata are concerned with the uncertainty of
	the system’s state, which is defined by a stochastic vector. In
	a particular state, each event may have transitions to multi-
	ple states (with associated probabilities). Note that this is one
	approach to represent actuation uncertainty.  In [16], actua-
	tion uncertainty is represented by probabilistic computation
	tree logic in the context of a stochastic motion planning task.
	Probabilistic generators, on the other hand, are concerned
	with the uncertainty of events occurring in the system’s state,
	which is assumed to be known.  Each event will result in a
	transition to a single state"
	Ok, so not quite the same thing as probablistic automata
	This ends up apparently solving the choice of what action to take when multiple are available
		Which is not something GCPR really handled
	Deterministic controller can live-lock
		e.g. always turning right when encountering a wall can get trapped by a slight spiral
		SCT synthesis can prevent deadlocks, but not livelocks
	Nondeterministic controller cannot live-lock
		Will eventually try all combinations of possible actions
		Could just do everything with equal probability
			But some actions should probably be tried first/more likely to be tried earlier
	pSCT has probablistic generators
		Probability of generating a controllable event
	The synchronization stuff is where you get the "no, fuck YOU sir" combinatorial explosions
		Statespaces are multiplied by each other

Viable Algorithmic Options for Designing Reactive Robot Swarms
Todd Wareham, Andrew Vardy
	"We show that the design of a generalized computation-free swarm for an arbi-
	trary given task in an arbitrary given environment is not polynomial-time solvable either in general or by the
	most desirable types of approximation algorithms (including evolutionary algorithms with high probabilities
	of producing correct solutions) but is solvable in effectively polynomial time relative to several types of re-
	strictions on swarms, environments, and tasks. "
	Return of the son of gridworld!
		Static env, squares are occupied or free for robot to occupy
		Sensor can be oriented
		Robot has a compass
		Sensor has a fixed range
		Control is just a bigass if-else based on the sensor
			final else is just "if you don't see anything or you do and it wasn't otherwise covered"
		Motion is atomic and always works
		Sensors are perfect
	Proof of intractability is by reduction to dominating set, which is NP-hard
		The intractable thing is generalized computation free swarms with correct operation and polynomial runtime
		Can relax to either 
			Approximation algos - polynomial time, but might be wrong
				Unfortunately, most of these can also be reduced to NP-hard, assuming bounded error
					Unbounded error is kind of a bad scene
			Restriction-bsed algos - correct, but over a restricted set of inputs
				Some sets of aspects still end up allowing the reduction to dominating set/NP-hard
	Extends to broader set of reactive swarms
		Although keeps noncontinuious manner on a grid
			I wonder how it works with continuious robots in a non-grid/real world
				Paper discusses this, but answer isn't clear
				"It often seems to be implicitly assumed that the
				observed capabilities of reactive swarms come in large part from the offloading of the computa-
				tional power of individual swarm members onto the physics of continuous motion in a Euclidean
				environment like the real world."
		Brooks-style subsumption and neural network with 1.0/0.0 weights
			Which are kind of like the if/else structure previously described

From Formalised State Machines to Implementations of Robotic Controllers
Wei Li, Alvaro Miyazawa, Pedro Ribeiro, Ana Cavalcanti, Jim Woodcock, and Jon Timmis
	Controller code generated from a state machine spec
		RoboChart
			Formal semantics allow for verification
			Allows timed and probabalistc systems, multiple controllers
			States have entry, during, and exit actions
			State machines are, generally, pretty easy to transform into code
	PRISM is for probablistic automata
		This is probably what I'd end up using
	Formal verification desirable for safety
	Self-organized aggregation
		Using one of the no-computation style controllers with binary sensor
			Did not derive the controller from the user input, it was from the literature
	Swarm taxis


Modeling and Supervisory Control of Mobile Robots: A Case of a Sumo Robot
César R. C. Torrico, André B. Leal, Ana T. Y. Watanabe
	Looks into preventing combinatorial explosion
	Reduces states based on physical layout of robot and env, to remove states that are physically impossible
		Rather than all combinations of sensors, just those combinations that can realistically occur
			Which in turn requires a controlled environment

Scaling the Formal Synthesis of Supervisory Control Software for Multiple Robot Systems
R.C. Hill and S. Lafortune
	Hierarchical decomposition
	Vague global plan
		Assessment of blocking is inherently global
	Precise local plan with receeding horizon
	Ended up actually implementing to ROS and driving a simulation
		Move-base doing the actual motion, so this was more of a planner

Algorithms for Timing and Sequencing Behaviors in Robotic Swarms
Sasanka Nagavalli (PhD Thesis)
	Input timing and neglect benevolence
	Library of swarm behaviors (probably already human-written)
	Library is consensus-based behaviors
	Intermediate goals and planning in state space, but unclear how the UI works into it
	Interesting chapter on intelligibility
		Also references gestalt perception, cite there
	Seems a bit math heavy and actual-robot light

Gauci et al. (2014b) sounds really cool
	Reactive, single sensor of unlimited range that returns one bit (something is there or not)
	Extended to trinary (it's a robot, it's nothing, it's a non-robot thing)
	This is really cool in theory, and the dumbest thing I ever goddamn heard in practice
	Can apparently do aggregation, clustering of objects, perimeter formation, foraging
	Design using exhasutive search, evolutionary algos
	This is tripping my "deep exestential horror" spidey sense. Assuming arbitrairly good sensors, is computation ever needed?
	These are easy to implement in GCPR (really without the R)

	.  Konur,  C.  Dixon,  and  M.  Fisher.   Analysing  robot  swarm  behaviour  via
probabilistic model checking.

Ok, but is SCT actually going to get me a no-human-coding system?
	No, not really, still have to read sensors and operate effectors
		And given that the effectors appear to have some more grid-world kind of behaviors, rather than continuious behavior, this doesn't seem to be a minor concern, although Torrico/Sumo does have the robot's motions, rather than its positions as the final element
	Might cut down on me personally having to write the big combinations of guards for GCPR
	Also, the sensors appear to be binary (events either happen or don't, no concept of intensity, proximity, etc.)
		Although there are some fuzzy extensions


Improved Human-Robot Team Performance Using Chaski, A Human-Inspired Plan Execution System
Julie Shah, James Wiken, Brian Williams, Cynthia Breazeal
	Intended to make human-robot teaming better based on human-human teaming
	Reduces human idle time by 85% relative to a verbally commanded robot
	Drawn from studies of human interaction under stress
		Military tactical teams, medical teams
	Teammates make decisions on the fly
		Swarm doesn't make a huge number of decisions
		Decisionmaking isn't shared the same way, swarm isn't a peer
	Teammated communicate progress
		Communication channel back from the team is implicit, in whether the team appears to be doing what the user commanded
			Should really do a test of this
		Doesn't really communicate progress so much as perhaps provide information to be interpreted. 
	Teammates consider consequences of decision on others
		This is making my work feel very unlike a team
		Swarm doesn't team with remote user, swarm is more like a tool than a teammate
		Tool vs peer distinction is good to make
	Equal partners
		decentralized authority
			My swarm design has a more centralized authority
	Compiles into a format it can operate on quickly
		Latency within the bounds of human reflexes
	Doesn't support replanning if someone changes their mind partway through an activity

Shared Understanding for Collaborative Control
David J. Bruemmer, Douglas A. Few, Ronald L. Boring, Julie L. Marble, Miles C. Walton, and Curtis W. Nielse
	Search and exploration task
	Two experiments
		First, human mostly drives with some robot help vs robot mostly drives with some human help
			Robot better at driving
		Second, 3D interface better than video stream from robot
			Reduces operator workload
			Reduced nav error
	Hybrid deliberative/reactive architecture
	Teleoperation and the DARPA humanoid challenge are use as a tool
	Tools are not teammates
	"However, although it allows the robot to take a role in  navigation,  safeguarded  teleoperation  does  not  permit  a  dynamic sharing  of  roles  and  responsibilities  customarily  found  in  an effective  team"
	Robot as peer
		Communication and support in both directions
		Robot can have leadership in som parts of task
		Not just letting robot take initiative
	My control architecture is what this paper calls autonomous control
		High-level tasking of robot 
	Interesting point about video as a false sense of SA
		Not a wide enough field to be really useful
			Sometimes doesn't show obstacle
		Sometimes only shows the obstacle
			As in, that's all you can see
	3D view replaced video in (...kinda nightmarish) interface
		3D was extrusion of 2d laser scan, to show walls/spaces
	Dennet ref at the end is interesting
		Physical stance
			Can see what robot can do from looking at it
			4" tall robot with wheels can't climb stairs
		Design stance
			Cn usually guess how js motions become robot motions
		Intentional stance
			Understanding robot as a rational agent with goals and intentional states

Whose Job Is It Anyway? A Study of Human–Robot Interaction in a Collaborative Task
Pamela J. Hinds, Teresa L. Roberts, Hank Jones
	Deals more with human-like robots
	Also how human-like-ness interacts with status in team
	Probably not going to be seeing humanoid swarms for QUITE some time
	Humans apparently have a hard time delegating responsibility to non-humanoids
		In keeping with treatment of swarm as more like a tool than a peer
		If I screw up, my hammer isn't to blame, I am
	"Machine-like robots, however, may be more appropriate when robots are expected to be unreliable, are less well-equipped for the task than people are, or in other situations in which personal responsibility should be emphasized."
		People tend to assume humanoids have human-level ability
			Refrigerators on wheels don't get that assumption

Which One? Grounding the Referent Based on
Efficient Human-Robot Interaction
Raquel Ros, Severin Lemaignan, E. Akin Sisbot, Rachid Alami, Jasmin Steinwender, Katharina Hamann, Felix Warneken
	Perspective-taking for ambiguity resolution
	Probably not very related

Towards Predicting Robot Team Performance
Jacob W. Crandall, Curtis W. Nelson, Michael A Goodrich
	1 human, multiple robots (3 in example)
	Measure neglect tolerance and interface efficiency
	Also world complexity, but that's out of scope for this paper
	This is from before neglect benevolence
		which is totally a thing in modern swarms, emergent systems now
	Interaction scheme depends on human OODA loop
	Effeciency of a scheme p is given as a random process
		args are p, mission time so far, world complexity, and time the robot has been neglected
	Neglect tolerance given as random process of p, time since the robot was neglected, and world complexity
	Restricted to a case where human can operate one robot at a time
		So not properly a swarm interface, more a multi-robot interface
	"At a certain robot attention demand robot performance peaks, after which increasing the percentage of time interacting with a robot only hinders its performance"
		Hints of neglect benevolence


Establishing Human Situation Awareness Using a Multi-Modal Operator Control Unit In An Urban Search & Rescue Human-Robot Team
Benoit Larochelle, Geert-Jan M. Kruijff, Nanja Smets, Tina Mioch, Peter Groenewege
	Single-robot single user
	Intersting point about OCU being between the environment and the person, rather than the robot and the person
	Still working with a tool in an environment, not a teammate


Shared Environment Representation for a Human-Robot Team Performing Information Fusion
Tobias Kaupp, Bertrand Douillard, Fabio Ramos, Alexei Makarenko, and Ben Upcroft
	Humans provide high level info
	Robots provid metric and low-level info
	3 levels of abstraction
		Geometric
		Appearance
		Identity
	Semantic mapping stuff kind of related to this
	Not really about teaming