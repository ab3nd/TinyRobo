{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/usr/lib/python2.7/dist-packages/matplotlib/__init__.py:874: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "#Preamble stuff, loading up libraries and convenience functions\n",
    "import all_data_handler\n",
    "import pandas\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import itertools\n",
    "import seaborn as sb\n",
    "import scipy.stats as ss #For ss.f_oneway() ANOVAs\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "adh = all_data_handler.UserData()\n",
    "per_task_df = pandas.DataFrame(adh.toPandas())\n",
    "col_list = list(per_task_df)\n",
    "col_list.remove(\"user\")\n",
    "col_list.remove(\"condition\")\n",
    "col_list.remove(\"task\")\n",
    "\n",
    "#Given the object list of a gesture from the coding, return a list of letters representing normalized \n",
    "#values for the objects of the gesture\n",
    "def tag_object(original):\n",
    "    #This use of strip is to prevent quotes from messing up regex matches\n",
    "    original = \" \".join(original).strip(\"\\\"\")\n",
    "    tags = []\n",
    "    #Matches robots, robot, bot, bots, etc. \n",
    "    robots = re.compile(\"bot|group|swarm|orange|red\", re.I)\n",
    "    crate = re.compile(\"crate\", re.I)\n",
    "    targetA = re.compile(\"area a|box a| a$|to a,|^a$\", re.I)\n",
    "    targetB = re.compile(\"area b|box b| b$|to b,|^b$\", re.I)\n",
    "    whitespace = re.compile(\"whitespace|ground|screen|white area\", re.I)\n",
    "    \n",
    "    toCheck = [(robots, \"r\"), (crate, \"c\"), (targetA, \"a\"), (targetB, \"b\"), (whitespace, \"w\")]\n",
    "    for compiled, tag in toCheck:\n",
    "        if re.search(compiled, original):\n",
    "            tags.append(tag)\n",
    "    return tags\n",
    "\n",
    "def count_select_taps(participant):\n",
    "    #Dict of task id to count of taps on robots\n",
    "    counts = {}\n",
    "    for task_id in participant[\"tasks\"].keys():\n",
    "        #Default to no counts of select taps\n",
    "        counts[task_id] = 0\n",
    "        events = participant[\"tasks\"][task_id]\n",
    "        #Flip through all the events\n",
    "        for event in events:\n",
    "            if event[\"event_type\"] == \"memo\":\n",
    "                #This event is a memo, not a user gesture\n",
    "                continue\n",
    "            elif \"example\" in event.keys() and event[\"example\"] == True:\n",
    "                #This event is an example, don't count it\n",
    "                continue\n",
    "            else:\n",
    "                #We have an event, check if it's a tap on a robot\n",
    "                if event[\"event_type\"] == \"tap\":\n",
    "                    #Taps always have an object\n",
    "                    tags = tag_object(event[\"objects\"])\n",
    "                    if 'r' in tags:\n",
    "                        counts[task_id] += 1\n",
    "    return counts\n",
    "\n",
    "def count_group_select(participant):\n",
    "    #Dict of task id to count of taps on robots\n",
    "    counts = {}\n",
    "    for task_id in participant[\"tasks\"].keys():\n",
    "        #Default to no counts of select taps\n",
    "        counts[task_id] = 0\n",
    "        events = participant[\"tasks\"][task_id]\n",
    "        #Flip through all the events\n",
    "        for event in events:\n",
    "            if event[\"event_type\"] == \"memo\":\n",
    "                #This event is a memo, not a user gesture\n",
    "                continue\n",
    "            elif \"example\" in event.keys() and event[\"example\"] == True:\n",
    "                #This event is an example, don't count it\n",
    "                continue\n",
    "            else:\n",
    "                #If we have objects, tag them\n",
    "                if \"objects\" in event.keys():\n",
    "                    tags = tag_object(event[\"objects\"])\n",
    "                    #We have both an event and a set of tags, check if it's a tap on a robot\n",
    "                    if 'r' in tags and (event[\"event_type\"] == \"lasso\" or event[\"event_type\"] == \"box_select\"):\n",
    "                        counts[task_id] += 1\n",
    "    return counts\n",
    "\n",
    "def count_box_select(participant):\n",
    "    #Dict of task id to count of taps on robots\n",
    "    counts = {}\n",
    "    for task_id in participant[\"tasks\"].keys():\n",
    "        #Default to no counts of select taps\n",
    "        counts[task_id] = 0\n",
    "        events = participant[\"tasks\"][task_id]\n",
    "        #Flip through all the events\n",
    "        for event in events:\n",
    "            if event[\"event_type\"] == \"memo\":\n",
    "                #This event is a memo, not a user gesture\n",
    "                continue\n",
    "            elif \"example\" in event.keys() and event[\"example\"] == True:\n",
    "                #This event is an example, don't count it\n",
    "                continue\n",
    "            else:\n",
    "                #If we have objects, tag them\n",
    "                if \"objects\" in event.keys():\n",
    "                    tags = tag_object(event[\"objects\"])\n",
    "                    #We have both an event and a set of tags, check if it's a tap on a robot\n",
    "                    if 'r' in tags and event[\"event_type\"] == \"box_select\":\n",
    "                        counts[task_id] += 1\n",
    "    return counts\n",
    "\n",
    "def count_lasso_select(participant):\n",
    "    #Dict of task id to count of taps on robots\n",
    "    counts = {}\n",
    "    for task_id in participant[\"tasks\"].keys():\n",
    "        #Default to no counts of select taps\n",
    "        counts[task_id] = 0\n",
    "        events = participant[\"tasks\"][task_id]\n",
    "        #Flip through all the events\n",
    "        for event in events:\n",
    "            if event[\"event_type\"] == \"memo\":\n",
    "                #This event is a memo, not a user gesture\n",
    "                continue\n",
    "            elif \"example\" in event.keys() and event[\"example\"] == True:\n",
    "                #This event is an example, don't count it\n",
    "                continue\n",
    "            else:\n",
    "                #If we have objects, tag them\n",
    "                if \"objects\" in event.keys():\n",
    "                    tags = tag_object(event[\"objects\"])\n",
    "                    #We have both an event and a set of tags, check if it's a tap on a robot\n",
    "                    if 'r' in tags and event[\"event_type\"] == \"lasso\":\n",
    "                        counts[task_id] += 1\n",
    "    return counts\n",
    "\n",
    "#Returns a dict of task IDs to count of total events\n",
    "def count_events(participant):\n",
    "    counts = {}\n",
    "    for task_id in participant[\"tasks\"].keys():\n",
    "        #Default to no counts of select taps\n",
    "        counts[task_id] = 0\n",
    "        #Flip through all the events\n",
    "        events = participant[\"tasks\"][task_id]\n",
    "        for event in events:\n",
    "            if event[\"event_type\"] == \"memo\":\n",
    "                #This event is a memo, not a user gesture\n",
    "                continue\n",
    "            elif \"example\" in event.keys() and event[\"example\"] == True:\n",
    "                #This event is an example, don't count it\n",
    "                continue\n",
    "            else:\n",
    "                #Not one of the skip cases, so count it\n",
    "                counts[task_id] += 1\n",
    "    return counts\n",
    "\n",
    "#Prints out the per-condition counts, one entry for each user in that condition\n",
    "#Also gets the mean and standard deviation for the condition\n",
    "def user_counts(user_counts):\n",
    "    per_cond = {}\n",
    "    #For each user, maintain a running total\n",
    "    for pid in user_counts.keys():\n",
    "        #Get their condition\n",
    "        cond = adh.IdToCondition(pid)[0]\n",
    "        counts = user_counts[pid].values()\n",
    "        per_user_total = sum(counts)\n",
    "        if cond in per_cond.keys():\n",
    "            per_cond[cond].append(per_user_total)\n",
    "        else:\n",
    "            per_cond[cond] = [per_user_total]\n",
    "    \n",
    "    for cond in per_cond.keys():\n",
    "        \n",
    "        total = sum(per_cond[cond])\n",
    "        mean = np.mean(per_cond[cond])\n",
    "        std_dev = np.std(per_cond[cond])\n",
    "        print cond, per_cond[cond]\n",
    "        print \"total:{} mean:{} std dev:{}\".format(total, mean, std_dev)\n",
    "        print\n",
    "\n",
    "#Given a dict of user IDs to dicts of task ids to event counts\n",
    "#return a dict of user IDs to lists of event counts for the common tasks\n",
    "def get_matched_tasks(counts):\n",
    "    #Get a list of the task names that every condition has in common\n",
    "    common_names = []\n",
    "    for name in adh.taskMap.keys():\n",
    "        if all(adh.taskMap[name].values()):\n",
    "            common_names.append(name)\n",
    "    common_names.sort()\n",
    "\n",
    "    #dict of user ids to a list of counts, index of counts is task number\n",
    "    matched_tasks = {}\n",
    "    for user in counts.keys():\n",
    "        common_counts = []\n",
    "        for task in common_names:\n",
    "            #print user, adh.IdToCondition(user), task, adh.taskNameToNumber(task, user)\n",
    "            #Get the count at the task number for this common name\n",
    "            common_counts.append(counts[user][str(adh.taskNameToNumber(task, user))])\n",
    "        matched_tasks[user] = common_counts\n",
    "    return matched_tasks\n",
    "\n",
    "#Given a dict of conditions to lists of samples\n",
    "#Do an all-pairs 1-way ANOVA on the samples\n",
    "def all_pairs_f(d):\n",
    "    for k1, k2 in itertools.combinations(d.keys(), 2):\n",
    "        print k1, k2\n",
    "        print ss.f_oneway(d[k1], d[k2])\n",
    "        print\n",
    "\n",
    "#Given a dict of users to lists of samples\n",
    "#Return a dict of conditions to a list of all the samples for users in that condition \n",
    "def make_condition_dict(user_samples):\n",
    "    cond_dict = {}\n",
    "    for user in user_samples.keys():\n",
    "        #Get the condition for this user\n",
    "        cond = adh.IdToCondition(user)[0]\n",
    "        #If we already have a set of samples, extend it, otherwise, create it\n",
    "        if cond in cond_dict.keys():\n",
    "            cond_dict[cond].extend(user_samples[user])\n",
    "        else:\n",
    "            cond_dict[cond] = copy.deepcopy(user_samples[user])\n",
    "    return cond_dict\n",
    "\n",
    "#Set up dicts of user ids to dicts of task ids to various types of counts\n",
    "all_select_taps = adh.apply(count_select_taps)\n",
    "all_group_selects = adh.apply(count_group_select)\n",
    "all_lassos = adh.apply(count_lasso_select)\n",
    "all_box = adh.apply(count_box_select)\n",
    "all_gesture_counts = adh.apply(count_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H1: There exists a number of robots beyond which users will transition from treating robots as individuals to interacting with the robots in small groups or as a single large group. \n",
    "\n",
    "This transition point will be apparent because of a change in the gesture set that the user uses to interact with the swarm. It is hypothesized that above the transition point, users will be more likely to neglect some subset of the available robots. The user will instead use commands that control the bulk of the robots as a cloud or flock, but may leave some robots unused. For example, the user may switch from selecting robots as individuals to shaping and pushing the swarm the way a child might play with a bug, putting their hand down so the bug goes around or avoids it, touching the back of the bug gently to make it scurry forwards, and so forth, or by shaping the group as if sculpting, with pushing and pinching to \"carry\" groups around. \n",
    "\n",
    "The user may also change how they indicate which robots are to be interacted with. Rather than selecting each robot by clicking on it, they may \"paint\" over the area containing the robots they want to use, or draw a circle around them. \n",
    "The size of the swarm where changes in the user gestures occur will indicate the transition point between interacting with individual robots and interacting with the swarm as a whole. \n",
    "\n",
    "This hypothesis would be invalidated by the gestures selected by the user displaying no correlation with the size of the swarm that they are controlling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tap as Select\n",
      "unknown thousand\n",
      "F_onewayResult(statistic=4.857660764681959, pvalue=0.028806401178702146)\n",
      "\n",
      "unknown hundred\n",
      "F_onewayResult(statistic=8.874444350701339, pvalue=0.003295634676882301)\n",
      "\n",
      "unknown ten\n",
      "F_onewayResult(statistic=0.47522212088753896, pvalue=0.4914921715791879)\n",
      "\n",
      "unknown one\n",
      "F_onewayResult(statistic=2.6306783002182796, pvalue=0.10658684217143713)\n",
      "\n",
      "thousand hundred\n",
      "F_onewayResult(statistic=1.0228400919295035, pvalue=0.3132190642039571)\n",
      "\n",
      "thousand ten\n",
      "F_onewayResult(statistic=1.788549832548111, pvalue=0.18280936019424932)\n",
      "\n",
      "thousand one\n",
      "F_onewayResult(statistic=10.45962892134517, pvalue=0.0014544293123260345)\n",
      "\n",
      "hundred ten\n",
      "F_onewayResult(statistic=4.201182723081977, pvalue=0.041862718197988216)\n",
      "\n",
      "hundred one\n",
      "F_onewayResult(statistic=13.799628516759492, pvalue=0.00027202826822461256)\n",
      "\n",
      "ten one\n",
      "F_onewayResult(statistic=4.503627229070396, pvalue=0.03520618864924477)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filter user gesture counts, user tap-as-select counts, and user group select counts to common tasks only\n",
    "common_select_tap = get_matched_tasks(all_select_taps)\n",
    "common_group_select = get_matched_tasks(all_group_selects)\n",
    "common_gesture_counts = get_matched_tasks(all_gesture_counts)\n",
    "\n",
    "#For each user, get the sum of their gesture use across all the common tasks. This is the user's \"verbosity\".\n",
    "#The verbosity is used to normalize the raw counts of gestures so that users that make a lot of gestures don't\n",
    "#dominate the analysis. \n",
    "total_gesture_counts = {k:sum(v) for (k,v) in common_gesture_counts.items()}\n",
    "\n",
    "#Normalize tap-as-select for matched tasks\n",
    "#This is a list comprehension that does the norming (divide each task by the appropriate entry in the total counts)\n",
    "#inside of a dictionary comprehension that operates over all users\n",
    "norm_select_tap = {k:[float(count)/float(total_gesture_counts[k]) for count in v] for (k,v) in common_select_tap.items()}\n",
    "#Normalize group select for matched tasks\n",
    "norm_group_select = {k:[float(count)/float(total_gesture_counts[k]) for count in v] for (k,v) in common_group_select.items()}\n",
    "\n",
    "#Set up dictionaries by condition for all-pairs ANOVA for tap-as-select and group select\n",
    "select_tap_by_cond = make_condition_dict(norm_select_tap)\n",
    "group_select_by_cond = make_condition_dict(norm_group_select)\n",
    "\n",
    "#And do our ANOVAS\n",
    "print \"Tap as Select\"\n",
    "all_pairs_f(select_tap_by_cond)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a=0.05, the following pairs of conditions in bold have statistically significant differences in the use of tap as select:\n",
    "\n",
    "|              | unknown | one    | ten        | hundred     | thousand   | \n",
    "| ------------ | ------- | ------ | ---------- | ----------- | ---------- |\n",
    "| **unknown**  |         | 0.1066 |   0.4915   | **0.0033**  | **0.0288** |   \n",
    "| **one**      |         |        | **0.0352** | **0.0003**  | **0.0014** |\n",
    "| **ten**      |         |        |            | **0.0419**  |   0.1828   |\n",
    "| **hundred**  |         |        |            |             |   0.3132   |\n",
    "| **thousand** |         |        |            |             |            |\n",
    "\n",
    "One and ten not differing from unknown is expected. In the one and ten robot case, actions on individual robots do not take up too much time, and the unknown case is like the one robot case in that a single entity is displayed, although it represents more than one robot. \n",
    "\n",
    "The differences between thousand and unknown are surprising, since it seemed like a lot of users in the thousand robot case didn't use group selection, but apparently enough did that it is still more like the ten and hundred cases than the one and unknown cases. \n",
    "\n",
    "The hundred and ten case, I would have expected to be more similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Select\n",
      "unknown thousand\n",
      "F_onewayResult(statistic=10.817674837981038, pvalue=0.001211720122771659)\n",
      "\n",
      "unknown hundred\n",
      "F_onewayResult(statistic=51.10444866800627, pvalue=2.179056890041691e-11)\n",
      "\n",
      "unknown ten\n",
      "F_onewayResult(statistic=39.03237249237476, pvalue=2.9852519963238435e-09)\n",
      "\n",
      "unknown one\n",
      "F_onewayResult(statistic=nan, pvalue=nan)\n",
      "\n",
      "thousand hundred\n",
      "F_onewayResult(statistic=28.89935934050297, pvalue=2.3691725354231207e-07)\n",
      "\n",
      "thousand ten\n",
      "F_onewayResult(statistic=18.535993292609703, pvalue=2.7489292452600023e-05)\n",
      "\n",
      "thousand one\n",
      "F_onewayResult(statistic=10.817674837981038, pvalue=0.001211720122771659)\n",
      "\n",
      "hundred ten\n",
      "F_onewayResult(statistic=1.421140552523716, pvalue=0.2348026467807657)\n",
      "\n",
      "hundred one\n",
      "F_onewayResult(statistic=51.10444866800626, pvalue=2.1790568900417192e-11)\n",
      "\n",
      "ten one\n",
      "F_onewayResult(statistic=39.03237249237475, pvalue=2.9852519963238435e-09)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/scipy/stats/stats.py:2952: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "print \"Group Select\"\n",
    "all_pairs_f(group_select_by_cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a=0.05, the following pairs of conditions in bold have statistically significant differences in the use of group selections:\n",
    "\n",
    "|              | unknown | one    | ten        | hundred     | thousand   | \n",
    "| ------------ | ------- | ------ | ---------- | ----------- | ---------- |\n",
    "| **unknown**  |         | NaN    | **0.0000** | **0.0000**  | **0.0012** |   \n",
    "| **one**      |         |        | **0.0000** | **0.0000**  | **0.0012** |\n",
    "| **ten**      |         |        |            |   0.2348    | **0.0000** |\n",
    "| **hundred**  |         |        |            |             | **0.0000** |\n",
    "| **thousand** |         |        |            |             |            |\n",
    "\n",
    "The reason that unknown and one have an uncomputable ANOVA is that in the common tasks for the one and unknown robot conditions, no group selection gestures were used.\n",
    "\n",
    "This restriction to the common tasks is because some tasks do not make sense for a single robot, such as forming a square formation, and some do not make sense for an unknown number of robots, such as tasks that single out a specific robot. \n",
    "\n",
    "In the next section, I will work with only the ten, hundred, and thousand robot cases, as these cases have all of their tasks in common (but not in common with the one and unknown cases). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thousand hundred\n",
      "F_onewayResult(statistic=0.24214754060632215, pvalue=0.622960939579051)\n",
      "\n",
      "thousand ten\n",
      "F_onewayResult(statistic=3.9852059977626766, pvalue=0.04665847479025153)\n",
      "\n",
      "hundred ten\n",
      "F_onewayResult(statistic=2.399275134994357, pvalue=0.12227501538059789)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert the dictionary of user id to dictionary of task to count to a simple list of counts\n",
    "#The list is ordered by task\n",
    "def tasks_to_list(tasks):\n",
    "    counts = []\n",
    "    for key in sorted(tasks.iterkeys()):\n",
    "        counts.append(tasks[key])\n",
    "    return counts\n",
    "\n",
    "#For each user, get the sum of their gesture use across all the tasks. As above, this gets used as verbosity.\n",
    "total_gesture_counts = {k:sum([count for count in v.values()]) for (k,v) in all_gesture_counts.items()}\n",
    "\n",
    "#Convert the dicts of per-task dicts of counts into a dict of ordered list of counts\n",
    "#The keys at the top level remain the user ids\n",
    "tap_select_counts = {k:tasks_to_list(v) for (k,v) in all_select_taps.items()}\n",
    "group_select_counts = {k:tasks_to_list(v) for (k, v) in all_group_selects.items()}\n",
    "\n",
    "# #Normalize the counts by the user's total gestures\n",
    "norm_select_tap = {k:[float(count)/float(total_gesture_counts[k]) for count in v] for (k,v) in tap_select_counts.items()}\n",
    "norm_group_select = {k:[float(count)/float(total_gesture_counts[k]) for count in v] for (k,v) in group_select_counts.items()}\n",
    "\n",
    "#Set up dictionaries by condition for all-pairs ANOVA for tap-as-select and group select\n",
    "select_tap_by_cond = make_condition_dict(norm_select_tap)\n",
    "group_select_by_cond = make_condition_dict(norm_group_select)\n",
    "\n",
    "#Get rid of the conditions we're not checking (the don't have the same number of samples)\n",
    "del select_tap_by_cond[\"one\"]\n",
    "del select_tap_by_cond[\"unknown\"]\n",
    "all_pairs_f(select_tap_by_cond)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across all tasks, with a=0.05, only thousand differs from ten in the use of taps as a selection gesture. This is likely because with ten robots, tapping each individual is not too difficult, but beyond that, it becomes time-consuming and tedious. I'm surprised ten and hundred don't show a significant difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thousand hundred\n",
      "F_onewayResult(statistic=46.93700094454729, pvalue=3.210528401062233e-11)\n",
      "\n",
      "thousand ten\n",
      "F_onewayResult(statistic=28.420205547243633, pvalue=1.7326302506804138e-07)\n",
      "\n",
      "hundred ten\n",
      "F_onewayResult(statistic=3.4875197834890277, pvalue=0.0626501116426523)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get rid of the conditions we're not checking (the don't have the same number of samples)\n",
    "del group_select_by_cond[\"one\"]\n",
    "del group_select_by_cond[\"unknown\"]\n",
    "all_pairs_f(group_select_by_cond)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across all tasks, with a=0.05, hundred and ten both differ from thousand, but not from each other, in the use of group selects as a selection gesture. \n",
    "\n",
    "The reason for this is that the use of group selections actually drops off in the thousand robot case compared to the hundred robot case. This is evidence that the user expects commands to be obeyed by all robots, without having to select them first. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- group select, all tasks --\n",
      "unknown\n",
      "\tTotal: 1\n",
      "thousand\n",
      "\tTotal: 28\n",
      "hundred\n",
      "\tTotal: 109\n",
      "ten\n",
      "\tTotal: 107\n",
      "one\n",
      "\tTotal: 3\n",
      "   Overall: 248\n",
      "\n",
      "-- group select, common tasks --\n",
      "unknown\n",
      "\tTotal: 0\n",
      "thousand\n",
      "\tTotal: 15\n",
      "hundred\n",
      "\tTotal: 60\n",
      "ten\n",
      "\tTotal: 55\n",
      "one\n",
      "\tTotal: 0\n",
      "   Overall: 130\n",
      "\n",
      "-- tap select, all tasks --\n",
      "unknown\n",
      "\tTotal: 29\n",
      "thousand\n",
      "\tTotal: 18\n",
      "hundred\n",
      "\tTotal: 29\n",
      "ten\n",
      "\tTotal: 108\n",
      "one\n",
      "\tTotal: 53\n",
      "   Overall: 237\n",
      "\n",
      "-- tap select, common tasks --\n",
      "unknown\n",
      "\tTotal: 15\n",
      "thousand\n",
      "\tTotal: 7\n",
      "hundred\n",
      "\tTotal: 4\n",
      "ten\n",
      "\tTotal: 45\n",
      "one\n",
      "\tTotal: 38\n",
      "   Overall: 109\n"
     ]
    }
   ],
   "source": [
    "def total_by_condition(by_user):\n",
    "    counts_by_cond = make_condition_dict(by_user)\n",
    "    total = 0\n",
    "    for cond in counts_by_cond.keys():\n",
    "        print cond\n",
    "        print \"\\tTotal: {}\".format(sum(counts_by_cond[cond]))\n",
    "        total += sum(counts_by_cond[cond])\n",
    "    print \"   Overall: {}\".format(total)\n",
    "\n",
    "#Display the total count of group selection gestures per condition\n",
    "print \"\\n-- group select, all tasks --\"\n",
    "total_by_condition(group_select_counts)\n",
    "\n",
    "#Display the total amount of group selection gestures within the common tasks, per condition\n",
    "print \"\\n-- group select, common tasks --\"\n",
    "total_by_condition(common_group_select)\n",
    "\n",
    "#Display the total amount of tap selection gestures per condition\n",
    "print \"\\n-- tap select, all tasks --\"\n",
    "total_by_condition(tap_select_counts)\n",
    "\n",
    "#Display the total amount of tap selection gestures within the common tasks, per condition\n",
    "print \"\\n-- tap select, common tasks --\"\n",
    "total_by_condition(common_select_tap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as described above, the thousand robot task has a lower use of group selections than the ten and hundred robot cases, in both the common and in all tasks. It also has a lower use of tap select than the ten and hundred robot cases over all all tasks, but nearly the use of tap to select in the common tasks. That said, 7 and 4 are not huge count differences, given that all other cases have far more tap selects in the common tasks. \n",
    "\n",
    "This diminished use of group select for thousand robots across all tasks is what accounts for the statistically significant difference between ten and thousand and between hundred and thousand cases for group selection, while having a statistically insignificant difference between hundred and ten. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get per-user "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2: A display which obscures individual robots and displays a cloud or swarm boundary will cause the user to treat the swarm as a whole rather than individuals, which will be apparent because the user will use the same gestures they would use to control a single robot. \n",
    "\n",
    "Once the ratio of the size of individual swarm members to the size of the area the swarm is in becomes sufficiently large, displaying the swarm members at the same scale as the map will result in the representation of the swarm members being too small to interact with. This problem will arise at smaller scales if the swarm robots are themselves quite tiny, and some of the available swarm robots are indeed small. Scaling the representation of the robots up, relative to the map, will make the robot representations overlap unrealistically and obscure the map. Instead, we propose that for certain scales of swarms, it makes sense to represent the swarm as the area covered, rather than the locations of the individual robots. This approach has been used successfully for navigation in three dimensions, by developing a controller that causes the individual UAVs to remain within a bounding prism, and allowing the user to control the shape and location of that prism.\n",
    "\n",
    "Altering how the user interface displays the location of the robots in the swarm will affect the transition point. \n",
    "\n",
    "This hypothesis would be invalidated by the gestures selected by the user in the single robot case being dissimilar from those selected in the case where the swarm is displayed as a cloud or covered region. However, some variation is expected in commands for tasks which a swarm can do, which a single robot cannot perform, such as dividing into two groups. \n",
    "\n",
    "-----\n",
    "\n",
    "As seen above, for a=0.05, the following pairs of conditions in bold have statistically significant differences in the use of group selections:\n",
    "\n",
    "|              | unknown | one    | ten        | hundred     | thousand   | \n",
    "| ------------ | ------- | ------ | ---------- | ----------- | ---------- |\n",
    "| **unknown**  |         | NaN    | **0.0000** | **0.0000**  | **0.0016** |   \n",
    "| **one**      |         |        | **0.0000** | **0.0000**  | **0.0016** |\n",
    "| **ten**      |         |        |            |   0.1801    | **0.0000** |\n",
    "| **hundred**  |         |        |            |             | **0.0000** |\n",
    "| **thousand** |         |        |            |             |            |\n",
    "\n",
    "Unknown and one are identical, as they have no use of group selection in the common tasks (which is why the calculation came out to NaN). \n",
    "\n",
    "For tap selection:\n",
    "\n",
    "|              | unknown | one    | ten        | hundred     | thousand   | \n",
    "| ------------ | ------- | ------ | ---------- | ----------- | ---------- |\n",
    "| **unknown**  |         | 0.1066 |   0.4915   | **0.0032**  | **0.0288** |   \n",
    "| **one**      |         |        | **0.0352** | **0.0003**  | **0.0014** |\n",
    "| **ten**      |         |        |            | **0.0419**  |   0.1828   |\n",
    "| **hundred**  |         |        |            |             |   0.3132   |\n",
    "| **thousand** |         |        |            |             |            |\n",
    "\n",
    "Unknown and one are not statistically signficantly different, although there is some degree of difference. At least one of the users regularly tapped on the cloud in the unknown robot case as an \"attention\" signal, which is a sort of selection of the entire group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous statistical analyses used the total of the user's gestures across all tasks as a measure of their verbosity. Mark Micire's paper used per _task_ normalization, rather than per _user_ normalization. The below analysies are a repeat of the above, except that the gestures are normalized by gesture count per task and not total gestures per user. I don't expect that it will change the results much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tap as Select\n",
      "unknown thousand\n",
      "F_onewayResult(statistic=5.577222739981358, pvalue=0.019276385592448275)\n",
      "\n",
      "unknown hundred\n",
      "F_onewayResult(statistic=7.6964308686268055, pvalue=0.006123398182074149)\n",
      "\n",
      "unknown ten\n",
      "F_onewayResult(statistic=1.8353598304103607, pvalue=0.17721276637599293)\n",
      "\n",
      "unknown one\n",
      "F_onewayResult(statistic=0.3371165780787707, pvalue=0.5622326894557608)\n",
      "\n",
      "thousand hundred\n",
      "F_onewayResult(statistic=0.36651781239907794, pvalue=0.5456796105669024)\n",
      "\n",
      "thousand ten\n",
      "F_onewayResult(statistic=1.2146251676037936, pvalue=0.27190598611477024)\n",
      "\n",
      "thousand one\n",
      "F_onewayResult(statistic=10.427411515786487, pvalue=0.0014785752751878712)\n",
      "\n",
      "hundred ten\n",
      "F_onewayResult(statistic=2.5964016313743294, pvalue=0.10887841528272646)\n",
      "\n",
      "hundred one\n",
      "F_onewayResult(statistic=13.588890258328336, pvalue=0.00030188601614797734)\n",
      "\n",
      "ten one\n",
      "F_onewayResult(statistic=4.329889858594716, pvalue=0.038880302713248306)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filter user gesture counts, user tap-as-select counts, and user group select counts to common tasks only\n",
    "common_select_tap = get_matched_tasks(all_select_taps)\n",
    "common_group_select = get_matched_tasks(all_group_selects)\n",
    "common_gesture_counts = get_matched_tasks(all_gesture_counts)\n",
    "\n",
    "#The get_matched_tasks function does a sort on task names, so the lists produced are ordered by task. \n",
    "#This means I can get away with zipping the common gesture counts and e.g. the common select taps, and then\n",
    "#doing the division to normalize in a list comprehension\n",
    "#Or I could, if it were not for the fact that sometimes the gesture count is 0 (rarely, some users made no gestures)\n",
    "norm_select_tap = {k:[float(a)/float(b) if a != 0 else 0.0 for a,b in zip(common_select_tap[k], common_gesture_counts[k])] for k in common_select_tap.keys()}\n",
    "#Normalize group select for matched tasks\n",
    "norm_group_select = {k:[float(a)/float(b) if a != 0 else 0.0 for a,b in zip(common_group_select[k], common_gesture_counts[k])] for k in common_group_select.keys()}\n",
    "\n",
    "#For testing \n",
    "# for k in common_select_tap.keys():\n",
    "#     print k\n",
    "#     print common_group_select[k]\n",
    "#     print common_gesture_counts[k]\n",
    "#     print norm_group_select[k]\n",
    "#     print\n",
    "\n",
    "#Set up dictionaries by condition for all-pairs ANOVA for tap-as-select and group select\n",
    "select_tap_by_cond = make_condition_dict(norm_select_tap)\n",
    "group_select_by_cond = make_condition_dict(norm_group_select)\n",
    "\n",
    "#And do our ANOVAS\n",
    "print \"Tap as Select\"\n",
    "all_pairs_f(select_tap_by_cond)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a=0.05, the following pairs of conditions in bold have statistically significant differences in the use of tap selections:\n",
    "\n",
    "|              | unknown | one    | ten        | hundred     | thousand   | \n",
    "| ------------ | ------- | ------ | ---------- | ----------- | ---------- |\n",
    "| **unknown**  |         | 0.5622 |   0.1772   | **0.0006**  | **0.0193** |   \n",
    "| **one**      |         |        | **0.0389** | **0.0030**  | **0.0015** |\n",
    "| **ten**      |         |        |            |   0.1089    |   0.2719   |\n",
    "| **hundred**  |         |        |            |             |   0.5457   |\n",
    "| **thousand** |         |        |            |             |            |\n",
    "\n",
    "One and ten probably don't differ from unknown because they are conditions where the number of robots is small enough that a user can tap on all of the robots. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Select\n",
      "unknown thousand\n",
      "F_onewayResult(statistic=10.234695939973674, pvalue=0.001631828850498129)\n",
      "\n",
      "unknown hundred\n",
      "F_onewayResult(statistic=60.435124868723285, pvalue=5.871514653163783e-13)\n",
      "\n",
      "unknown ten\n",
      "F_onewayResult(statistic=47.63591573861913, pvalue=8.695813953501536e-11)\n",
      "\n",
      "unknown one\n",
      "F_onewayResult(statistic=nan, pvalue=nan)\n",
      "\n",
      "thousand hundred\n",
      "F_onewayResult(statistic=30.237273336840744, pvalue=1.3109879217064968e-07)\n",
      "\n",
      "thousand ten\n",
      "F_onewayResult(statistic=19.01097407513412, pvalue=2.1946268839487587e-05)\n",
      "\n",
      "thousand one\n",
      "F_onewayResult(statistic=10.23469593997367, pvalue=0.001631828850498129)\n",
      "\n",
      "hundred ten\n",
      "F_onewayResult(statistic=1.8055268830162108, pvalue=0.18075611377274647)\n",
      "\n",
      "hundred one\n",
      "F_onewayResult(statistic=60.43512486872327, pvalue=5.871514653163783e-13)\n",
      "\n",
      "ten one\n",
      "F_onewayResult(statistic=47.63591573861913, pvalue=8.695813953501536e-11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Group Select\"\n",
    "all_pairs_f(group_select_by_cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a=0.05, the following pairs of conditions in bold have statistically significant differences in the use of group selections:\n",
    "\n",
    "|              | unknown | one    | ten        | hundred     | thousand   | \n",
    "| ------------ | ------- | ------ | ---------- | ----------- | ---------- |\n",
    "| **unknown**  |         | NaN    | **0.0000** | **0.0000**  | **0.0016** |   \n",
    "| **one**      |         |        | **0.0000** | **0.0000**  | **0.0016** |\n",
    "| **ten**      |         |        |            |   0.1808    | **0.0000** |\n",
    "| **hundred**  |         |        |            |             | **0.0000** |\n",
    "| **thousand** |         |        |            |             |            |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unknown doesn't differ from one at all, they both have no uses of group selection, which is why the ANOVA results in NaN. \n",
    "\n",
    "I'm not sure how to explain the difference in use of group selection between pretty much all other cases. My expectation would have been that the one and unknown were similar to each other, and that the ten, hundred, and thousand were similar to each other, rather than that e.g. hundred and thousand were very different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unknown': [8, 1, 1, 8, 5, 3, 1, 0, 1, 1], 'thousand': [0, 0, 2, 3, 7, 0, 1, 0, 1, 4], 'hundred': [3, 0, 0, 2, 0, 1, 0, 10, 9, 4], 'ten': [55, 18, 1, 3, 12, 3, 2, 10, 2, 2], 'one': [1, 5, 7, 1, 8, 4, 0, 2, 14, 11]}\n",
      "{'unknown': [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'thousand': [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'hundred': [1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1], 'ten': [1, 10, 8, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'one': [1, 2, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1]}\n"
     ]
    }
   ],
   "source": [
    "#Looking at lengths of sequences of taps\n",
    "def tap_sequences(participant):\n",
    "\t#Dict of task id to count of taps on robots\n",
    "\tcounts = {}\n",
    "\tfor task_id in participant[\"tasks\"].keys():\n",
    "\t\t#Set up an empty list for this task\n",
    "\t\tcounts[task_id] = []\n",
    "\t\tevents = participant[\"tasks\"][task_id]\n",
    "\t\t#Flip through all the events\n",
    "\t\ttask_count = 0\n",
    "\n",
    "\t\t# #Conditional breakpoint for debugging\n",
    "\t\t# if task_id == \"11\" and participant[\"participant\"] == 1:\n",
    "\t\t# \timport pdb; pdb.set_trace()\n",
    "\n",
    "\t\tfor event in events:   \n",
    "\t\t\tif event[\"event_type\"] == \"memo\":\n",
    "\t\t\t\t#This event is a memo, not a user gesture\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telif \"example\" in event.keys() and event[\"example\"] == True:\n",
    "\t\t\t\t#This event is an example, don't count it\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telse:\n",
    "\t\t\t\t#We have an event, check if it's a tap on a robot\n",
    "\t\t\t\tif event[\"event_type\"] == \"tap\":\n",
    "\t\t\t\t\t#Taps always have an object\n",
    "\t\t\t\t\ttags = tag_object(event[\"objects\"])\n",
    "\t\t\t\t\tif 'r' in tags:\n",
    "\t\t\t\t\t\t#This is a tap on a robot, add it to the temp list\n",
    "\t\t\t\t\t\ttask_count += 1\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tcounts[task_id].append(task_count)\n",
    "\t\t\t\t\t\t#Reset the counter\n",
    "\t\t\t\t\t\ttask_count = 0\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t#This is the end of the sequence, push the count into the event list\n",
    "\t\t\t\t\tcounts[task_id].append(task_count)\n",
    "\t\t\t\t\t#Reset the counter for the next sequence\n",
    "\t\t\t\t\ttask_count = 0\n",
    "\t\tif task_count > 0:\n",
    "\t\t\t#The last gestures were part of a tap sequence, so include them\n",
    "\t\t\tcounts[task_id].append(task_count)\n",
    "\t\t\ttask_count = 0\n",
    "\treturn counts\n",
    "\n",
    "#Get the tap sequences \n",
    "seqs = adh.apply(tap_sequences)\n",
    "\n",
    "# #Just get some per-user totals\n",
    "raw_counts = {}\n",
    "total = 0\n",
    "for uid in seqs.keys():\n",
    "    raw_counts[uid] = 0\n",
    "    #Sum up over all the tasks\n",
    "    for tid in seqs[uid].keys():\n",
    "        raw_counts[uid] += sum(seqs[uid][tid])\n",
    "    total += raw_counts[uid]\n",
    "\n",
    "\n",
    "#Put it in a dictionary by condition\n",
    "#Make condition dict expects everything in arrays already\n",
    "raw_counts = {k:[v] for k,v in raw_counts.items()}\n",
    "print make_condition_dict(raw_counts)\n",
    "\n",
    "#Convert each user's per task counts into a list of counts\n",
    "by_user = {}\n",
    "for user in seqs.keys():\n",
    "    sequences = []\n",
    "    for task in seqs[user].keys():\n",
    "        #Since we don't care about 0-length sequences of taps, filter those out\n",
    "        sequences.extend([c for c in seqs[user][task] if c > 0])\n",
    "    by_user[user] = sequences\n",
    "cond_seqs = make_condition_dict(by_user)\n",
    "print cond_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I learn from this is that the overall _length_ of sequences of taps doesn't really go up in the 10 user case, but there are a lot more taps in the ten user case. Looking at the averages, std devs, and total sequence count may be of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unknown \t Count: 28\t Mean: 1.0357\t Std. Dev.: 0.1856\n",
      "  thousand \t Count: 17\t Mean: 1.0588\t Std. Dev.: 0.2353\n",
      "   hundred \t Count: 23\t Mean: 1.2609\t Std. Dev.: 0.4391\n",
      "       ten \t Count: 72\t Mean: 1.5000\t Std. Dev.: 1.6499\n",
      "       one \t Count: 42\t Mean: 1.2619\t Std. Dev.: 0.5798\n",
      "Total tap selects: 237\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for c in cond_seqs.keys():\n",
    "    c_str = (\" \" * (10-len(c))) + c\n",
    "    seq_count = len(cond_seqs[c])\n",
    "    total += sum(cond_seqs[c])\n",
    "    mean_len = float(sum(cond_seqs[c]))/float(seq_count)\n",
    "    std_dev = np.std(cond_seqs[c])\n",
    "    print \"{} \\t Count: {}\\t Mean: {:.4f}\\t Std. Dev.: {:.4f}\".format(c_str, seq_count, mean_len, std_dev)\n",
    "print \"Total tap selects: {}\".format(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, and not entirely unexpectedly, the ten robot case has a way higher standard deviation. Apparently, at least one user did a tap on every robot, and they did way more taps in general. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
