{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preamble stuff, loading up libraries and convenience functions\n",
    "import all_data_handler\n",
    "import pandas\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import itertools\n",
    "import seaborn as sb\n",
    "import scipy.stats as ss #For ss.f_oneway() ANOVAs\n",
    "\n",
    "import re\n",
    "\n",
    "#Given the object list of a gesture from the coding, return a list of letters representing normalized \n",
    "#values for the objects of the gesture\n",
    "def tag_object(original):\n",
    "    #This use of strip is to prevent quotes from messing up regex matches\n",
    "    original = \" \".join(event[\"objects\"]).strip(\"\\\"\")\n",
    "\ttags = []\n",
    "\t#Matches robots, robot, bot, bots, etc. \n",
    "\trobots = re.compile(\"bot|group|swarm|orange|red\", re.I)\n",
    "\tcrate = re.compile(\"crate\", re.I)\n",
    "\ttargetA = re.compile(\"area a|box a| a$|to a,|^a$\", re.I)\n",
    "\ttargetB = re.compile(\"area b|box b| b$|to b,|^b$\", re.I)\n",
    "\twhitespace = re.compile(\"whitespace|ground|screen|white area\", re.I)\n",
    "\t\n",
    "\ttoCheck = [(robots, \"r\"), (crate, \"c\"), (targetA, \"a\"), (targetB, \"b\"), (whitespace, \"w\")]\n",
    "\tfor compiled, tag in toCheck:\n",
    "\t\tif re.search(compiled, original):\n",
    "\t\t\ttags.append(tag)\n",
    "\treturn tags\n",
    "\n",
    "def count_select_taps(participant):\n",
    "    #Dict of task id to count of taps on robots\n",
    "    counts = {}\n",
    "    for task_id in participant[\"tasks\"].keys():\n",
    "        #Default to no counts of select taps\n",
    "        counts[task_id] = 0\n",
    "        events = participant[\"tasks\"][task_id]\n",
    "        #Flip through all the events\n",
    "        for event in events:\n",
    "            #If we have objects, tag them\n",
    "            if \"objects\" in event.keys():\n",
    "                tags = tag_object(event[\"objects\"])\n",
    "                #We have both an event and a set of tags, check if it's a tap on a robot\n",
    "                if 'r' in tags and event[\"event_type\"] == \"tap\":\n",
    "                    counts[task_id] += 1\n",
    "    return counts\n",
    "\n",
    "def count_group_select(participant):\n",
    "    #Dict of task id to count of taps on robots\n",
    "    counts = {}\n",
    "    for task_id in participant[\"tasks\"].keys():\n",
    "        #Default to no counts of select taps\n",
    "        counts[task_id] = 0\n",
    "        events = participant[\"tasks\"][task_id]\n",
    "        #Flip through all the events\n",
    "        for event in events:\n",
    "            #If we have objects, tag them\n",
    "            if \"objects\" in event.keys():\n",
    "                tags = tag_object(event[\"objects\"])\n",
    "                #We have both an event and a set of tags, check if it's a tap on a robot\n",
    "                if 'r' in tags and (event[\"event_type\"] == \"lasso\" or event[\"event_type\"] == \"box_select\"):\n",
    "                    counts[task_id] += 1\n",
    "    return counts\n",
    "\n",
    "def count_box_select(participant):\n",
    "    #Dict of task id to count of taps on robots\n",
    "    counts = {}\n",
    "    for task_id in participant[\"tasks\"].keys():\n",
    "        #Default to no counts of select taps\n",
    "        counts[task_id] = 0\n",
    "        events = participant[\"tasks\"][task_id]\n",
    "        #Flip through all the events\n",
    "        for event in events:\n",
    "            #If we have objects, tag them\n",
    "            if \"objects\" in event.keys():\n",
    "                tags = tag_object(event[\"objects\"])\n",
    "                #We have both an event and a set of tags, check if it's a tap on a robot\n",
    "                if 'r' in tags and event[\"event_type\"] == \"box_select\":\n",
    "                    counts[task_id] += 1\n",
    "    return counts\n",
    "\n",
    "def count_lasso_select(participant):\n",
    "    #Dict of task id to count of taps on robots\n",
    "    counts = {}\n",
    "    for task_id in participant[\"tasks\"].keys():\n",
    "        #Default to no counts of select taps\n",
    "        counts[task_id] = 0\n",
    "        events = participant[\"tasks\"][task_id]\n",
    "        #Flip through all the events\n",
    "        for event in events:\n",
    "            #If we have objects, tag them\n",
    "            if \"objects\" in event.keys():\n",
    "                tags = tag_object(event[\"objects\"])\n",
    "                #We have both an event and a set of tags, check if it's a tap on a robot\n",
    "                if 'r' in tags and event[\"event_type\"] == \"lasso\":\n",
    "                    counts[task_id] += 1\n",
    "    return counts\n",
    "\n",
    "#Returns a dict of task IDs to count of total events\n",
    "def count_events(particpant):\n",
    "counts = {}\n",
    "    for task_id in participant[\"tasks\"].keys():\n",
    "        #Default to no counts of select taps\n",
    "        counts[task_id] = 0\n",
    "        #Flip through all the events\n",
    "        for event in events:\n",
    "            if event[\"event_type\"] == \"memo\":\n",
    "                #This event is a memo, not a user gesture\n",
    "                continue\n",
    "            elif example in event.keys() and event[\"example\"] == True:\n",
    "                #This event is an example, don't count it\n",
    "                continue\n",
    "            else:\n",
    "                #Not one of the skip cases, so count it\n",
    "                counts[task_id] += 1\n",
    "    \n",
    "#This gets a dict of user ids to dicts of task ids to select tap counts\n",
    "all_select_taps = adh.apply(count_select_taps)\n",
    "all_group_selects = adh.apply(count_group_select)\n",
    "all_lassos = adh.apply(count_lasso_select)\n",
    "all_box = adh.apply(count_box_select)\n",
    "all_gesture_counts = adh.apply(count_events)\n",
    "\n",
    "#Prints out the per-condition counts, one entry for each user in that condition\n",
    "#Also gets the mean and standard deviation for the condition\n",
    "def user_counts(user_counts):\n",
    "    per_cond = {}\n",
    "    #For each user, maintain a running total\n",
    "    for pid in user_counts.keys():\n",
    "        #Get their condition\n",
    "        cond = adh.IdToCondition(pid)[0]\n",
    "        counts = user_counts[pid].values()\n",
    "        per_user_total = sum(counts)\n",
    "        if cond in per_cond.keys():\n",
    "            per_cond[cond].append(per_user_total)\n",
    "        else:\n",
    "            per_cond[cond] = [per_user_total]\n",
    "    \n",
    "    for cond in per_cond.keys():\n",
    "        \n",
    "        total = sum(per_cond[cond])\n",
    "        mean = np.mean(per_cond[cond])\n",
    "        std_dev = np.std(per_cond[cond])\n",
    "        print cond, per_cond[cond]\n",
    "        print \"total:{} mean:{} std dev:{}\".format(total, mean, std_dev)\n",
    "        print\n",
    "\n",
    "#Given a dict of user IDs to dicts of task ids to event counts\n",
    "#return a dict of user IDs to lists of event counts for the common tasks\n",
    "def get_matched_tasks(counts):\n",
    "    #Get a list of the task names that every condition has in common\n",
    "    common_names = []\n",
    "    for name in adh.taskMap.keys():\n",
    "        if all(adh.taskMap[name].values()):\n",
    "            common_names.append(name)\n",
    "    common_names.sort()\n",
    "\n",
    "    #dict of user ids to a list of counts, index of counts is task number\n",
    "    matched_tasks = {}\n",
    "    for user in counts.keys():\n",
    "        common_counts = []\n",
    "        for task in common_names:\n",
    "            #print user, adh.IdToCondition(user), task, adh.taskNameToNumber(task, user)\n",
    "            #Get the count at the task number for this common name\n",
    "            common_counts.append(counts[user][str(adh.taskNameToNumber(task, user))])\n",
    "        matched_tasks[user] = common_counts\n",
    "    return matched_tasks\n",
    "\n",
    "#Given a dict of conditions to lists of samples\n",
    "#Do an all-pairs 1-way ANOVA on the samples\n",
    "def all_pairs_f(d):\n",
    "    for k1, k2 in itertools.combinations(d.keys(), 2):\n",
    "        print k1, k2\n",
    "        print ss.f_oneway(d[k1], d[k2])\n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H1: There exists a number of robots beyond which users will transition from treating robots as individuals to interacting with the robots in small groups or as a single large group. \n",
    "\n",
    "This transition point will be apparent because of a change in the gesture set that the user uses to interact with the swarm. It is hypothesized that above the transition point, users will be more likely to neglect some subset of the available robots. The user will instead use commands that control the bulk of the robots as a cloud or flock, but may leave some robots unused. For example, the user may switch from selecting robots as individuals to shaping and pushing the swarm the way a child might play with a bug, putting their hand down so the bug goes around or avoids it, touching the back of the bug gently to make it scurry forwards, and so forth, or by shaping the group as if sculpting, with pushing and pinching to \"carry\" groups around. \n",
    "\n",
    "The user may also change how they indicate which robots are to be interacted with. Rather than selecting each robot by clicking on it, the may \"paint\" over the area containing the robots they want to use, or draw a circle around them. \n",
    "The size of the swarm where changes in the user gestures occur will indicate the transition point between interacting with individual robots and interacting with the swarm as a whole. \n",
    "\n",
    "This hypothesis would be invalidated by the gestures selected by the user displaying no correlation with the size of the swarm that they are controlling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2: A display which obscures individual robots and displays a cloud or swarm boundary will cause the user to treat the swarm as a whole rather than individuals, which will be apparent because the user will use the same gestures they would use to control a single robot. \n",
    "\n",
    "Once the ratio of the size of individual swarm members to the size of the area the swarm is in becomes sufficiently large, displaying the swarm members at the same scale as the map will result in the representation of the swarm members being too small to interact with. This problem will arise at smaller scales if the swarm robots are themselves quite tiny, and some of the available swarm robots are indeed small. Scaling the representation of the robots up, relative to the map, will make the robot representations overlap unrealistically and obscure the map. Instead, we propose that for certain scales of swarms, it makes sense to represent the swarm as the area covered, rather than the locations of the individual robots. This approach has been used successfully for navigation in three dimensions, by developing a controller that causes the individual UAVs to remain within a bounding prism, and allowing the user to control the shape and location of that prism.\n",
    "\n",
    "Altering how the user interface displays the location of the robots in the swarm will affect the transition point. \n",
    "\n",
    "This hypothesis would be invalidated by the gestures selected by the user in the single robot case being dissimilar from those selected in the case where the swarm is displayed as a cloud or covered region. However, some variation is expected in commands for tasks which a swarm can do, which a single robot cannot perform, such as dividing into two groups. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
