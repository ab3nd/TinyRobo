
Run experiment in style of Wobbrock et al
	Show action of swarm, then ask user to make the gestures that caused it
Because:
	Flailing, users expected UI to be interactive even though it wasn't, and they were told it wasn't

-or-

run the experiment with paper prototypes
	Users can't possibly expect paper to be interactive, they're used to it just being paper


Keep the swarm robots the same size?
They'd have to all be the really tiny size that was used for 1000 robot case
Scale relative to the crate was an issue
	Maybe make the crate really tiny too?


Slides that say "tell the robots to..." would just be "form a line" or "form a square"
	Some participants were very literal, but in colloquial english, we can say things like "a stop sign tells you to stop", despite the fact that it doesn't say "stop" out loud using a voice (although we would say that it "says stop")

Drop the toys earlier, they really didn't work well. 3D printing is really the way to go, or using the PCB as the frame of the robot. 

Deal with the hardware first, rather than switching back and forth and only finding tag tracking problems late in the game. 
Ideal organization would have been to get the swarm working, then do the user experiment (or the other way around), and then focus on the translation layer
	Would have caught the convergence to gritsbots/colias/mroberto a lot earlier
	Could have had implementing a bunch of swarm algos as ros nodes as part of the translation layer work?

Robots capable of monitoring their own battery charge and recharging themselves. 

SCT might be a better framework than GCPR for program generation

Communication channel back from the team is implicit, in whether the team appears to be doing what the user commanded
	Should really do a test of this
	Does having the swarm use e.g. biased random walks to accomplish a task bother the users?
		Probably better done in simulation, more control over the degree to which the swarm appears to be dicking around instead of working
		
