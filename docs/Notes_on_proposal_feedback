Hobby robotics is very underrepresented in the scientific literature, searches on google scholar didn't turn up much about the platforms used
	- Could try screen-scraping instructables or something
	- Seems like more trouble/time than it's worth

Why use real robots?

Brooks in Artifical Life and Real Robots: "unfortunately there is a vast difference (which is not appreciated by people who have not used real robots) between simulated robots and physical robots and their dynamics of interaction with the environment"
	- Is this still the case? This was in the '90s
	- This paper is REALLY precient
		- evolvable controllers for real robots
		- Golem project evolving bodies/controllers together
	"Without regular validation on real robots, there is a great danger that much effort will go into solving problems that simply do not come up in the real world with a physical robot"
	"There is a real danger (in fact, a near certainty) that programs which work well on simulated robots will completely fail on real robots because of the differences in real world sensing and actuation - it is very hard to simulate the actual dynamics of the real world."

	Sensors are uncertain
		It seems like I have virtual sensors, and so I'm way more certain. 
		This is not the case, I have physical sensors, they're just not the physical sensors that they are presented as. 
		Sonar is not a ruler, but we use it to measure distance. 
		A camera is not a laser, but it's still a physical optical sensor being used to measure distance
			Could test noise of camera based fake laser vs real lasers, characterize difference between multiple sensor readings of same thing

	Nap of carpet can affect odometry
		- which some people tried to work around with nap sensors
			- which is clearly insane, but has kind of a chicken-and-egg feel to it
		- this isn't the kind of thing simulators even attempt to do
			- combinatorical disaster (how many kinds of carpet are there?)

Tim Smithers, "On Why Better Robots Make it Harder"
	The idea that the variation in real robot behavior will go away if the robots are "better" as a justification for simulation
	Better-made components allowing hunting where worse ones provided damping (steam engine governor example)
	Don't view robots as measuring with sensors and reasoning about results
		Sensors act as filters whose output drives internal robot dynamics

Simulation Tools for Model-Based Robotics: Comparison of Bullet, Havok, MuJoCo, ODE and PhysX
Tom Erez, Yuval Tassa and Emanuel Todorov.
	Most simulators aimed at visual plausibility, for video games
	Contact dynamics are particularly hard (NP-Hard, in fact)
		workaround is approximation, which raises concerns about accuracy
	Simulations deviate due to
		numerical instability
		model errors
			e.g. Sims and the evolved robots that push themselves around
	Showed speed accuracy tradeoff, no simulator stood out over all others
	ODE does coriolis forces, which is how Sims bots cheated 
	PhysX and Havoc don't, so that's still possible

	So overall, yes, the situation Brooks described still holds

An Overview about Simulation and Emulation in Robotics
Michael Reckhaus, Nico Hochgeschwender, Jan Paulus, Azamat Shakhimardanov and Gerhard K. Kraetzschmar
	Simulation went out of fashion when people started getting real robots
	Computers got better and games drive for realism pushed development
	Proposes a lot of use cases and reasons to use simulation
		Which are interestingly orthogonal to the reasons not to use it
			One doesn't counter the other, it's just "here are the good parts, here are the bad parts"

Simulation in robotics
Leon Zlajpah
	Overview of tools

Noise and The Reality Gap: The Use of Simulation in Evolutionary Robotics
Nick Jakobi and Phil Husbands and Inman Harvey
	Having too much noise in evolved controller simulation environment can result in controllers that rely on there being more noise than there is in the real world

Swarm Engineering
S. Kazadi PhD Thesis from Caltech, May 2000


Defence of heterogeneity
	Keeps individual robots from becoming complex by attempting to do everything
		Spreads ability over swarm, if there are multiple gripper robots and multiple scout robots, losing one isn't as problematic
		Swarmanoid
	Practical concern with toys
		May build swarm in stages, change platforms based on ability or cost
		Tries to move platform-specific calculations closer to the hardware, leaving higher-level concerns able to be interchanged
	Impact on compilation
		minimization of mobility heterogeneity means that current translator does not use robot capability in translation
		Could be extended to ensure that tasks were assigned to robots that can perform them
			Task assignment is a well-studied problem in the literature
			Makes the assumption that the robots the user selects have the capability to do what they command
				Error back to user if robot can't do it? Select closest robot that can?
	Heterogeniety is a good model of real-world situations
		Swarm members of different capability, e.g. family groups of pack animals, young-old, ill members
		Military convoy with different vehicles (HUMV, Tank, Jeep)
		Human/robot teams 


A Minimalist Flocking Algorithm for Swarm Robots
Christoph Moeslinger, Thomas Schmickl, and Karl Crailsheim
	Simulated flocking 
	Can work with heterogeneous robots as long as they use the same sensing method (IR rangers)
		Doesn't actually justify how they know this, though
		Robots heading/motion is abstract, so could be mobility-heterogeneous

Self-Organized Flocking with a Heterogeneous Mobile Robot Swarm
Alessandro Stranieri, Vito Trianni, Eliseo Ferrante, Carlo Pinciroli, Marco Dorigo, Ali Emre Turgut, Mauro Birattari
	Heterogeneous
	Aligning robots can agree on a common heading
	non-aligning robots cannot
	Behavioral heterogeneity
	Boids - seperate, cohere, align
		This work, some robots don't align
	As proportion of aligning robots drops, performance degrades

Mixed Species Flocking for Heterogeneous Robotic Swarms
Sifat Momen, Bala P. Amavasai, Nazmul H. Siddique 
	Defines flocking efficiency as percentage mean number of agents participating in a flock
	Two types of agents, can tell each other apart
	Variable heterospecific attraction (tendency to join each other's flocks)
		Increasing this increases efficency
	Doesn't really indicate why heterogeneity is cool
		Birds apparently form mixed flocks for predator defence

Flocking for Heterogeneous Robot Swarms: A Military Convoy Scenario
Christopher JR. McCook and Joel M. Esposito
	2 unit types, supply unit and defender unit
	Control based on potential field derived from stated goals of the units

Swarmanoid: A Novel Concept for the Study of Heterogeneous Robotic Swarms
By Marco Dorigo, Dario Floreano, Luca Maria Gambardella, Francesco Mondada, Stefano Nolfi, Tarek Baaboura, Mauro Birattari, Michael Bonani, Manuele Brambilla, Arne Brutschy, Daniel Burnier, Alexandre Campo, Anders Lyhne Christensen, Antal Decugnière, Gianni Di Caro, Frederick Ducatelle, Eliseo Ferrante, Alexander Förster, Jerome Guzzi, Valentin Longchamp, Stéphane Magnenat, Javier Martinez Gonzales, Nithin Mathews,
Marco Montes de Oca, Rehan O’Grady, Carlo Pinciroli, Giovanni Pini, Philippe Rétornaz, James Roberts, Valerio Sperati, Timothy Stirling, Alessandro Stranieri, Thomas Stützle, Vito Trianni, Elio Tuci, Ali Emre Turgut, and Florian Vaussard
(37 authors, but it was a big project...)
	Accuses swarm systems of being homogeneous as an oversimpification of natural systems, e.g. all worker ants
	Footbots (wheeled, with omnicams)
	Handbots (climbers and manipulators)
	Eyebots (flyers, with cameras for overhead views)
	No centralized control
	Swarm + Humanoid, intended to refute the idea humans are the best form to operate in human-designed spaces
	Interchangalbe parts, gives robustness
	Local ad-hoc groups and structures to perform tasks
	Being able to physically interact adds complexity to design
		Manipulation and sensing methods must be compatible to allow interaction and communication
		Robots may have very different perceptions and want to communicate about them
	Indirect relationship between what individual robot is doing and what swarm as a whole is doing
		Heterogenieity increases complexity
	All the robots do IR comms and range/bearing sensing
	Eyebots collaborate to localize off each other
		Other robots can also localize off of them

Heterogeneous Multirobot Cooperation
Lynne E. Parker MIT AI Lab tech report 1465				TODO README
	Paper describing ALLIANCE

Does driving real robots affect user behavior?
	Does realism of NUI affect user behavior?

How/when do humans stop treating people as individuals and start dealing with groups?
	Gestalt perception 
		Proximity principle, elements near each other are perceived as groups
		Common fate principle, things that move together are perceived as a unit
		Similarity principle, elements that are the same are grouped together
		Various others
			But the heirarchy among them is amorphous, so doesn't give clear parsings of complex scenes

Do Numbers Really Count? Group Threat Theory Revisited
Dr Mikael Hjerm
	Size of a minority affects perception of threat to the majority
	Actual and perceived size of minority doesn't affect threat perception across 20 EU countries
	Not really about group size for social interaction

Perception of Groups, Size of Opposition, and Social Influence
DAVID A. WILDER
	Organized attempted social influencers as group, multiple small groups, or individuals
	More groups -> more conformity
	Varying size of single group -> little effect on conformity
	Increase in opposition size beyond 3-4 people has little impact
		First opposer is a leader, the rest are clearly sniviling synchophants
		So the group more-or-less counts as 1 person
	"Persons may regard opponents as discrete individuals contributing independent bits of information until opposition size increases beyond some critical point, after which they are perceived as a single group unit. Additional opponents are assimilated to the group unit, so that the number of distinct entities in opposition remains constant. This process is analogous to a Gestalt principle of organization in which elements exhibiting similar characteristics are “grouped” together."
	4 individuals is 4 data points, but one group of four people is one data point
	Similar actions in a group is assumed to be a product of group influences
	Similar actions in individuals are assumed to be product of their internal state/abilities
	Talks about a cut-off group size, but doesn't say what it is

Choice Behavior in Social Dilemmas: Effects of Social Identity, Group Size, and Decision Framing
Roderick M. Kramer, Marilynn B. Brewer
	Larger groups get worse at providing a public good
		Probably diffusion of responsibility, there are enough people doing X that I don't have to
		Number of other possibilities (social loafing, decrease in payoff, deindividualization)
	Mixed findings around group size, one reports showed no difference between 7 and 20, but another found 1 was better than 3 was better than 6
	Not really related, has to do with perception of group one is in

Perceiving Persons as a Group: Effects on Attributions of Causality and Beliefs
DAVID A. WILDER
	Distinction between groups and aggregates of people
	Groups have a boundary, in or out, aggregate does not (just a random set of people, anyone could be in it)
	Not about how people make the distinction between individuals and groups, but how they perceive the people in either aggregates or groups

Trust Transfer on the World Wide Web
Katherine J. Stewart
	Cites Campbell (1958) for introducing "the term 'entitativity' to describe the degree to which a collection of individuals is perceived as a group"
		Continuum, not binary group/not group distinction
		Higher entitativity -> higher expectation of unity and consistency
	Members of small groups perceived as more similar than members of large groups (salience increases as group size decreases)

Many Hands Make Light the Work: The Causes and Consequences of Social Loafing
Bibb Latane, Kipling Williams, and Stephen Harkins
	Interesting, but not related


Elements of a Lay Theory of Groups: Types of Groups, Relational Styles, and the Perception of Group Entitativity
Brian Lickel and David L. Hamilton, Steven J. Sherman
	What is people's intuitive understanding/taxonomy of groups?
		Clustering of survey categorization of groups
			Intimacy groups (friends, family, romantic)
			Task groups (work, jury)
			Social category (gender, race, class)
			Loose associations (line at the bank, parade crowd, fans of a musical genre)
		Clusters have different qualities wrt permiability, size, duration, level of interaction, etc. 
	How do they arrive at conclusions about groups?
	Perception of relationsl style in the group and perception of entitativity are related
		unclear how degree vs quality of interaction affects perception of entitativity


Varieties of Groups and the Perception of Group Entitativity
Brian Lickel and David L. Hamilton, Grazyna Wieczorkowska, Amy Lewis and Steven J. Sherman, A. Neville Uhles
	Cited from previous paper "Elements of a Lay Theory..."
	Curse of high dimensionality
		What a "group" is is highly variable
	Very little study of dynamic small groups (more study of stereotypes of large groups not personally related to the subject)
		Relational vs. perception, are subjects within group, or outside observing?
	Entitativity is about perception of group, not actual objective assessment of the group
		How much do they appear to be a group, not how well do they actually function as one
		Affects perception as causal agent, higher entitiativity -> more causally effective
	Perciever differences
		Need for closure (?)
		individualism/collectivism biases in observer
	Contextual factors
		Observer in group or not
		competition present between groups?
	Properties of the group itself
		do they all dress the same?
		Similarity in Campbell paper, possibly links to gestalt perception
	Minorities higher in entitativity
		Arguably links to gestalt perception, figures vs. ground
		members stereotyped -> increased similarity within group -> higher entitativity
	Entitativity isn't about the group size cutoff so much as it is about the groupiness of a group. 

Static Versus Dynamic Theories and the Perception of Groups: Different Routes to Different Destinations
Sheri R. Levy, Jason E. Plaks, Ying-yi Hong, Chi-yue Chiu, Carol S. Dweck
	Static view thinks people are fixed entities
	Dynamic view thinks people are changeable tendencies
	Has effects on perception of groups, but not related to my work

Neocortex Size as a Constraint on Group Size in Primates
R. I. M. Dunbar
	Group size is a function of neocortical size, but environment is not 
	Information overload is on whole network structure, not count of dyadic relationships
	Larger groups are groups of grooming cliques
		Implies formation of heirarchy at ~150 members (upper bound, for humans)
	Selective pressures favoring larger groups drive increased brain size
	Could put an upper bound on human social groups, but that isn't the same thing as perceived group size

A Study of Interaction and Consensus in Different Sized groups
A. Paul Hare
	9 groups of 5 boys and 9 groups of 12 boys (all boy scouts)
	Rated 10 pieces of equipment individually for utility in escaping the wilderness
		Each group then had to select the most important piece
	Measured increase in consensus after discussion
	Smaller groups acheive consensus better
	Leaders have more influence in small groups
	Larger groups take longer to come to consensus


Overall, it feels like the research in social psychology for how groups are perceived as groups vs. aggregations and how much of an entity the group is are highly dependant on a large number of distinct factors. My robot groups have color, heading, spacing, but beyond that don't display a lot of the variation that people display, even when the group they are in has strong entiativity (also depends on context, the robotics club is an entity, the same people standing in line at a bank would be way less of an entity). Human perception of groups has less to do with exact count of people, and far more to do with common cause, visible similarity, tasks, interpersonal relations, etc. 

Unified Human and Robot Command for Disaster Recovery Situations
Carlos Ibarra Lopez, James Kuczynski, Holly A. Yanco
	(Hey, I know that guy!)
	Multi-agent command software
		Expanded on Mark's work, small group and individual C&C, not swarm scale
		DREAM controller
	People are willing to use manual control mode on people
		if they're inexperienced with robots, they're more likely to use it on people than on robots
		If they're experinced with robots, they use it more on robots than on people
	Similar level of success with both people and robots and mixte teams

So driving real robots vs. driving people does affect human behavior, what about driving real robots vs. simulated robots?


Carlos cites Humphrey et. al. 2007 for interface for control, but it's for multiple individuals, not swarms
	What does Humphrey cite? Can talk about distinction between multi-individual and swarm




Spontaneous, Short-term Interaction with Mobile Robots
J. Schulte, C. Rosenberg, S. Thrun
	Single robot interacting with crowds, not single person interacting with crowd of robots


Guiding and Interacting with Virtual Crowds in Real-Time
Soraia Raupp Musse, Fabien Garat and Daniel Thalmann
	Virtual crowds for simulated worlds
	Programmed, autonomous, or guided/interactive control
	UI allows people to type in messages to be sent to the crowds, text boxes and a big "SEND" button
	Guided crowd has some autonomy, can be told to go do specific actions or react to triggered events

IntGUItive: Developing a Natural, Intuitive Graphical User Interface for Mobile Devices
Ammaar Amin Mufti
	Ha ha ha "Natural, Intuitive"
	Depth as a guide
		highlighting and shading
		static light in upper l of screen
		buttons on top of screen plane, screen controls below it
		non-interactive elements should stay flat/have no perspective
	Transition from skeuomorphism to flat/minimal
	Zooming-based UI


Arch-Explore: A Natural User Interface for Immersive Architectural Walkthroughs
Gerd Bruder, Frank Steinicke, Klaus H. Hinrichs
	Cave-based architectural walkthrough software
	Based on actual walking around, but not related (v. clever, though)

Post-WIMP User Interfaces
Andries van Dam
	Eventually wants a butler-style interface
		Not useful for creative tasks, but I guess that's not what he wants to do
	Reasonably precient for 1997, though. 

A comparison of human-computer user interface methods: The effectiveness of touch interface compared to mouse
Muncey, Andrew
	Touch better than mouse for selection, dragging, gestures
	Analysis of some UIs, not relevant at the moment

Skeu the Evolution: Skeuomorphs, Style, and the Material of Tangible Interactions
Shad Gross, Jeffrey Bardzell, Shaowen Bardzell
	Interesting points about skueomorphs kept around as kitsch (deliberately) vs kept around because no one thought to do it a different way



Affordances for designing natural user interfaces for 3D modelling
Zoltán Rusák, Ismail Cimen, Imre Horváth and Aadjan van der Helm
	Physical and anthropomorphic aspects of hand gestures
	Discussion of various matching methods
	Have to balance what can be detected by the technology with what the user finds appropriate
	Users asked to do gestures for various modeling actions
		motions, rotations of object
		Selection of object
		motion/rotation of camera/zoom
		extrude
		undo
		etc.
	Validation by doing the tasks
		Qualitative accuracy assessment
	Error types
		1 - hand motion isn't part of the UI, so system doesn't recognize it
		2 - system fails to recognize an action that is part of the UI
		3 - errors due to limitations of the tracking technology
	Mouse and keyboard took less time, but more actions
		It would be nice to know how an "action" is defined...
	Extrusion and delete tasks had most of the errors
		Mostly type 2 & 3, so the gesture chosen by the designer was bad

Semiotic analysis of multi-touch interface design: The MuTable case study
Jan Derboven, Dries De Roeck, Mathijs Verstraete
	Semiotic analysis (meaning of signs and sign systems)
	User interface is a message from designers to users
	early NUI, content serves as the interface
	Users interact in a direct, unmediated way
		In theory, no icons, no metaphors
			But anything on a screen is a metaphor

Game UIs

FIFA 17 - Soccer, full teams on field, console, so gamepad interface
	move on l stick, sprint/dribble/stop ball (so moderate-level abstraction of play commands)
	Attacking (various kinds of fake/real shots, passes)
	tactics on d-pad
	Defence (tackles, changing player, jockey, etc.) mostly on buttons and triggers
	Set pieces on buttons (free kick, corners and throw-ins)
	Goalkeeper has its own controls
	Generally, interface is controlling a single player, probably the one with the ball

Age of empires - RTS
	has fog of war
		Unexplored, explored but not occupied, currently occupied
	Panning around world map appears to be off hand from mouse
	Box select for units 
	Multiplayer, appears to have context menu for actions in the bottom left corner
		May actually be key-related actions, mouse cursor stays over screen

Battlefield - FPS
	Radial menu
	WASD for move, mouse look (pretty standard RTS)
	jump, many other moves are on the left side of the keyboard around wasd
	weapon controls on mouse

Battlefront - FPS
	WASD move, mouse look, spacebar jump, powerups on 1-4, gun and zoom controls on mouse clicks

Borderlands standard FPS controls
	PC adds inventory, callenges, skills, and a map that don't appear to have matches on console (and are on IJKM, so not around WASD constellation)

Brawlhalla
	Keyboard A Controls

    Up - Jump
    C or Left Click - Light Attack
    X or Right Click - Heavy Attack
    Z - Dodge
    V or Middle Click - Throw

	Keyboard B Controls

    W - Jump
    4 or Left Click - Light Attack
    5 or Right Click - Heavy Attack
    8 - Dodge
    6 or Middle Click - Throw

    Keys all placed very close to each other

Bubble witch saga
	Mobile, aim and fire bubbles, make matches to get screen clear

Call of Duty, CoD Zombies - FPS
	Had trouble finding the controls, probably typical FPS

Civ V - Turn-based strategy
	Mouse interaction, pop-up menus around the edge of the screen
	isometric view map
	Map in hex grid

Clash of clans
	Train troops in your base, attack others, try to destroy entire base
	defence is passive
	appears to be mouse-driven

Crash Bandicoot - platformer, console
	Character move on dpad or left stick
	attac - square
	inventory - triangle
	jump - x 

Crypt of the Necrodancer
	Has Fog of War
	Moving, digging and attacking: 	up, right, down, left
	To use your Bombs: 	down + left
	To use your first item: 	up + left
	To use your second item or

	To swap weapons:
		left + right
	To use your first spell: 	up + right
	To use your second spell: 	down + right
	Reload/Throw Weapon: 	up + down 
	So it's like DDR on a keyboard, can only act in time with the beat of the music

Dark Souls Console  and PC action rpg
	l stick player
	r stick camera 
	d-pad weapon/magic controls
	triggers have a lot of modifiers for combat (block types, dash, backstab, etc.)

	PC
		WASD run, l control + WASD = walk
		camera IJKL, just like WASD
		VCFR switch equipment
		a lot of keys on the right hand do weapon action / item actions
		No mouse at all, but this is 3rd-person rather than first-person, so no splitting body into upper and lower control

DOTA - Realtime 3rd person battle
	https://dota2.gamepedia.com/Controls
	l click, l click and drag for box select
	shift click to add
	right click is do (move to, attack, shift queues order)
	esc to stop/undo

	alt + left click does communication actions
	WASD for moving camera (overhead/isometric view)

Europa Universialis
	doesn't appear to show actual units, map/overhead view
	Does appear to have box selection
	doesnt' appear to be realtime
	Regiments listed as units, strength by numbers
	Pop-up menus 
	https://eu4.paradoxwikis.com/Controls
	Uses entire keyboard, no mapping of key to action as WASD, although slight mnemonics

Fire Emblem
	Appears to have perfect information
	Battles appear automated, moves appear semi-turn-based
	Menu-based weapon selection 
	D-pad for cursor, scrolling in menus
	A - confirm, context-sensitive map menu or dialog scrolling
	B - cancel/undo
	L - scrol between uncommanded units
	R - Data for the unit the cursor is over, info on items during battle

RimE - exploration? 3d 3rd person view
	WASD move, space jump, e interact, shift roll/dive, l mouse "shout"
	Doesn't appear to even have an "attack"?

Paragon - MOBA
	WASD/Mouse controls like a FPS

Seems like games that require real-time interaction (FPS, RPG) keep the keys close to each other, games that don't have the keys laid out however the designers felt like it (EU4). DOTA interesting because it's almost all mouse and modifiers. 

FPS very standard, wasd move, mouse look and fire control, space jump

Intel shooting star drones (from Intel-Shooting-Star-Tech-Fact-Sheet-073117-1.pdf)
	"proprietary algorithms"
	Automated creation of image, calculation of drones needed to form it
	Controlled by a single computer (what happens if it goes down?)
	Max range is 1.5km (is that drone travel or wireles range?)

	From video screenshots, appears to be a 3D rendering suite similar to Blender
	GPS + barometer (that's not enough resoultion, they're doing something else)
		Ascending Technologies (AscTec) Trinity Autopilot, triple-redundant IMU
		http://www.asctec.de/en/asctec-trinity/ claims reproducable 3d flight "within gps accuracy"
		ASCTec also had a program called Navigator for GPS flight control

	Can apparently import some form of GIS data to place drones relative to ground level, avoid hills
	Has tabs for "Curves/Surfaces", "Poly modeling" and "Sculpting" in UI
	Also "Rigging", "Animation", FX & FX Caching, HEALTH, and some stuff I can't make out
	Seems like a 3d CGI suite, but rendering to drones rather than rendering to an STL file

	Coachella video has touch interaction with 3d display of drones in a volume of space

	UI in 500 drone video seems to be earlier version? Still has GIS import
	Also shows single point scrolling and rotation of swarm with touch commands
	Talks about changing thinking "from many individual drones to one single fleet of drones"

	Automated health monitoring and drone selection for better deployment
	Red/yellow/green dot interface for at-a-glance health monitor, probably battery status

Design of a Drone Lead-Follow Control System
Alexander Lanteigne, Elias Kibru, Sabreena Azam, Suliman Al Shammary
	Lead/follow control law
	AscTec drone (hummingbird)
	Also has some stuff on profitability of shows?
		Weird change in focus for the paper
	Models risk of drone loss

Gesture Based Human - Multi-Robot Swarm Interaction
and its Application to an Interactive Display
J. Alonso-Mora, S. Haegeli Lohaus, P. Leemann, R. Siegwart, and P. Beardsley
	Gesture control of robots acting as mobile pixels
	Co-locaed with robots, had to point at the robots
	Useful description of interface
	Swarm still centralized, though
	System operating as an "intractive display", so kind of an electronic toy/amusement device


Human Influence of Robotic Swarms with Bandwidth and Localization Issues
S. Nunnally, P. Walker, A. Kolling, N. Chakraborty, M. Lewis, K. Sycara, and M. Goodrich
	Cites a vector-field based interface for battlefield conditions
		M. Fields, E. Haas, S. Hill, C. Stachowiak, and L. Barnes, “Effective robot team control methodologies for battlefield applications,”
	Other relevant papers
		A. Naghsh, J. Gancet, A. Tanoto, and C. Roast, “Analysis and design of human-robot swarm interaction in firefighting,”
		M. Goodrich, B. Pendleton, P. Sujit, and J. Pinto, “Toward human interaction with bio-inspired robot teams,”
		G. Coppin and F. Legras, “Autonomy spectrum and performance perception issues in swarm supervisory control,”
		Z. Kira and M. Potter, “Exerting human control over decentralized robot swarms,”
	Interface has two commands, "stop" and "head towards"
		Mouse clicks, plus zoomable/pannable viewpoint
	Operators adapted to swarm conditions and stayed able to perform tasks

Two Invariants of Human-Swarm Interaction
Daniel S. Brown, Michael A. Goodrich, Shin-Young Jung, and Sean Kerman
	Claims two invariants:
		(1) collective state is the fundamental percept associated with a bio-inspired swarm
		(2) a human’s ability to influence and understand the collective state of a swarm is determined by the balance between the span and persistence.
	Attractors abstract from individual to group behavior, so humans percieve and try to manage attractors
	"Span" is how many units the controller interacts with
	"Persistence" is how long each interaction takes
		If you have low span, you need long persistence to make a change
	Citation of mulitple fan-out papers
		Need to manage group, not individuals
		"Other work has estimated fan-out using large simulation studies involving several sizes of robot teams (Olsen & Wood, 2004; Olsen, Wood, & Turner, 2004)."
		"Pourmehr, Monajjemi, Vaughan, and Mori (2013) examine group-level abstracted multi-robot control to form dynamically-sized teams to increase fan-out."
	Swarm model similar to boids, can transition between torus and flock
		... doesn't really talk about e.g. moving an object or obstacle avoidance
	Shape torus using mediators with attraction/repulsion

Toward Human Interaction with Bio-Inspired Robot Teams
Michael A. Goodrich and Brian Pendleton, P. B. Sujit and Jose Pinto
	Information foraging problem
		Abstract resources at unknown locations in a space
		Agents have to locate the resources and stay at them for a period of time
		Resources are depleted by agents at them
		New resources can appear at any time
		Human input is helpful
	Other appproaches
		Playbook, human calls plays for robots
		Human controls leader, other robots follow leader
		Potential fields
	Lead-by-attraction (leader) vs. lead-by-repulsion (predator)
		lead-by-repulsion makes having persistent interactions hard, and keeps span low over time
	Simulation, no real robots
		Leader models are better than predator models


Human-Swarm Interactions Based on Managing Attractors
Daniel S. Brown, Sean C. Kerman, Michael A. Goodrich
	V. Similar to "Two Invariants", which I think recaps/references it
	Raidus used for orienting affects probability of flock or torus
	So it's controllable, can switch under user control
	Good for e.g. overwatch/loiter & move-to-area
		Which is to say, flying ISR applications or search & destroy
	This seems a lot like that military system (Perdix)
		Perdix UI appears to have point-orbit, and move-to-point functions
		Overhead view, but each unit seems to be individualy taskable, but tasking all at once is also supported
			Playbook interface, operator calls plays, drones run them
			https://www.defense.gov/Portals/1/Documents/pubs/Perdix%20Fact%20Sheet.pdf	
	Has study of reliability of quorum sensing in situation with multiple robot failures


Online Feature Extraction for the Incremental Learning of Gestures in Human-Swarm Interaction
Jawad Nagi, Alessandro Giusti, Farrukh Nagi, Luca M. Gambardella, Gianni A. Di Caro
	Learning gestures from a person co-located with the robots
	Can't provide thousands of examples
	Cites work on gaze detecton, again assuming the robots are co-located
	Variant of next paper, not using an SVM anymore, doing online training

Human-Swarm Interaction through Distributed Cooperative Gesture Recognition
Alessandro Giusti, Jawad Nagi, Luca M. Gambardella, Stéphane Bonardi, Gianni A. Di Caro
	Uses swarmanoid footbots
	Bots look at human hand gestures as commands
	Bots also move around to try to figure out what the gesture is
		distributed consensus protocol
	Video session, so paper is one page teaser

Integrating human swarm interaction in a distributed robotic control system
Cristian Vasile and Ana Pavel and C ̆at ̆alin Buiu
	Chidori - 1k birds in Japanese
	Cites Particle swarm optimization methods, physicomimetics, gravity points method
	User creates attraction points and repulsion points
	Network heavy, all done in sim

Bearing-Compass Formation Control: A Human-Swarm Interaction Perspective
Eric Schoof, Airlie Chapman, and Mehran Mesbahi
	Using only local information aids robustness: agent can act alone
	Version in this paper uses bearing only
	Also uses a compass to get rotation of robot in global frame
	Deals with predictability of the motion from an HRI view
		Example is preservation of scale and centroid when changing formation shape
	Control permits combination with human influence to allow scaling and translation of formation
	Very control-theoretic approach

Human-Swarm Interaction Using Spatial Gestures
Jawad Nagi, Alessandro Giusti, Luca M. Gambardella, Gianni A. Di Caro
	Most of the same crew that were throwing gang signs at footbots
	4 selection gestures involving wearing some garish gloves and an orange shirt
	Selection, bit not commands beyond that (in future work)

Human-Swarm Interaction: An Experimental Study of Two Types of Interaction with Foraging Swarms
Andreas Kolling, Katia Sycara, Steven Nunnally, Michael Lewis
	"Currently, multi-robot approaches generally scale to at most ten’s of robots per operator even when using state of the art mapping, path planning, target detection, and coordination algorithms to alleviate the load on the operator (H. Wang et al., 2011; J. Wang & Lewis, 2007)."
	2 kinds of interaction
		Intermittent
			User tells swarm when to change from one behavior to another
			Selection - active selection of robots
				Scales better to larger swarms
				Outperforms beacon
					Broader span and persistence
		Environmental
			User manipulates environment to cause swarm response
			Beacon - operates on robots within beacon range
	Paper also lists
		Persistent
			User provides a constant control input
				Predator/leader systems, single-joystick systems
		Parameter setting
			Attractor management
	UI appears to be very single-click mouse oriented

User Interfaces for Human Robot Interactions with a Swarm of Robots in Support to Firefighters
Jeremi Gancet, Elvina Motard, Amir Naghsh, Chris Roast, Miguel Munoz Arancon and Lino Marques
	"Sahin [2] describes the swarm robotics as a (i) a large number, of (ii) homogeneous, (iii) autonomous, (iv) relatively incapable or inefficient robots with (v) local sensing and communication capabilities" - Could be the other Sahin definition I was looking for
	Remote v. Prximate interaction
	Early deployment to gather knowledge vs. synchronous deployemnt as helpers
	Details reasons firefighting is hard and how they constrain the interface design
	Light array visor
		LEDs on inside of visor as a HUD
		...I guess that's a good idea? Looks like it could be blinding.
	Paper cites EID, but I'm not sure the LAV is properly EID based on my understanding of it
	Paper mostly about LAV and data on tests with it
		Remote HSI evaluation was inerview with 4 firefighters
		Swarm seems to have been very small (4 robots?) and not very swarm-like

Exerting Human Control Over Decentralized Robot Swarms
Zsolt Kira, Mitchell A. Potter
	Focus on real-time control
	Top down control
		Global swarm characteristics defined, agents optimized to acheive those characteristics
	Bottom up control
		Virtual agents exert forces on the real agents as if they were present in the space
	Physicomimetic control scheme
	Virtual particle parameters evolved in simulation, and then used by the user to perform split and follow operations on swarm

Assessing the Scalability of a Multiple Robot Interface
Curtis M. Humphrey, Christopher Henk, George Sewell, Brian W. Williams, Julie A. Adams
	Halo display that shows were other robts are with respect to selected robot
	Supervisory control usuaally top-down, assumes known map (which USAR may not have)
	Halo kind of like HUD/radar displays in video games
	Tapping halo robot switches to that view
		So this is a many-individuals kind of interface, not a swarm interface
	Increase in workload with bounded time diminishes success
		Adding robots increases workload
	SA didn't appear to drop with more robots
		6 robots vs. 9 robots, which is still in the human-handlable fan-out that other papers have seen
	Experiment proposed halo display, but doesn't appear to have a non-halo test case?
		So they were testing the display in 6 vs. 9 robot cases, but not halo vs. non-halo case
		So the experiment doesn't say anything about the halo case
			Except in comparision to other studies, which they don't compare it to...


Symbolic Planning and Control of Robot Motion
BY CALIN BELTA, ANTONIO BICCHI, MAGNUS EGERSTEDT, EMILIO FRAZZOLI, ERIC KLAVINS, AND GEORGE J. PAPPAS
	Shows that Klavins, among others was interested in the general problem
	And also that it was considered open as of March 2007
	Gets into LTL descriptions of environment to synthesize controllers
		Points out that "if a solution is found, it might still exist"
		Doesn't work well with incomplete knowledge
		Doesn't work well with dynamic worlds, as they imply incomplete knowledge
	Symbolic approaches make assumptions about holonomic drive
		car-style steering complicates things
	Some approaches work by minimizing/collecting possible control into small segments (motion primitives) and composing those
		Trades completeness/optimiaility for conciseness
		Want to capture an idea of how expressive a given motion primive set is
	Embedded graph grammars as a protocol for controlling robots
		Robots are nodes and have states, communications are edges and change states
		Transitions between states change robot behavior
		Robots update their state based on their surroundings/messages from other robots

Reactive mission and motion planning with deadlock resolution avoiding dynamic obstacles
Javier Alonso-Mora, Jonathan A. DeCastro, Vasumathi Raman, Daniela Rus, Hadas Kress-Gazit
	Small robot team, mission specification written in LTL
	Automaton plus motion planner to avoid moving obstacles
	Scalable with the number of moving obstacles
	Some assumptions about atomic actions and perfect sensing
		Which, sadly, don't really hold
	This system works as long as the obstacles are not intentionally adversarial
		By which they mean "won't block the robot forever"
	Doesn't attempt to model agents at build time
		Modifies plans at runtime instead (to avoid state explosion related to agent count)
	Still for fixed maps, though
	Assumes moving obstacles: 
		Maintain constant velocity during planning (to project motion)
		or try to avoid collisions using the same algorithm as the robots
		are not out to get the robots
	Certifies solution about things like doors
		"This task will complete if the door is opened eventually"
	Has an exponential blow-up in number of robots in team
		Single robot has 16 revisions
		Two robots have 1306 revisions
		Optimization can bring this down some, but still exponential

Decentralized Control of Robotic Swarms from High-Level Temporal Logic Specifications
Salar Moarref and Hadas Kress-Gazit
	High level temporal logic to controllers for safe nav of area
	Imperfect synchronization
	Again with the known map
	This paper assumes static and known environment, but the approach used doesn't rule out reaction to dynamic environment

An Integrated System for Perception-Driven Autonomy with Modular Robots
Jonathan Daudelin, Gangyuan Jing, Tarik Tosun, Mark Yim, Hadas Kress-Gazit, and Mark Campbell
	Modular robot that reconfigures in response to previously unknown environment
		But known task types, classifies task as discovered and shapeshifts to match
	Does permit exploring and figuring things out about the environment
	Sensitive to failure of modules

From High-level Task Specification to Robot Operating System (ROS) Implementation
Kai Weng Wong and Hadas Kress-Gazit
	Automatically suggests possible fixes for mapping from controller to ROS
	"While many of these approaches have been demonstrated on physical robots, the low-level integration of the provably-correct, typically symbolic, controller with the hardware is usually a manual and robot-specific ad-hoc process"
		MURI integration 
	Assumes single rosmaster, and no node launches another node as part of execution
		Pretty reasonable
	Talks about a boolean person detector
		This stuff frequently gets really noisy, people can be hard to detect
		Although hitting a person you fail to detect is provably correct, it's not great
	Permits easy integration of provably correct controllers to ROS
		Doesn't deal with the problems with provably correct controllers
			Perfect information
			Perfect sensors/actuators


Robot Creation from Functional Specifications 
Ankur M. Mehta, Joseph DelPreto, Kai Weng Wong, Scott Hamill, Hadas Kress-Gazit, and Daniela Rus
	3D prints the entire robot from the specification, as well as synthesizing the controller for it
	Still has binary sensors in the form of prepositions such as "seeObject_d" where d is an object
		This blows up because the number of possible states is 2^cardnality(objects)
	Maps propositions to components, so the actuations the robot can take and the senses it needs get added to the robot
	This is actually a pretty cool argument for heterogeneity, in that the software can design the robot for you and add it to the swarm

An End-to-End System for Accomplishing Tasks with Modular Robots
Gangyuan Jing, Tarik Tosun, Mark Yim, Hadas Kress-Gazit
	V similar to "An Integrated System for Perception-Driven Autonomy with Modular Robots"
	LTL controller isn't specified in terms of forms, but in terms of desired behaviors
	Properties of robot action and of environment dictate selected forms

Kilobot: A Low Cost Scalable Robot System for Collective Behaviors
Michael Rubenstein, Christian Ahler, and Radhika Nagpal
	Original Kilobot hardware announcement
	$14 worth of parts and 5 minutes to assemble (assuming you're not assembling the PCB)
	Indicates that it's still hard to model robots interactions with each other and the environment, so the stuff from the Brooks paper still holds
	Gives a price point for Jasmine of $130
	Kilobots don't shut off
		time to program, etc is constant 
		Because every robot gets the same program
	Heh. Kilobot parts cost is for 1000 units. 
		My price is close to theirs at that level
		And my robots don't need a whiteboard
	
Can deep-sleep a esp-8266 for 20uA, but no wifi
Has no wifi-enabled sleep mode, radios are just power-hungry

Automatic Synthesis of Controllers for Distributed Assembly and Formation Forming
Eric Klavins
	Controlled self-assembly of intelligent parts
	Controllers syntehsized from some sort of description of the higher-level form
	Forms forms in space, but has no notion of position within that space
		So can't really go to a goal location
	Focused on tree-graph structures
	So, very close to being scooped maybe, but different enough 
		He does call the controller synthesizer a compiler, though

Translating Temporal Logic to Controller Specifications
Georgios E. Fainekos, Savvas G. Loizou and George J. Pappas
	LTL -> Hybrid automaton -> control spec
	Control specification is probably for movement, continuious moves despite discrete states
	Event-based semantics for LTL can't distingish events that must hold at an instant from those that must hold over a time period
	Combines continuious flows (vector field) with discrete control transitions
	I think this is making some assumptions of a pure holonomic robot on the ideal plane

Neglect Benevolence in Human Control of Swarms in the Presence of Latency
Phillip Walker, Steven Nunnally, and Mike Lewis, Andreas Kolling, Nilanjan Chakraborty, and Katia Sycara 
	Claims to introduce neglect benevolence, first paper on HSI under latency
		Published...?
	Leader-follower control mentioned
	Prev user studies had no delay, or had continuious input
		which is a problem if the user is doing anything else
	Swarm takes time to stabilize
		Cites a lot of HSI papers
		Neglect benevolence is leaving the swarm alone to stabilize
	3 commands: Stop swarm, send heading to swarm, apply boids-style constraints
	Latency adversly impacts finding targets
	Adding a predictive display mitigates it
	Paper never really shows their UI

Virtual Synergy: A Human-Robot Interface for Urban Search and Rescue
Sheila Tejada, Andrew Cristina, Priscilla Goodwyne, Eric Normand, Ryan O’Hara, and Shahrukh Tarapore
	Robots build 3d VR map (Aibos + 2 blimps)
	Virtual world acts as "memory" of the system, stores the things it has seen
	System is based on Tekkotsu
	Humans can interact with robots in VR
	Student paper, probably undergrads
	Not a lot of detail on UI evaluation

Emergent Structures Assembled by Large Swarms of Simple Robots 
David Andréen, Petra Jenning, Nils Napp, Kirstin Petersen
	Robot behavior based on physical form
	Bristlebots with laser-cut foam hats
		Controller synthesis for this would be an interesting feat...
	Not a lot of data, but description of the overall process
		Has human-level interactive design
			Really sounds like a job for genetic design, though
	200 robots, pretty cheap swarm


What about the possibility of no interface at all?
	Design the robots from the ground up so that their behavior under physics is as desired by the user
	Sci-fi, but kind of ideal
	Maybe in a stochastic way, spread like dust, etc. 
	Assumes the limit case that robots are so cheap and so fast to build that it's easier to make piles of them than it is to reprogram the ones you already have
	End case of physicomimetics as well: the robots actually _are_ particles and interact through attractive/repelling forces

A Flexible Delegation-Type Interface Enhances System Performance in Human Supervision of Multiple Robots: Empirical Studies With RoboFlag
Raja Parasuraman, Scott Galster, Peter Squire, Hiroshi Furukawa, and Christopher Miller
	Addresses whether encreasing autonomy can help
	Playbook control, waypoint control, or both
	Delegation decreases mission time and increases successes
	Only 8 robots
	Cost of developing automation tradeoff for gains in efficency
	Simulated red vs. blue teams playing capture the flag
	Second experiment, users don't use automated plays as often as they could have
		And some plays were prefered over others
		And manual control reduced mission time (automation wasn't optimal)
		Having manual and automation is best control, but higher workload
	Seems a lot like the precursor to Perdix, and they mention control of military drones at the end of the paper "Other ongoing work [49], [50] on
the implementation and application of such interfaces provides
further support for their use in complex human–robot systems.
This work has been conducted in a high-fidelity simulation em-
ulating multiple small UAVs (fixed and rotary wing) operating
in an urban environment to perform useful support services for
small units of infantry soldiers."

How Search and its Subtasks Scale in N Robots
Huadong Wang, Michael Lewis, Prasanna Velagapudi, Paul Scerri, Katia Sycara
	Full task - users directed robots and looked for victims
	Explore - users just directed robots
	Perceptual search - Users just looked for victims
	Workload increases monotonically with robot count
	Task performance on full task increased up to four robots, then decreased
	Increasing autonomy decreases overload
		Depends on task characteristics as well
		Fan-out is higher with simpler tasks
	
