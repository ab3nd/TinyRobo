\documentclass[]{article}


\usepackage{xargs} 
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommandx{\improvement}[2][1=]{\todo[linecolor=purple,backgroundcolor=purple!25,bordercolor=purple,#1]{#2}}
\newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{auto-pst-pdf}
\usepackage{graphviz}
\usepackage{microtype}

%opening
\title{TinyRobo: Development of an Inexpensive Software and Hardware System for Swarm Robotics}
\author{Abraham Shultz}

\begin{document}

\maketitle

\begin{abstract}
Because simulations are necessarily incomplete, it is desirable to test algorithms for swarm robots on physical robots, rather than in simulation. 
However, the cost of robot hardware can be high, and the larger a swarm, the more it will cost. 
This paper presents an inexpensive, open source hardware platform for converting toys into swarm robots, and a software infrastructure for controlling the swarm nodes. 
The resulting system was designed as a tabletop swarm but has the ability to be expanded both in the area used by the swarm, and the capabilities of the individual swarm members. 
However, the use of toys as a platform for swarm robotics poses some implementation challenges in balancing reliability and low cost. 

\end{abstract}

\section{Motivation}

Simulation of robots is clearly the lowest cost option for performing tests with large collections of robots. 
Once the simulation environment is created, adding additional robots does not cost more. 
However, simulation brings with it a number of problems. 
Because simulations often can have bugs in them that are exploitable by agents operating in the simulation, it is sometimes possible to develop solutions that cannot be reproduced in reality. 
Additionally, simulations are often more perfect than the real world. 
In simulation, factors such as wheel slip, which adds error to robot odometry, and other forms of noise and sensor error can be left out of the simulation. 
Even if these factors are included, the simulated version may lack complexities that are present in the real world, such as the effects of tires bending under load as the robot turns. 
These sorts of departures from reality are tempting, because they save processor time and development effort.
However, they complicate bringing the resulting software designs into the real world.  
With real hardware, these effects are included at no cost. 

Unfortunately, crossing the gap from simulation to testing on real hardware requires the purchase of hardware, which can be quite expensive. 
This paper describes the design of a hardware platform and the associated software framework that were intended to produce a tabletop research robot swarm for about \$30 per robot. 


\section{Related Work}

Swarm robots are generally small. 
The reason to keep swarm robots small is related to both the cost of making them and the cost of using them. 
Larger robots consume more materials per unit, and so cost more money.
Also, each robot requires some amount of space in which to move.
To keep the ratio of free space to robots constant, the area of space used by the robots grows as the robots do. 
If the ratio is not kept constant, the robots will crowd each other, and so large robots will require either a very large space, a small swarm, or become overly crowded.
Finally, larger robots are just more cumbersome to deal with. 
They require larger storage areas, possibly teamwork to lift or repair, and so forth, all multiplied by the number of robots in the swarm. 

The robots used in most swarm research are of a sufficiently small size that many of them can fit in a room. In addition to budgetary constraints, interaction with an environment built for humans places an upper bound on the scale of the individual swarm members. 
Normal interior doors are around 80 cm wide, and so a robot larger than 80 cm across will not be able to move between rooms in a normal building.
The lower bound on swarm robots is generally dictated by fabrication technology, with smaller robots becoming increasingly difficult to assemble. 
As a result of these bounds, swarm robots are mostly between 1cm$^3$ and 0.3m$^3$. 
This scale range can be divided into robots that can operate in swarms on a table, and those that can operate in swarms within a room, albeit possibly a large room. 
This paper is concerned with tabletop swarm robot platforms.
For discussion of swarms of larger robots, see \cite{olson2013cacm, dorigo2013swarmanoid, bonani2010marxbot, tammet2008rfid, guo2007bio}. 

At the low end, in terms of size, the I-SWARM Project was intended to create a 2x2x1mm robot that moved by stick-slip locomotion actuated by piezo levers \cite{seyfried2005swarm}. 
Over the course of the project from 2004-2008, the hardware was developed and used in research, but was not converted to a commercial product.
Other techniques have been developed to use magnetic fields to apply force to small magnetic objects, resulting in controlled motion of the objects \cite{floyd2008untethered, pelrine2012diamagnetically}.
These systems are not amenable to decentralized control, because the moving components are not themselves robots. 
The moving parts are more accurately viewed as manipulators, with the instrumented environment and the manipulators themselves comprising a single robot. 

Alice, by Caprari et al. \cite{caprari1998autonomous} combined a PIC16F84 processor, motors, RF and IR networking, and enough battery power for 10 hours of autonomy into a robot measuring under 2.5cm$^3$. 
The processor used in Alice is relatively underpowered compared to modern processors at the same price point and power consumption. 
Alice robots are no longer available for purchase. 
The AmIR robot was similar to Alice in size and capability, but with a more modern processor \cite{arvin2009development}.
There is no evidence that AmIR was ever widely available.

The Jasmine swarm robots were possibly the closest thing to a commercially-available successor to Alice \cite{kernbach2011swarmrobot}.
Jasmine measured 26x26x20mm, and included an ATMega processor, IR close range communication and obstacle detection, two motor skid steering, and li-po batteries.
Unfortunately, Jasmine units cost about 100 Euro (\$111 USD) each when they were available, and they are no longer available for purchase. 

Colias and the related Colias-$\Phi$, are dual-microprocessor systems similar to Jasmine in functionality, but with additional features for pheremone robotics applications \cite{arvin2014colias, arvin2015colias}. 
Colias is built out of two PCBs, with the upper PCB and processor handling IR collision avoidance and communication, and the lower processor controlling the motors, power management, and a few other sensors.
Parts for Colias robots cost \pounds25, or \$35US, but assembled are not commercially available. 
The Colias-$\Phi$ model has an even more impressive price, at \pounds16, or \$22 USD.
Part of this drop in price may be due to the omission of the IR inter-robot communication system which Colias robots have.

The GRITSBots platform is a differential-drive platform using stepper motors \cite{pickem2015gritsbot}.
GRITSBots use the same processor as Colias, in a similar configuration, with one processor operating sensors and the other controlling the robot's motors. 
The sensor board incorporate a 3D accelerometer and gyro as well as a 6-direction IR distance sensing ring. 
GRITSBots measure 31mm x 33mm, and cost approximately \$50 for parts per unit. 

MROBerTO is a swarm robot with a 16mm$^2$ footprint. It has modular expandability via a header for daughterboards, and includes a single-point laser rangefinder, gyro, accelerometer, compass, and a VGA resolution camera \cite{Kim2016mROBerTOAM}. 
The mROBerTO processor is a 32-bit ARM processor with Bluetooth and ANT+ wireless. 
All of this hardware is only \$60 per unit in quantities of 25 or more units. 
In order to permit an overhead camera to localize the mROBerTO robots, a single RGB LED on top of the camera can be lit in a unique color to localize the robot, and a green LED on the front of the robot indicates its heading. 
The use of color information is likely much faster to process than fiducual tags, but does have the disadvantage that it is only useful in 2D unless a stereo camera is used. 

Even when they are commercially available, most existing swarm robots are too expensive to build a large swarm.
The Epuck from EFPL is approximately 800 Swiss francs (\$810 USD) per unit, so the cost of maintaining a large swarm can become daunting quickly. 
The high price of the Epuck is a result of its extensive suite of sensors, including a camera and 360$^{\circ}$ IR range sensor and communication system. 

The r-one research robot is cheaper than the Epuck, at approximately \$220 USD per unit \cite{mclurkin2013low}. 
The developers of the r-one position it as a more-featureful and less expensive alternative to the Epuck (\$810, cannot sense neighbors without additional hardware), Parallax's Scribbler (\$198, minimal sensors), the iRobot Create (\$220, requires additional hardware to be programmable), the K-team Khepera III (\$2000), and the Pololu 3pi (\$99, minimal sensors). The main advantage in sensing that the r-one has over these other platforms is neighbor sensors and ground truth position sensing, both of which are implemented on the r-one using infrared.
The design of the r-one is open source, but it does not appear to be commercially available as of this writing.   

The Harvard Kilobots are a more recent entry to inexpensive swarms, and have been produced in large quantities \cite{rubenstein2014kilobot}. 
Kilobots contain about \$15 worth of parts, but a 10-pack sells for 1100 Swiss francs, or about \$112 (US) per robot. 
The Kilobots are intended for research in a highly homogeneous environment, with most or all of the robots executing the same program. 
They are designed to be programmed in parallel using an IR interface. 
For small groups, individual Kilobots can be programmed differently, but any attempt to give each of a very large collection of robots an unique program will take a long time. 

One way to reduce the cost of swarm robots is to use commercial, off-the-shelf (COTS) hardware in the construction of the robot. 
Reusing existing hardware leverages the economies of scale that reduce the price of commercial hardware, as well as eliminating the need to design or build the COTS parts. 
Use of COTS parts in research robotics has led to at least two platforms referred to as COTSBots \cite{bergbreiter2003cotsbots, soule2011cotsbots}.
The first COTSBots used Mica mote hardware for the communications link and sensing, plus a motor control add-on board \cite{bergbreiter2003cotsbots}. 
The mobility platform was a modified toy, in particular, a specific brand of high-quality micro RC car.
At the time of this writing, the car used in COTSBots is moderately expensive for a toy car, although quite cheap for a research robot, costing a little over \$100 (US) per unit. 
The motor driver board is not commercially available, but can be custom-built by board fabrication companies. 
As of this writing, the mote board is also no longer available, and the company producing it has gone out of business. 

The other COTSBots platform is composed of a laptop for processing interfaced via an Arduino or similar microcontroller board to a modified RC car, tank, or similar toy as a mobility platform \cite{soule2011cotsbots}.
These COTSBots are no longer a tabletop platform, but they have a more flexible design than the previous COTSBots, as they do not call for a specific toy to be used.
Due to the diversity of possible combinations of hardware that can be assembled into this configuration, it is still a very viable platform. 
However, the minimum size of this style of COTSBot is the size (and cost) of a laptop.
The idea of having a standard computer and a variable base, which can be customized to the task at hand, is applicable even if a full laptop is not used. 

\section{Hardware}

The controller module described in this work was designed to be used as a replacement for the control electronics of children's toys, similar to the Spider-Bots developed by Laird, Price, and Raptis, or Bergbreiter's COTSBots \cite{lairdspider, bergbreiter2003cotsbots}.
However, unlike the Spider-Bots and COTSBots, this platform does not specify a particular toy chassis to use for mobility. 
Most children's toys use either one motor with a mechanical linkage to cause the toy to turn when the motor is reversed, or two motors.
Two-motor toys frequently use either differential steering or have one motor provide drive power and the other provides steering. 
All of these toys can be controlled by the hardware described in this work. 
Duplication of software and other digital artifacts is trivial, so constructing a duplicate of the hardware is the primary difficulty. 
The use of toys for the mechanical components of the robots is intended to reduce the difficulty of constructing the hardware. 
The control module is called TinyRobo, both because of the small size of the toys it controls, and the relative simplicity of the controller.

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{../robot_makers_2/tiny_tank}
\caption{A tank-drive toy with a 3.7V lithium polymer battery and a TinyRobo control board mounted to it.}
\end{figure}


TinyRobos are intended to be heterogeneous, partly because of the advantages of heterogeneity in a swarm, and partly because toy supplies are unreliable.
A particular line of toys might be discontinued or a modified version released. 
The software framework in development to support TinyRobos is based on ROS, and so allows modular replacement of the control algorithms used to convert desired motion of the robot, expressed as ROS Twist messages, into drive signals for the motors. 
As a result, changing to a base with different drive kinematics requires minimal changes to the control software. 

 \begin{table}
	\begin{tabular}{l l l l l l l }
	Name & Value & Cost & Cost & Count & Sub- & Subtotal\\
	& & (1) & (100) & & total& (100) \\
	\hline
	Wifi& ESP-8266-03& 4.32 & 2.25 & 1 & 4.32 & 2.25\\
	PCB& & 3.3 & 0.79 & 1 & 3.3 & 0.79\\
	Battery& 3.7V& 3.41 & 1.5 & 1 & 3.41 & 1.5\\
	Motor driver& DRV8830& 2.27 & 1.64 & 2 & 4.54 & 3.28\\
	V Regulator& MIC5265& 1.4 & 1.06 & 1 & 1.4 & 1.06\\
	Switch& 410-2016& 0.91 & 0.72 & 1 & 0.91 & 0.72\\
	Charge IC& MCP73831& 0.59 & 0.44 & 1 & 0.59 & 0.44\\
	Charge LED& Green& 0.54 & 0.3 & 1 & 0.54 & 0.3\\
	Header& 6-pin& 0.52 & 0.37 & 1 & 0.52 & 0.37\\
	Diode& GF1A & 0.51& 0.23 & 1 & 0.51 & 0.23\\
	C1, C2& 4.7uF& 0.5 & 0.2 & 2 & 1 & 0.4\\
	R3, R4& 0.22 ohm& 0.46 & 0.13 & 2 & 0.92 & 0.26\\
	C4& 10uF& 0.19 & 0.06 & 1 & 0.19 & 0.06\\
	Thermal Fuse& 0ZB0050FF2G1& 0.13 & 0.1 & 1 & 0.13 & 0.1\\
	C3& 0.1uF& 0.1 & 0.02 & 1 & 0.1 & 0.02\\
	R1& 470 ohm& 0.1 & 0.02 & 1 & 0.1 & 0.02\\
	R2& 2k & 0.1& 0.02 & 1 & 0.1 & 0.02\\
	R5, R8-12& 10k& 0.1 & 0.01 & 6 & 0.6 & 0.06\\
	R6, R7& 1k& 0.1 & 0.01 & 2 & 0.2 & 0.02\\
	\hline
	Total Cost &  &  &  &  & 23.38 & 11.9\\
 	\end{tabular}
 \end{table}
 
The processor of the TinyRobo controller is an ESP-8266 WiFi module.
The ESP-8266 contains both a wireless interface and a micro controller that can be programmed from a variety of programming environments and languages, including Lua and the Arduino variant of C/C++. The ESP-8266 module is based on the ESP-8266 IC, made by Expressif Systems. The IC itself has an 80Mhz Tensilica Xtensa L106 processor with 64kB of instruction memory and 96kB of data RAM. The modules come equipped with 512kB to 16MB of flash memory for program storage, and some combination of the 16 GPIO lines of the IC available for use. 
The ESP-8266 is available in several form factors, each designated by a different suffix. 
The version selected is the ESP-8266-03, which offers more GPIO pins than most other versions, and includes an internal antenna.

In addition to 802.11 b/g/n WiFi, the ESP-8266 supports a variety of serial protocols, including a UART, I$^2$C, and SPI. 
The I$^2$C interface is used on the TinyRobo board to connect to two DRV8830 motor driver ICs by Texas Instruments. 
The DRV8830 provides 1A of drive current.
Experimental tests with 8 different toys indicate that small toys draw well under 1A while moving freely, and peak around 2A when the motors are stalled. 
The tested toys include 3 insect-styled walkers, 3 wheeled vehicles (2 differential drive, 1 Ackerman steering), 1 toy helicopter, and 1 toy quadcopter.
The DRV8830 provides overcurrent limiting, so a stall condition or short circuit of the motor leads will disable the motor drive, but not damage the DRV8830. 

The TinyRobo control module also provides connections for a 3.7V lithium-ion battery pack, as well as charge control circuitry for the battery. 
The charge controller allows the TinyRobo to be charged from the same USB connection that is used to change the programming of the ESP-8266. 
Reset and entry into programming mode is controlled by a separate USB-to-serial adapter board, the Sparkfun BOB-11736.
Moving this functionality to the adapter board reduces the size and cost of the TinyRobo control module. 

The mobility platforms used for the existing TinyRobo swarm cost 12-20 dollars in single quantities, putting the total cost for a single robot at \$35-45.
Where bulk ordering is available, the cost of 100 mobility platforms is \$8 per unit, reducing the per-unit cost of a 100-member TinyRobo swarm to \$20. 
This is roughly in line with the parts cost of the Kilobot, which is \$15 \cite{rubenstein2014kilobot}.

However, this should not be taken to mean that the TinyRobo platform is a competitor with the Kilobots. 
Kilobots were designed to have scalable interactions, which is to say that programming, charging, and even turning on the Kilobots does not take more time as the number of robots increases. 
To have programming take constant time, the Kilobots are programmed in parallel using an infrared broadcast device that illuminates the entire swarm at once. 
To charge together, the Kilobots have one charging contact on their legs, and the other on a leaf spring on their tops. 
By sandwiching the robots between two conductive plates, the entire swarm can be charged at once.
Finally, in order to all be turned on quickly, the Kilobots never turn off.  
Instead, they enter a low power sleep mode, and wake occasionally to check for an infrared signal to become fully active. 
This last attribute makes it very difficult to have a robot that has both WiFi and a very low power sleep mode. 
The WiFi module used in the TinyRobo platform consumes 15mA in its highest-power sleep mode, and 20$\mu$A in its lowest power mode. 
Unfortunately, only the highest power sleep mode can remain connected to an access point and receive a wake-up command, and so it will deplete the 750mAH battery used in the TinyRobos in just over two days. 
In contrast, a Kilobot can sleep for 3 months. 

\subsection{Toy Compatibility}

Children's toys normally use inexpensive brushed DC motors in their construction. 
These motors have not been the subject of extensive study, as they are commodity parts. 
However, it is useful to quantify their behavior to some extent, to determine which kinds of toys can be used with the TinyRobo controller. 

Two common types of motors found in children's toys are the RE and FA series of motors produced by Mabuchi Motor, or imitations of these motors produced by other companies. 
These motors use simple metal brushes and are constructed to be inexpensive, rather than precise. 
The intended voltage range of the motors varies with different winding types. 
Table \ref{tab:properBrandedMotors} shows the voltage ranges and current draws for some Mabuchi motors, according to datasheets available from Mabuchi Motor.

\begin{table}
	\begin{tabular}{l l l l l}
	Model & Voltage & No Load Current & Max Efficiency & Stall Current\\
	\hline
	RE-140RA-2270 & 1.5-3 & 0.21 & 0.66 & 2.1 \\
	RE-140RA-18100 & 1.5-3 & 0.13 & 0.37 & 1.07 \\
	RE-140RA-12240 & 3-6 & 0.05 & 0.14 & 0.39 \\
	FA-130RA-2270 & 1.5-3 & 0.2 & 0.66 & 2.2\\
	FA-130RA-18100 & 1.5-3 & 0.15 & 0.56 & 2.1\\
	FA-130RA-14150 & 1.5-4.5 & 0.11 & 0.31 & 0.9\\
	\end{tabular}
	\caption{Current draw for Mabuchi-branded motors.}
	\label{tab:properBrandedMotors}
\end{table}

The Mabuchi motors in table \ref{tab:properBrandedMotors} are somewhat large brushed motors, generally measuring around 2-3 cm$^3$. 
For smaller toys, coreless motors are more common. 
The values in table \ref{tab:coreless} were measured from six of the toys used in constructing the TinyRobo swarm.
The measurements from the toy helicopter and toy quadcopter are included for comparison.
While the TinyRobo board can supply sufficient current to control all of these toys, it has not been tested in flying platforms.

\begin{table}
	\begin{tabular}{l l l}
	Motor number & No Load Current & Stall Current (measured)\\
	\hline 
	Hexbug brand mini spider & 0.03A & 0.13A \\
	Hexbug brand 6-legged insect & 0.06A & 0.25A \\
	Miniature toy RC car & 0.21A & 0.8A \\
	Miniature toy RC insect & 0.19A & 1.13A \\
	Miniature toy RC vehicle & 0.37A & 0.8A \\
	Miniature toy RC vehicle & 0.06A & 0.74A \\
	Toy helicopter & 0.07A & 1.12A \\
	Toy quadcopter & 0.74A & 1.99A \\
	\end{tabular}
	\caption{No load and stall current for coreless DC micromotors. Measurements were performed at 3V supply voltage. The Hexbug mini spider includes a slip clutch, so attempting to stall the motors by holding the toy still does not prevent the motor from turning}
	\label{tab:coreless}
\end{table}


\subsection{Potential for Expansion}

The current design for TinyRobo does not include sensors as a cost-saving decision. 
However, the communication between the ESP-8266 and the motor drivers uses the industry standard I2C bus serial interface. 
Due to the non-proprietary nature of this interface standard, it has been widely adopted, and many sensors are available to connect to an I2C bus. 
For example, Vishay Semiconductor makes the VCNL3020, which is an infrared proximity sensor with a 20mm range. 
If greater range is required, The ST Microelectronics VL53L0X Time-of-flight (ToF) laser ranger and gesture sensor provides a 2M range and 1D gesture sensing in a 4.4mm x 2.4mm package. 
As of this writing, the VCNL3020 is \$3.44 and the VL53L0X costs \$6.28 in single quantities.
These prices are reduced significantly when buying components in bulk, but because they increase the cost, size, and power draw of the hardware, they have not yet been integrated with the TinyRobo platform. 
Numerous multichannel ADC ICs with I2C interfaces are also available, which permits the addition of analog sensors to the TinyRobo platform. 

\section {Firmware}

The current version of the TinyRobo firmware is developed in the open-source Arduino development environment.
Arduino programs are written in a dialect of C++. 

Every robot runs the same firmware. 
The firmware listens for connections on port 4321 for TCP/IP packets containing one of two types of messages. 
Messages starting with a 0x51 byte (ASCII `Q') cause the firmware to respond with a message containing the ASCII string ``TinyRobo". 
This function is to allow automatic detection of TinyRobos on a network by querying all connected systems to determine if they respond in this way. 

Messages starting with a 0x4D byte (ASCII `M') followed by four bytes are motor speed commands.
The firmware interprets the first two bytes as the speed and direction for the first motor, and the second two bytes as speed and direction for the second motor.
The control bytes are converted to a single byte command for the DRV8830 driver and transmitted over the I2C bus to set the motor speed.
 
The DRV8830 driver is a voltage-controlled motor driver. 
It accepts a single-byte command for each motor. 
Bits 7-2 of the byte define the output voltage to be applied to a motor, and the driver attempts to maintain that output voltage.
The valid range of motor voltage commands for the DRV8830 driver is 0x06 to 0x3F, which corresponds to a range of 0.48V to 5.06V in 0.08V increments. 
Because the TinyRobo battery is nominally 3.7V, the motor command 0x30 is the highest output available. 
Bits 1 and 0 of the command byte control the polarity of the output voltage, and so the direction of the motor.

Once the motor speed is set, the firmware reads the fault bytes from the DRV8830, and sends the motor command and the fault bytes for each motor back to the client over WiFi. 
The client uses the fault bytes to detect overcurrent conditions in the motor drivers and reduce output power. 

The decision to have all of the robots have the same firmware and control the speed of the motors from ROS was made because different toys have different control schemes. 
Toy tanks use differential drive, toy cars have Ackerman steering, and so forth. 
By moving the control to the main computer, the firmware can be kept simple while still allowing researchers to adapt the system to the available toys. 

\section{Software}

The TinyRobo swarm is controlled by ROS nodes running on a single computer.
Since all of the robots are controlled by a single computer, it may appear that this is a highly centralized system. 
However, the central computer provides a framework for implementing a decentralized control scheme on the individual robots. 

%Graphic of the software environment as a whole
\begin{figure}
	\centering
	\digraph[scale=0.6]{Framework}{
	
	graph[nodesep=0.5];

	subgraph clusterRobot1 {
		motor[shape=box; label="Motor Driver"];
		robotCode[label=<Robot <br/> Firmware>];
		robotCode -> motor;
		label="Robot 1";
		shape=box;
	}
	
	subgraph clusterRobot2 {
		motor2[shape=box; label="Motor Driver"];
		robotCode2[label=<Robot <br/> Firmware>];
		robotCode2 -> motor2;
		label="Robot 2";
		shape=box;
	}
	
	subgraph clusterRobot3 {
		motor3[shape=box; label="Motor Driver"];
		robotCode3[label=<Robot <br/> Firmware>];
		robotCode3 -> motor3;
		label="Robot 3";
		shape=box;
	}
	
	subgraph clusterRobotN {
		motorN[shape=box; label="Motor Driver"];
		robotCodeN[label=<Robot <br/> Firmware>];
		robotCodeN -> motorN;
		label="Robot N";
		shape=box;
	}
	
	subgraph clusterComp {
		concentrate=true;
		label="Control Computer";
		{rank=source;
			aprilTag [label="Tag Detector"];
		}
		
		{rank=same;
			vrLaser [label="Laser Service"];
			vrNet [label="Network Service"];
			vrDist [label="Distance Service"];			
		}
		
		{rank=same rp1 rp2 rp3 rpN}
		
		rp1 [label=<Robot <br/> Process 1>];
		rp2 [label=<Robot <br/> Process 2>];
		rp3 [label=<Robot <br/> Process 3>];
		rpN [label=<Robot <br/> Process N>];
		lc1 [label=<Robot 1<br/> Laser>];
		lc2 [label=<Robot 2<br/> Laser>];
		//vrNet -> {rp1, rp2, rp3, rpN} [dir="both"];
		//vrSense -> {rp1, rp2, rp3, rpN};
		
		//Distance informs whether robots can be reached on the net
		vrNet -> vrDist;
		vrDist -> vrNet;
		
		rp1 -> robotCode [label="WiFi", dir="both"];
		rp2 -> robotCode2 [label="WiFi", dir="both"];
		rp3 -> robotCode3 [label="WiFi", dir="both"];
		rpN -> robotCodeN [label="WiFi", dir="both"];
	
		//Robots 1 and 2 have laser clients getting scans
		lc1 -> vrLaser;// [label=<std\string_msgs/Integer>];
		vrLaser -> lc1;// [label=<sensor\string_msgs/LaserScan>];
		lc1 -> rp1;
		lc2 -> vrLaser;// [label=<std\string_msgs/Integer>];
  		vrLaser -> lc2;// [label=<sensor\string_msgs/LaserScan>];
		lc2 -> rp2;
		
		//Robots 3 and N are talking over the network
		rp3 -> vrNet;
		vrNet -> rpN;
					
		//AprilTags inform distance and laser
		aprilTag -> vrDist;// [label=<apriltags\string_ros/TagDetections>];	
		aprilTag -> vrLaser;// [label=<apriltags\string_ros/TagDetections>];
		
				
	}
	
	camera[label=<Overhead<br/>Camera>;shape=box;]
	camera->{vrLaser, aprilTag};	
		 
	}
	\caption{Overview of the framework. Rectangular nodes are hardware, oval nodes are software. Robots 1 and 2 have virtual lasers, robots 3 and N are communicating over the network.}
\end{figure}

Rather than all of the robots being controlled by a single program on the central computer, each robot has ROS nodes that are responsible for controlling that robot. 
Each of these nodes only has access to the information that would be available to that robot, and so acts as if it is a local control program running on the robot.
However, since the ROS nodes are running on a relatively modern desktop PC, they have substantial processing power available to them. 
As a result, the individual robots are small, lightweight, and consume relatively little electrical power, but still have significant computing power. 
As more powerful and lower power consumption processors become available, more of the processing can be moved from the central computer and onto the actual robots, enabling a smooth transition from a simulated decentralized system to a real decentralized system. 

Individual TinyRobos have minimal sensing capacity. 
The central computer has a top-down camera over the ``arena'' the TinyRobos are active in. 
Each TinyRobo has an AprilTag \cite{olson2011tags} on top of it, so that the central computer can localize them within the arena. 
The central computer uses the location information to create ``virtual sensors'' for each robot. 
Since the central computer knows the location of each robot, the relevant information can be sent to each robot's control process as if it were coming from a sensor on the robot. 

The AprilTag tracking of the robots provides localization of the robots within a common coordinate frame. 
It should be stressed that while the central computer can localize the robots, both relative to each other and by absolute position within the arena, this information may be withheld from the individual robots, or given to them if required. 
The code virtually operating on the robot may be neither aware of its own position in the world, nor the location of other robots, if the experiment calls for such a lack of information. 

By using the location of each robot, a virtual range and bearing sensor is available for each robot.
The virtual sensor simply reports to each robot the range and bearing of the robots around it, if they are within the configured range of the virtual sensor.
Range and bearing sensors are available in hardware on Epucks, Colias, and Marxbots, but since each robot must be equipped with it, the cost scales linearly with the number of robots to equip.  

The virtual sensors can also be configured to emulate error conditions such as noisy sensors, failed sensors, degraded localization, and so forth.
Virtual parameter tweaking will allow fine-grained testing of the behavior of algorithms under imperfect conditions, and the response of human users to unreliability in the swarm. 

The AprilTag localizations and the image of the arena are used to provide virtual laser rangers for each robot. 
The virtual laser ranger consists of two ROS nodes, a service and clients for the service. 
The service subscribes to the AprilTag detections and the images from the arena overhead camera. 

Each sample of the laser scan is represented as a line segment, located based on the requested start, stop and inter-measurement angles for the virtual laser scanner. 
Each line segment is checked for intersection with the lines defining the contours of objects in the image. 
If multiple intersections are found for a line segment, the intersection closest to the robot is used, as the laser would stop after reflecting off an object.
The service then formats the distances to the intersection points as a ROS sensor\_msgs/LaserScan and returns it as the service response to the requesting client. 

The virtual laser clients take the place of the laser driver ROS nodes that would be used to control a real linear laser scanner. 
The laser client is initialized with some parameters, such as the sweep angle and angular resolution of the virtual laser, and polls the laser service regularly. 
As it receives laser scans from the service, it publishes them to a ROS topic in the same manner as a ROS node for a hardware laser. 
%
%The apriltags\_ros node publishes the detected locations of the tags in meters, but the computer vision detection of blue objects in the arena camera image operates in pixels. 
%In order to convert from pixels to real-world distances, the apriltags\_ros node was forked and a modified version was created that provides the locations of the tags in pixel as well as real-world coordinates. 
%The modified version is available at https://github.com/ab3nd/apriltags\_ros.

%\begin{figure}
%	\centering
%	\digraph[scale=0.6]{VirtualLaserSystem}{
%	
%	vls -> vsc [label=<std\string_msgs/Integer&nbsp;&nbsp;&nbsp;&nbsp;>];
%	vsc -> vls [label=<sensor\string_msgs/LaserScan>];
%	vsc -> sub1 [label=<sensor\string_msgs/LaserScan>];
%	cam -> vls [label=<sensor\string_msgs/Image>];
%	cam -> atag	[label=<sensor\string_msgs/Image>];
%	atag -> vls [label=<apriltags\string_ros/TagDetections>];	
%		 
%	vls [label="Virtual Laser Service"];
%	vsc [label="Virtual Laser Client"];
%	atag [label="AprilTag Detector"];
%	cam [label="Arena Camera"];
%	sub1 [label="Subscriber"];
%	}
%	\caption{Data flow in the virtual laser service}
%\end{figure}

If the robots are required to communicate directly with each other, the communication passes through a virtual network.
From the point of view of the robots, messages sent into the virtual network are delivered to other robots as if the messages were sent directly from one robot to another. 
However, all the communication is taking place between processes running on the central computer.
By changing how the messages are delivered by the central system, the virtual network can provide full connectivity, range-limited mesh networking, directional beacons, or other forms of networking. 
The reliability of the network can also be varied, by dropping some messages or otherwise changing them based on information about the robots. 
For example, the likelihood that a message arrives at the robot to which it was transmitted may depend on the distance between the sender and receiver. 
%
%\begin{figure}
%	\centering
%	\digraph[scale=0.6]{VirtualNetwork}{
%	
%	{rank=same atag dist}
%	{rank=same tx rx}
%
%	vns -> dist [label="Robot IDs"];
%	dist -> vns [label="Distance"];
%	cam -> atag	[label=<sensor\string_msgs/Image>];
%	atag -> dist [label=<apriltags\string_ros/TagDetections>];	
%	vns -> rx [label="Network Message"];
%	tx -> vns [label="Network Message"];	 
%	
%		
%	vns [label="Virtual Network Service"];
%	dist [label="Distance Service"];
%	atag [label="AprilTag Detector"];
%	cam [label="Arena Camera"];
%	tx [label="Transmitter"];
%	rx [label="Receiver"];
%	}
%	\caption{Data flow in the virtual network. The virtual network service can take the distance between the transmitting robot and the receiving robot into account when determining if the message is delivered.}
%\end{figure}
%
\section{Control of TinyRobos}

In order to characterize the behavior of the various toy hardware that the TinyRobo platform could be used on, seven TinyRobos were commanded by a program which instructed them to move forwards until the AprilTag tracking determined that they had moved a fixed distance, stop, and move again, in a loop. This program was run until the robot failed to move or ran into the walls of the robot arena.

Each robot was run 5 times, starting from the same location each time. The robot was power-cycled between runs. Each run was recorded using rosbag, and the data from the recordings were used to generate visualizations of the robot's commanded trajectory from the motion of the center of the robot's AprilTag.

The robots consisted of three toy tanks from the same manufacturer, a differential-drive Hexbug-brand robot, a differential-drive toy car with large wheels, a hexapod bug-like walker, and an Ackerman-drive toy car. 
The bug-like walker and the Ackerman-drive car both have different turning kinematics from the differential drive tanks, but this test only consists of forward drive.
It would have been preferable to have the test include turning, but control of the yaw rotation of a robot via feedback from the AprilTag system was found to be problematic. 
As the number of pixels that an AprilTag takes up on a camera image decreases, the accuracy of the subpixel estimation used to localize the corners of the tag decreases. 
Each estimation of the tag location from the ROS AprilTag detection node can then differ from previous estimations, and so even when the robot remains still, there is some noise in its detected position. 

The effect of the noise in subpixel position on the perceived rotation of the tags is larger than its effect on the perceived rotation of the tags, since rotation around the center of the tag does not change the position of its center at all. 
As a consequence, the tags could be detected to be in lateral motion by comparing the displacement of the center of the tag and checking that it was greater than the expected noise, but detection of rotational motion and velocity calculation was sometimes swamped by noise. 

The noise was also determined to be unevenly distributed over the robot arena. Because the arena is wide, a wide-angle lens \todo{check amazon receipts, figure out how wide that lens is} is used to ensure that the entire arena is visible. 
ROS provides tools for removing the distortion inherent in the use of a wide-angle lens, but at the cost of decreased effective resolution at the edges of the image. 
This decrease in resolution results in reduction of subpixel location accuracy, and so increased noise in localization of the tag. 
%This problem can be mitigated in a number of ways. 
%First, the resolution of the camera can be increased while keeping the tags the same size and the camera the same distance away. 
%This solution ends up requiring more computational power as the image size increases, in order to keep the tag detection framerate high enough to be useful for realtime control. 
%Second, the tag size could be increased, either by moving the tags closer to the camera and increasing their visual size, or by actually making the tags larger. 
%Moving the camera closer reduces the useful area of the robot arena, and making the tags larger increases the size and weight of the robots, potentially overbalancing some of the less nimble robots. 

%AprilTags have very solid position and orientation tracking, but are computationally intensive to detect and localize in typical webcam images. 
%More tags leads to longer computation time, increasing the latency of the robot control loop. 
%Parallelizing the implementation of the AprilTag library could improve it significantly, but is out of scope for this work. 
%
%One version of the GRITSBots used AprilTags and a standard web cam, resulting in position updates at approximately 10Hz. 
%This update rate is consistent with that observed by the author using the ROS implementation of AprilTags. 
%Decreasing the size of the image in which the tags are detected speeds it up, at the cost of requiring larger tags in order to have them legible in the lower-resolution image. 
%The update rate places an upper bound on the ability of the system to respond to the motion of the robots. 
%To decrease the latency of this sensing, the GRITSBots team considered moving to color blob tags, which can be detected by the onboard vision processor of a Pixy CMUCam5 at up to 50Hz \cite{PickemGrits2014}. 
%MROBerTO also used color tracking, with a single RGB LED on top of each robot to identify it, and a green LED on the front of each robot to indicate its orientation. 


Because the desired figure-8 motion could not be performed with the rotational localization noise present in the system, the robots were instead commanded to move forward 0.25m, stop, and repeat that sequence of actions until the program was stopped. 
The program was stopped if the robot was about to run into the wall of the arena, or had entered a state in which it could not move forward anymore. 
Acceleration during the movement phases was managed by increasing the commanded velocity of the robot until the AprilTag tracking detected that the robot had begun moving. 
Once the robot began moving, it was not commanded to change velocity until it had moved at least 0.25m.
In the following descriptions of the motions of the robots, the directions left and right are relative to the direction of travel of the robot. 

The Ackerman-steering toy car (page \pageref{img_traj}, image a) displayed very consistent mobility. In four out of its five runs, it crossed the arena without incident. 
In one run, it started and went a small distance, but then did not start again. 
However, the Ackerman-steering toy car has a gearbox that permits backdriving, so when commanded to stop, it coasts for a few centimeters. 
The toy tanks use a worm gear in their drivetrains, and so do not permit backdriving of the motors by the vehicle's inertia. 
Instead of coasting, they immediately stop when the motor is commanded to 0 velocity. 

The big wheel robot (page \pageref{img_traj}, image b) displayed an unfortunately small range of commanded velocities between those which caused it to begin moving, and those which caused it to flip over on its side.
In three of its five runs, the big wheel accelerated quickly and then flipped during the first motion period. 
In the remaining two runs, it did not move at all, possibly due to gears jamming. 

\begin{figure}
	\centering
	\begin{subfigure}[t]{0.3\textwidth}
		\includegraphics[width=\textwidth]{robot_17.png}
		\caption{Motion of toy car based robot}
	\end{subfigure}
	\begin{subfigure}[t]{0.3\textwidth}
		\includegraphics[width=\textwidth]{robot_1.png}
		\caption{Motion of big wheel robot}
	\end{subfigure}
	\begin{subfigure}[t]{0.3\textwidth}
		\includegraphics[width=\textwidth]{robot_6.png}
		\caption{Motion of 6-wheel bug}
	\end{subfigure}

	\begin{subfigure}[t]{0.3\textwidth}
		\includegraphics[width=\textwidth]{robot_0.png}
		\caption{Motion of robot 0}
	\end{subfigure}
	\begin{subfigure}[t]{0.3\textwidth}
		\includegraphics[width=\textwidth]{robot_8.png}
		\caption{Motion of robot 8}
	\end{subfigure}
	\begin{subfigure}[t]{0.3\textwidth}
		\includegraphics[width=\textwidth]{robot_18.png}
		\caption{Motion of robot 18}
	\end{subfigure}
	
	\begin{subfigure}[t]{0.3\textwidth}
		\includegraphics[width=\textwidth]{robot_5.png}
		\caption{Motion of bug robot}
	\end{subfigure}
	\label{img_traj}	
\end{figure}

The Hexbug-branded 6-wheeled bug (page \pageref{img_traj}, image c) displayed an asymmetry in its motor drive speeds. 
For three of its five runs, both motors ran, and the wheels on both sides rotated, but the right side was driven more quickly, and so the robot made a wide arc to the right and hit the wall of the arena behind the starting location. 
In one run, one side did not begin moving at all, causing the robot to rotate rapidly around that side. 
In another run, the robot twitched briefly, remained still, and then accelerated backwards quickly. 
This was likely caused by the gradual incrementing of the forward velocity eventually causing an integer overflow, resulting in a large forward velocity command being interpreted as a large negative velocity.


The green tank, carrying the 0 AprilTag (page \pageref{img_traj}, image d), experienced problems with one side of its drive train in three of its five runs.
One tread drive did not move, while the other did, resulting in tight turns to the left in two runs, and to the right in one run. In one of the two remaining runs, the green tank did not move at all. In the second, the tank alternated movement and stopped periods until it reached the other side of the arena, which constituted success on this test. 

There are two blue tanks, carrying AprilTags numbered 8 and 18. 
Tank number 8 (page \pageref{img_traj}, image e) moved slightly on four of its 5 runs, and did not move on one of them. 
At no point did it move the full 0.25m. 
Tank number 18 (page \pageref{img_traj}, image f) moved much more consistently, but displayed an arc to the right in four of its 5 runs. 
In one run, the tank failed to restart after one of the stop phases, and eventually accelerated quickly in reverse. 
As with the 6-wheeled bug, this was likely the failure of the robot to move leading to a long enough delay that incrementing the commanded acceleration resulted in an integer overflow. 

The single-motor Hexbug-branded blue bug (page \pageref{img_traj}, image g) moved consistently, but with a heavy bias towards turning to the left. 
In every run, it started and stopped, but the curvature of the path to the left caused it to run into the left side of the arena. 
During one run, it fell over while moving, due to the somewhat ``bouncy'' nature of the toy's gait.


Some of these problems, such as the coasting of the Ackerman-steering car and the biases towards the left or right of some of the robots when commanded to move straight, can be overcome by software. 
For example, assuming the tags could be used to accurately measure the rotation of the robots, error between the detected rotational velocity and perceived rotational velocity could be accounted for in subsequent motion commands. 
The Ackerman-steering car drift could be reduced by sending a ``brake'' command to the motor driver IC to activate its back-EMF braking mode, rather than simply stopping by reducing the power output to zero. 
However, some of the problems are more difficult to alleviate. 
The tendency of the big wheel robot to flip over could be mitigated by very gradually increasing its speed, at the cost of reducing its control responsiveness, or by increasing the frequency of the feedback loop that checks its speed. 
Perhaps the blue bug would not fall over if its height were reduced, or the battery were placed lower on the body of the robot.
However, these mechanical problems could be more easily avoided by simply not using toys that have them. 

\section{Future Work}
Any operation that requires user intervention with each individual robot will not scale well as the swarm size increases. 
As a result, robots should have autonomous charging, and be able to monitor their own battery level. 
The alternative, leaving out self-charging and battery monitoring, results in increased effort by humans to keep the batteries charged and failures due to discharged batteries that are not immediately obvious to the control software. 
In the case of the Kilobots, the swarm as a whole can be charged in parallel, rather than requiring the individual robots to be connected with a charger. 
For the GRITSBbots, pins on the front of each robot allow the robot to connect to a charging station by itself, rather than requiring a human to connect it. 
The TinyRobo platform could be trivially altered to provide GRITSBots-style self-charging, but does not at present have a method to detect a low battery condition.
At a more general level, hardware health monitoring is required for systems that intend to detect their own failed components and work around them, which increases robustness in a swarm system. 

In future work, the use of a direct drive train, as in GRITSBots or mROBerTO, would likely provide more reliable motion, because the drive train is sealed against foreign matter. 
Further, the use of stepper motors in GRITSBots provides some degree of precision in motion control by directing the motor in steps of known resolution, rather than commanding a particular speed. 
If the system requires additional torque, sealed micro gearmotors are preferable to adopting a drivetrain from a toy. 
Toy drivetrains are designed for minimal cost over reliability and precision. 

The chassis of the robot can be constructed from the same printed circuit board (PCB) that the electronics are supported on. 
Over the scales of forces present in tabletop swarms, PCB can be considered completely rigid, and electronics solder provides sufficient mechanical strength for motor mounts. 
The use of custom mechanical assemblies in e.g. Jasmine micro robots adds complexity to the build process. 
Using childrens' toys in TinyRobo was intended to avoid the use of such custom parts, but brought with it additional problems that were outside of the scope of the work to solve, and could have been avoided with a simpler drivetrain and mechanical design. 

If stepper motors were used, this change would bring the TinyRobo platform very close to the GRITSBots platform in terms of hardware design. 
If DC motors were used instead, the resulting platform would be closer to Colias. 
In biology, the appearance of similar solutions to a design problem across different species, such as the similar fin placement on dolphins and sharks, is called convergent evolution. 
It appears that over the development of tabletop swarm robots, stacked PCBs as mechanical structure, IR sensor rings, and direct drivetrains are all convergent features, representing the best solutions at the lowest cost. 
The use of toys as drivetrains is closer to the foot bones present in the skeletons of whales: of potential historical interest, but superseded by better methods of locomotion. 

\section{Conclusions}

However, while the toy-based design of TinyRobo may be an evolutionary dead end, the software and control modules are not.
Swarm software is frequently described as centralized or decentralized. 
In a centralized system, a single computer coordinates the actions of the swarm by commanding each individual robot. 
In a decentralized system, robots use their local processors and sensor information to make control decisions. 
The TinyRobo design works with ROS to provide an emulation of a decentralized system within a centralized system. 
While this paper presents it in the context of a complete system, the software framework is not tightly bound to the TinyRobo hardware, and so may be useful to other users of tabletop swarms. 

The combination of hardware and software presented in this work makes it possible to construct swarm robots at a cost of \$20-\$40 per robot. 
The hardware used in the construction of the TinyRobos tested in this paper was ultimately insufficiently reliable to be a good platform for swarm robot experimentation. 
However, the TinyRobo control module is flexible enough to permit it to be used with better mobility platforms, assuming some time is set aside to characterize the behavior of the chosen mobility platforms. 

In the hopes that they will be of use to future swarm roboticists, the TinyRobo control software and hardware design is available online at https://github.com/ab3nd/TinyRobo.

\bibliography{../proposal/swarm.bib}
\bibliographystyle{apalike}

\end{document}
