4/21/17
- Removed finger tracking from experiment app
- Updated netbook for experiment
- Removed task text from slides for experiment
- Edited "defective robot" images to have smoke coming from robot
- Replaced defective robot images in slides
- Install GUI framework on netbook
- Convert all the pdfs of the slides
- Test netbook with 3M screen

4/24/17
- Print instruction slides for all experiment cases
- Add command line options to test program 
	-c condition -i subject ID

4/25/17
- Fix problem with ini file loading in test app
	- It was the wrong monitor, no GL accleration on the rightmost monitor
- e-mailed a few people who asked about the code at the Open House
- Configured wheelchair network
	- Don't use the lab internal network and avahi-autoipd at the same time, they fight
- Disable whatever part of ubuntu keeps breaking the wired connection on the wheelchair
    - See above
- Added a bunch of stuff to the collection of everything we plug in
- Started fixing NTP on the wheelchair

4/26/17
- Organized schedule to include things like sleep, work, weightlifting, shower/shave/etc. routine
- Finished fixing ntp on the wheelchair
- Tried to get the wheelchair to talk to eduroam
	- mostly to be able to install software
	- It doesn't seem to be working well

4/27/17
- Integrated survey feedback
- Contacted Carlos about slide deck for 50th reunion event
- Botball setup
- Set up bit.ly link to youcanbookme for booking experiment slots
	- https://swarmbots.youcanbook.me/
- Set up e-mail for contacting me about experiment
	- Just using my ashultz@cs.uml.edu address, now that redirect works again
- Sent survey, slides, script, etc. to Holly to pass on to IRB
- Tried to get wheelchair to use eduroam, didn't really have any luck with it

4/28/17
- Tried to get packmule up and running to do Botball setup
- Botball setup

5/1/17 
- Researched history of robots for presentation
- Wrote presentation for class of 57/67 reunion

5/2/17
- Worked on presentation images
- tried to install active_sensing on scooter

5/3/17
- Finished presentation
- Lab meeting

5/4/17
- Installed active sensing
- Fixed up .bashrc
- Fixed cuda compilation problems and path configuration to get active_sensing working again
- Tested a few of the modules of the system

5/5/17
- Pestered everybody about videos for presentation
- Attempted to extract videos from powerpoint deck
- Interviewed canidates for summer internships
- Worked on getting scooter running, have some nodelet problem with the cameras

5/8/17
- Added movies of google glass and instrumented person to presentation
- Showed scooter to visitor from Israel
	- He asked about voice activation
	- Voice would make a good command interface

5/9/17
- Notecards for presentaton
- Dan practice talk
- Read some papers
	- Evolving a neural model of insect path navigation
		- Neat, but not relevant to the swarm project
	- http://blog.inf.ed.ac.uk/insectrobotics/antbot-setting-up-the-app/
		- ant robot, cheap swarm unit, but more individual capability than I have
		- used a vision-based path integration system

5/10/17
- Two job interviews
- Practice talk
- Talk edits

5/11/17
- Counseling appointment
- Health services appointment
- Collected primitives for programming robots
- wrote up a lot of possible ways to 
- Interviewed a potential summer hire

5/12/17 
- Presentation
- Went home and slept after presentation

5/15/17
- Tested wheelchair, trajopt pathing stuff doesn't seem to be working right in active_sensing_driving
- Lab meeting
- Brainstorming about coordinate spaces and having a UI where you legit can't see the robots
- started reg for research days in Austria

5/16/17 todo
- Fix whatever trajopt path is missing
- Read papers from that Austrian conf/Self-Organizing Systems
- Help Dan fix lab network
- Added a little calibration mark to the right camera mount
- Tried to get URDF loading to work so I can calibrate the cameras

5/8/17
- Set up single-camera on wheelchair
- Everything now working, imaged laptop

5/19/17
- Started playing with single camera
  - Structure sensor is being odd, rostopic hz didn't get anything from depth_registered
  - It only uses depth, not depth_registered, because it doesn't have RGB images

5/22/17
- Set up static transforms for second camera to wheelchair
- Test all three sensors at the same time
- put video on ICRA site so I can point people at it at the conference

5/23/17 
- Worked with Andreas on integrating second camera
- Has problems with interference between the cameras

5/24/17
- Slides for ICRA

5/25/17
- Brainstorming/todo list for PhD stuff

--ICRA--

6/5/17
- Lab meeting
- Gave interns some tasks related to Thing 1 bringup
- Read some papers on evolving controllers for cellular automata
	- probably not the way I want to go on my thesis

6/6/17
- Directing of some interns
	- Ray is doing automatic calibration of the scooter
	- Marshall is working on building Thing 1
- Automatic cloud registration with appropriate sensor activation
- Expense report for Singapore


6/12/17
- Finished registered cloud provider
- Can we get the RGB images in the same plane as well, for laser finding?
	- Otherwise, laser finder will have to be extended to two RGB images
- Lab meeting 
- Checked if subscribing to the RGB image turns the IR sensor on as well
- Expense report for Singapore trip

To Do:

6/13/17
- Test edits to active_sensing_driving
- Helped Siddharth fix a bad file system on his laptop
	- If you get "EXT4-fs (sda1): group descriptors corrupted!", boot with a liveCD, and do sudo mke2fs -n /dev/xxx to list the superblock backup locations, followed by sudo e2fsck -b block_number /dev/xxx using the first superblock backup number to restore the superblock. It will prompt you before fixing stuff, just hit y for everything. 

6/14/17
- Try to convert return path for arm to use obstacle-aware planner
- Try to troubleshoot arm kinematic problems
- Commit working stuff

6/15/17
- Troubleshooting of scooter
- Daringly updated packages and fixed CUDA again
	- Was hoping to make cloud registration a bit more stable

6/16/17
- Calibrate scooter
- Fix excessive NaN points for laser
	- have cloud_registration not check either sensor if it has no subscribers
	- have proxy unsub from cloud registration when not using it


6/20/17
- Scooter demo for Dave Kontak

6/21-25
- Finish virtual sensor node

6/27
- Fighting with the very old version of emerge on the baxter control PC to try to get wireless on the scooter. 
- Restore scooter image

6/28
- Just hook the scooter up to a switch
- Test controlling it with the laptop connected to the same switch
- Maybe put a switch in the box, so we could drive it around?

7/3,5,6
- Helped interns with finding stuff and scooter cam config
- Getting rqt_graphprofiler working with QT5
- Tried to fix lack of USB ports on XPS system (front and one rear don't do anything)
	- Using USB hub starts running into bandwidth issues with cameras
- Reseated cards and RAM in XPS, hoping to reduce crashes
- Started slides for presentation to psych class

7/5-7
- Reading up on planning 1970-1990
- Writing up notes on planning as applied to swarm program generation
- Looked into ROS planning
   - It's mostly for motion rather than task/goal oriented planning

7/10
- Reading up on planning 1990-present
- USB cables will arrive, so try to get USB cameras up on the swarm environment

7/11
- WFH, read a lot of papers

7/12
- Tried to fix the reliability issues with the scooter cameras
   - problem doesn't show up repeatably, so solving it is problematic
   - Also, linux is trash. 
      - Sometimes the scooter laptop doesn't have a visible mouse cursor on reboots
      - / somehow became read-only, rebooting fixed it, after a bit of whining about /tmp not being ready
   - Read a bunch of papers and took notes
      - Looks like I'm close to a lot of things but not exactly overlapping any of them
   - Swung by NERVE and tried out USB extension for table camera
      - Straight doesn't work. I get select timeouts if the cable is present, and no problems if the cable is absent. The camera cable just isn't long enough. 
   - USB card that I have in the computer probably just needs to be thrown away, it doesn't show up on lspci and is probably too slow anyway
   - I don't think I have any USB3 ports on this computer to test the extension on, took it home to test. 

7/13
- Tested cameras and extension cable on my home computer 
   - Cheese and ROS's usb_cam node work, guvcview doesn't
- Got a PCIe USB3 card for swarm control computer
   - Cameras work on extension cable on USB card, but aren't wide-angle enough
   

7/14
- Committed changes to cloud registration for wheelchair, seems to be a lot more stable now

7/17-721
- Find out what branch marcus was referring to
- Try to pull changes for doing multi-point views after failing on point view
- Image wheelchair laptop again before merging
- Bad attempt to add infinitam
- started better attempt to add infinitam to scooter
- No swarm work
- Added grasping in base cloud

7/23
- Edits to paper for HardwareX
   - Are there any other open-source hardware journals?

7/24
- Scooter work to add infinitam
- Paper from Holly

7/25
- Demo/meeting with Dave Kontak
- Read a bunch of papers (see notes file)
- Thinking about representation of interpreted user input for compiler
   - probably json data structures, don't see a lot of reason for anything much more complex at the moment

7/26
- Shot and tried to render video
   - lagged my computer like mad
- Tried to set up camera at Nerve
- Rendering videos and copying them off the camera takes 5ever
- Finished slides for talk... tonight. A fine academic tradition!
- Read a bunch of papers on bug algorithms and gap trees
   - Might be useful for swarms, given that swarms are frequently made of bugs (see notes.txt)

8/1
- Focus group at CMRC

8/2 - 8/4
- Writing, mostly hardware paper and heirarchy paper

8/7
- Cleaned out 216
- Writing heirarchy paper

8/8
- Tried to get camera calibrated on XPS for swarm
   - XPS keeps crashing, ran MemTest to try to diagnose it
- Paper writing

8/9
- Paper writing

8/10
- Paper writing, started control theory section    

8/14-15
- Setting up some stuff with the experiment for pilots
- Weird diagonal display tearing on the lab laptop and the 3m screen, will bring in my own laptop
- Finished first draft of hardware paper

8/16
- Video drivers on old linux laptop from scooter cause major rendering issues on second monitor
- Using the old robotbrain laptop can't have accurate mouse positions because it's also a touchscreen
   - https://askubuntu.com/questions/141341/touchscreen-with-dual-monitors first solution
   - command is 'xinput --map-to-output 16 VGA1'
- Test run with samuel took 10 minutes

8/18-8/22
- Saw a solar eclips from within the path of totality, it was AWESOME
- Hugs to Adeline!

8/23
- Fighting with kivy config to get multitouch from 3M screen, was met with failure
- Improvements to log processor

8/24
- Improvements to log processor, not sure how much more work it really needs
- Don't have the gesture recognizer yet

8/25
- Kivy includes some gesture recognition, may be able to roll into UI easily
- Can't seem to get multitouch monitor working with kivy on laptop, may try on desktop

8/26
- Got the touchscreen.... mostly working with mtdev and the line 
	microtouch = mtdev, /dev/input/by-id/usb-3M_3M_MicroTouch_USB_controller-event-if00
- Shape quality of the events isn't picklable, so I may have to do something a little fancy to deal with that
  - I probably do care if they e.g. use their hands for it. 
  - events are only either rectangles or None, so I save either the width/height of the rectangle or None for the width/height

9/5
- Gesture recognizer
  - I don't have a slide for "zoom the map" as a task

8/27
- Paper edits
- Schedule

8/28
- Lab meeting
- Work on swarm at NERVE
  - Start writing GCPR evaluator
- Yoga

8/30
- Work on swarm at NERVE
  - More GCPR evaluator

8/31
- Work on swarm at NERVE
  - More GCPR evaluator

9/1
- Work on swarm at NERVE
  - Have the compiler generate a program that the GCPR evaluator can deal with
- Probably leave early to head home?

9/2-9/5
- Home

9/6
- WFH, gesture compiler, out sick

9/8
- Made index card stack for tracking tasks
- Started to combine gesture recognizer and compiler

9/9
- Stutter removal in parsing of gestures 

9/11
- Debugged slide loading
- Added double-clicks to gesture recognizer

9/12
- Fixed apt, was using apt cache server on subtle, caused problems when subtle was down
- Hoping to run more pilots with lab people

Wheelchair:

9/13
- Lots of messing around with kivy image creation
- Lots of tinkering with python memmaping 
- Basic kivy app that reads camera works, but will fight anything else acessing the camera
- v4l2loopback looks like an interesting way forward, but having issues

9/14
- Added touch events to real ui, started gesture recognition for it

9/15
- Lab clean-up

9/18
- Working on gesture recognition
- Kivy pygst camera provider works on desktop, but not on laptop
- Kivy problems with touches being registered all over screen, not just on window

9/19
- Tried to fix kivy app getting multiple touches all over the screen
    - Not fixable, that's just How Kivy Is. Run app in fullscreen as workaround

9/22
- Attempt to do drive to point
- got sidetracked by quaternion math work
    - now have a rough idea of how quaternions are used

Spent a lot of time around here having a cold and not being able to think well

9/26
- Worked on program distribution for compiler
- Currently using ROS String messages with the code as a json string in them
- Much messing around with gstreamer to get
  gst-launch-1.0 v4l2src device=/dev/video0 ! "image/jpeg,width=1024,height=768" ! tee name=f ! queue ! v4l2sink device=/dev/video1 f. ! queue ! v4l2sink device=/dev/video2
  which works with ROS's gscam, but not usb_cam

9/27
- worked on deployment of program to tiny robots
    - currently sends a json representation of a GCPR program

9/28
- Swtched to gscam on main swarm box, usb_cam doesn't play well with v4l2loopback
- Tried to get kivy/real_ui.py working on main swarm box
- Tested Alvar tag tracker for ROS, got 1Hz in a configuration where APRIL tags get 4Hz
- Got IRB approval (finally!)

9/29
- Cleaned inner lab for experiment

10/2
- Set up cameras
- Physical therapy appointment
- Job fair at CIC

10/3
- Wired network for experiment
- Tested survey

10/4
- Set up camera angles for recording screen
- Figured out recording with VLC, but will probably use rosbag and ROS camera drivers
- Added ROS messaging to user interface for logging with rosbag

10/5-10/10
- Edited paper for Holly
- Started applicaiton for National Geographic grant to fly a drone around sculptures and scan them
   - because I'm clearly insane. 
- Got Dan's camera code and rosbag playing well with the UI, now records everything except sound
- finished poster
- added and tested rosbag logging
- arts and crafts day to add Aruco tags to robots

10/11
- Implemented state machine for core of compiler, not complete yet
   - Based on Mark's gesture language, will add my own extensions later

10/12 
- More work on state machine
- Cut tabs on a lot of flyers

10/13 (Friday the 13th! Auspicious!)
- Put up more flyers

10/16 
- Ran two users through the experiment
- Debugged a problem with running the script from the launchfile
- Worked on a program to dump video from the bagfile

10/17
- 2 Participants
- distance hacking for nat geo thing

10/18
- 3 participants, psych appointment, meeting with Holly

10/19
- 5 experiement particpants
- Video dump from bagfile doesn't synch with audio
- wrote a script to draw contacts on the UI image and publish as a ROS image topic
- can now code direct from bagfile, which is syncronized

10/20
- 5 experiement particpants
- 2-opt routing for nat geo budget calculations

10/21
- Worked on removing april tags in favor of aruco tags. 
- The package to use is http://wiki.ros.org/aruco_detect

10/22
- Tested aruco tags in rviz
	- too noisy at the scale I want
- april tags can be sped up a little by setting compiler flags (-DCMAKE_BUILD_TYPE=Release or thereabouts)

10/23
- 2 subjects
- set up backups for my data
- checked and labled a bunch of the hard drives from around the lab

10/24 
- 2 subjects, one no-show
- Reading up on Grounded Theory for coding
    - Based on social sciences
    - the main aspects we care about are open coding of gesture, then axial coding to refine gesture defs
- Wrote up how to code data

10/25
- test subjects
- started writing up experiment

10/26
- two users, 3 no-shows
- half done with data collect
- read some papers (notes file)
- worked more on writeup of experiment

10/27
- Reviewed Dalton doc
- Slight work on paper about experiment
- 5 participants, 1 no-show

10/28
- Attempts at camera cal again
- Rebuilt camera mount (no more tape)

10/29
- Installed new camera mount
- wrote a lot of the gcpr-to-robot code
    - Still needs testing

10/30
- No experiment, uni power down
- Made a few paper edits from Jordan

10/31
- 3 participants
- Read a bunch of papers on NUI, multitouch for experiment paper
- So far I've had three participants ask what a Palm PDA is. 
    - I feel old :-(

11/1
- 2 participants
- Read most of book on grounded theory

11/2
- Dr. appointment
- 3 participants
- Read some more papers on multitouch
- Helped set up Primesense on Baxter

11/13
- Proposal edits
- Set up for NERVE Open House

11/25
- Initial pass coding all the videos done over last week or so

11/27
- Entered some data from notes to csv files
- Lab meeting
- Call with Black-i

11/28
- Finished entering first 10 of the participants data to csv
- Started writing a script to normalize/correct csv files

11/29
- Corrected csv files to eliminate mis-entered dates, other problems

11/30
- Wrote script for coding video 
- Updates to timeline

12/4
- Modified some options to script, added ability to tag files with coder's username to avoid collisions
- Ran out of space on lab machine to make copy of experiment data, copying videos and MS thesis work to external drive
	- This will apparently take two forevers, and crippled my ability to watch the videos off the external drive

12/7
- Coded more video
- Packed up swarm table
- stripped four toy tanks to turn into more tiny robo nodes

12/8 

12/9
- What did I do here? Clearly not update this file...

12/11
- Coded more video

12/12
- Finished video coding
- Tried to help Victoria with a C++ problem
- Ordered more tiny robot parts
- Updated timeline for PhD

12/13
- wrote analysis script for handling the .json files that the video coding script produces
- still need some clarification on how to do Cohen's Kappa for differing sizes of sets of events
- Removed e-pucks from NERVE

12/15
- Built three more tiny robo boards
- Ordered batteries for more tiny robos

12/17
- Worked on writeup of experiment

1/1-1/7
- Sick
- Did some coding
- Did checking of Krippendorff's alpha of the coded data
- Found some causes of difference between James and my codings, told James how to not do that

1/8
-Wrote some scripts to handle the coded data
-Read a lot of papers on usability studies with an eye towards validation


Swarm control software
- Implement a simulation of attempting to vector towards a point, and doing wall follow to get around obstacles. Robots will have to have volume/area, so they don't just pile up in a point. Intent is to see what's a solid strategy for going somewhere with obstacle avoidance. 
- look for papers on follow-the-leader, ant mills in robots
- there are papers on developing a coordinate grid with only local sensing and messaging, get some references
- write a little sim to see if the spreading inhibition and member-count-based frame choice is a stable strategy for eventually having one coordinate frame dominate. Write a graphical output for it so it looks sweet, and for illustrating papers. 

Documentation/presentations
- Write presentation for ICRA
- Finish paper for HardwareX, including last revision of hardware





To Not Do:
- Put lubuntu on the vaio
	- Crashes on USB stick insertion, probably can't boot off USB anyway


Starting the rqt_graphprofiler
roscore
rosparam set enable_statistics true
rosrun rosprofiler rosprofiler
rosrun rosprofiler rosgrapher
roslaunch your stuff
rqt_graphprofiler


Wireless on the scooter:
The version of emerge on there is v. old, so installing a new version of emerge is blocked because of having an old version of emerge. This is a known problem with gentoo in general. Currently attempting to get the tarfile for the recent emerge, install that, upgrade it with itself. 

Attempting to get the url for the tarfile by visiting http://distfiles.gentoo.org/distfiles/ crashes firefox, so I got it with 

 wget http://distfiles.gentoo.org/distfiles/

Getting the new version of portage resulted in a python version fight. 

Installing things with either version of portage, old or new, results in it making output that looks like it's installing things, without actually doing the install. 

ruser@thing2 ~/new_portage/portage-2.3.6 $ sudo emerge python-updater
!!! Invalid PORTDIR_OVERLAY (not a dir): '/usr/local/portage/overlay-rethink'
!!! Invalid PORTDIR_OVERLAY (not a dir): '/usr/local/portage/overlay-ros-indigo'
!!! SYNC setting found in make.conf.
    This setting is Deprecated and no longer used.  Please ensure your 'sync-type' and 'sync-uri' are set correctly in /etc/portage/repos.conf/gentoo.conf

 * IMPORTANT: 2 config files in '/etc/portage' need updating.
 * See the CONFIGURATION FILES and CONFIGURATION FILES UPDATE TOOLS
 * sections of the emerge man page to learn how to update config files.
Calculating dependencies  .... done!
>>> Emerging binary (1 of 1) app-admin/python-updater-0.14::gentoo
>>> Installing (1 of 1) app-admin/python-updater-0.14::gentoo
>>> Jobs: 1 of 1 complete                           Load avg: 0.39, 0.42, 0.34
>>> Auto-cleaning packages...

>>> No outdated packages were found on your system.

 * GNU info directory index is up-to-date.

 * IMPORTANT: 2 config files in '/etc' need updating.
 * See the CONFIGURATION FILES and CONFIGURATION FILES UPDATE TOOLS
 * sections of the emerge man page to learn how to update config files.
ruser@thing2 ~/new_portage/portage-2.3.6 $ py
pydoc                  pygtk-codegen-2.0      python2.7-config       python-config          pyvenv-3.3
pydoc2.7               pylupdate4             python3                python-config-2.7      pyvenv-3.4
pydoc3.3               pyrcc4                 python3.3              python-config-3.3      
pydoc3.4               python                 python3.3-config       python-config-3.4      
pygmentize             python2                python3.4              python-wrapper         
pygobject-codegen-2.0  python2.7              python3.4-config       pyuic4                 
ruser@thing2 ~/new_portage/portage-2.3.6 $ py
pydoc                  pygtk-codegen-2.0      python2.7-config       python-config          pyvenv-3.3
pydoc2.7               pylupdate4             python3                python-config-2.7      pyvenv-3.4
pydoc3.3               pyrcc4                 python3.3              python-config-3.3      
pydoc3.4               python                 python3.3-config       python-config-3.4      
pygmentize             python2                python3.4              python-wrapper         
pygobject-codegen-2.0  python2.7              python3.4-config       pyuic4                 
ruser@thing2 ~/new_portage/portage-2.3.6 $ python-updater
-bash: python-updater: command not found

Unfortunately, restoring the image of the baxter hard drive seems to have done something bad to the networking on the baxter. 

It's now using "stable network interface names" instead of net1 and net0

Somehow, /etc/udev/rules.d/70-persistent-net.rules either wasn't included in the clonezilla backup, or got deleted. Either way, it's needed to configure the network interfaces to be named net1 and net0, which is in turn needed by everything else. 

I fixed it by scping the 70-persistent-net.rules off the working baxter and editing it. For future reference, the values are 

net0: 34:17:eb:af:2b:a5 <- Dell interface, or at least Dell vendor according to lookup
net1: 00:0a:f7:68:78:7e <- Broadcom, probably the network card